---
title: 视线移动和提交
description: 视线移动和提交输入模型概述
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
keywords: 混合现实的视线移动，注视目标交互，设计
ms.openlocfilehash: 7bce18853e46d71d963574b35c393e5a5dbf2cd0
ms.sourcegitcommit: 90ce9415889e7121dd2fd76a893dc3734672881b
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 04/29/2019
ms.locfileid: "64873968"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="bf6b3-104">Head 注视和提交</span><span class="sxs-lookup"><span data-stu-id="bf6b3-104">Head-gaze and commit</span></span>
<span data-ttu-id="bf6b3-105">Head 注视和提交是包括针对具有转发指点您头 （head 的方向） 的方向的对象输入的模型，然后对其进行操作的辅助数据库输入此类为以无线方式点击手手势或语音命令"Select"。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="bf6b3-106">它被视为具有间接操作，这意味着它最适用于与超出手臂达到了的内容进行交互的"得"输入的模型。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="bf6b3-107">设备支持</span><span class="sxs-lookup"><span data-stu-id="bf6b3-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="bf6b3-108"><strong>输入的模型</strong></span><span class="sxs-lookup"><span data-stu-id="bf6b3-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="bf6b3-109"><a href="hololens-hardware-details.md"><strong>HoloLens （第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="bf6b3-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="bf6b3-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="bf6b3-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="bf6b3-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式耳机</strong></a></span><span class="sxs-lookup"><span data-stu-id="bf6b3-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="bf6b3-112">Head 注视和提交</span><span class="sxs-lookup"><span data-stu-id="bf6b3-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="bf6b3-113">✔️ 建议</span><span class="sxs-lookup"><span data-stu-id="bf6b3-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="bf6b3-114">建议使用 ✔️ (第三个选项-<a href="interaction-fundamentals.md">查看其他选项</a>)</span><span class="sxs-lookup"><span data-stu-id="bf6b3-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="bf6b3-115">➕ 备用选项</span><span class="sxs-lookup"><span data-stu-id="bf6b3-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="bf6b3-116">Head 视线移动</span><span class="sxs-lookup"><span data-stu-id="bf6b3-116">Head-gaze</span></span>
<span data-ttu-id="bf6b3-117">混合的现实耳机使用位置和方向的用户的头来确定其头方向向量。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="bf6b3-118">您可以将此视为直接在用户的眼球之间直接向前点从激光。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="bf6b3-119">这是相当粗略的用户正在近似值。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="bf6b3-120">你的应用程序可以与此虚拟还是实际对象与射线相交和在该位置以让用户知道什么它们当前面向绘制光标。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="bf6b3-121">除了头的视线移动，如 HoloLens 2 所示一些混合的现实耳机包含的眼跟踪生成的眼睛注视向量的系统。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="bf6b3-122">这提供了用户正在细粒度的度量的值。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="bf6b3-123">可以生成的视线移动并提交交互使用关注的视线移动，但这会带来一组非常不同的设计的限制，这将在单独介绍[眼跟踪文章](eye-tracking.md)。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="bf6b3-124">提交</span><span class="sxs-lookup"><span data-stu-id="bf6b3-124">Commit</span></span>
<span data-ttu-id="bf6b3-125">面向对象或 UI 元素之后, 用户可以进行交互或者"单击"上使用辅助输入。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="bf6b3-126">这被称为模型提交步骤。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="bf6b3-127">支持以下的提交方法：</span><span class="sxs-lookup"><span data-stu-id="bf6b3-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="bf6b3-128">以无线方式手势</span><span class="sxs-lookup"><span data-stu-id="bf6b3-128">Air Tap gesture</span></span>
- <span data-ttu-id="bf6b3-129">说话的语音命令"Select"或其中一个目标的语音命令</span><span class="sxs-lookup"><span data-stu-id="bf6b3-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="bf6b3-130">按上的单个按钮[HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="bf6b3-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="bf6b3-131">按 Xbox 游戏板上的 A 按钮</span><span class="sxs-lookup"><span data-stu-id="bf6b3-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="bf6b3-132">按 Xbox 自适应控制器上的 A 按钮</span><span class="sxs-lookup"><span data-stu-id="bf6b3-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="gaze-and-air-tap-gesture"></a><span data-ttu-id="bf6b3-133">视线移动和 air 的点击手势</span><span class="sxs-lookup"><span data-stu-id="bf6b3-133">Gaze and air tap gesture</span></span>
<span data-ttu-id="bf6b3-134">空敲击是与手持设备竖直的情况下的点击手势。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="bf6b3-135">若要执行敲击，引发食指到准备就绪的位置，然后用拇指捏合引发食指备份以释放。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="bf6b3-136">HoloLens 1 上敲击是最常见的辅助输入。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![在准备好的位置，然后单击或点击动作手指](images/readyandpress.jpg)<br>

<span data-ttu-id="bf6b3-138">敲击，还可以在 HoloLens 2，并与原始版本放宽了。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="bf6b3-139">现在支持几乎所有类型的 pinches，只要手形图标仍是靠背和小存货。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="bf6b3-140">这使得更便于用户了解并执行手势。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="bf6b3-141">此新敲击替换旧证书通过相同的 API，因此现有的应用程序会收到新行为会自动重新编译 HoloLens 2 后。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="gaze-and-select-voice-command"></a><span data-ttu-id="bf6b3-142">视线移动和"选择"语音命令</span><span class="sxs-lookup"><span data-stu-id="bf6b3-142">Gaze and "Select" voice command</span></span>
<span data-ttu-id="bf6b3-143">语音命令是在混合现实的主要交互方法之一。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="bf6b3-144">它提供了非常强大的"免费手"机制来控制系统。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="bf6b3-145">有不同类型的语音交互模型：</span><span class="sxs-lookup"><span data-stu-id="bf6b3-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="bf6b3-146">"选择"的泛型命令允许执行"单击"传动或作为辅助输入的提交。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="bf6b3-147">对象命令，如"关闭"或"使其更大"，允许执行并提交对作为辅助输入的操作。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="bf6b3-148">全局 commnads 如"转到起始位置"，不需要一个目标。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="bf6b3-149">会话的用户界面或实体等 Cortana 具有 AI 自然语言功能。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="bf6b3-150">自定义 commnads</span><span class="sxs-lookup"><span data-stu-id="bf6b3-150">Custom commnads</span></span>

<span data-ttu-id="bf6b3-151">若要查找更多详细信息和可用的命令以及如何使用 comprenhesive 列表，请查看我们[语音设计](voice-design.md)指南。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice design](voice-design.md) guidance.</span></span>


### <a name="gaze-and-hololens-clicker"></a><span data-ttu-id="bf6b3-152">视线移动和 HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="bf6b3-152">Gaze and HoloLens Clicker</span></span>
<span data-ttu-id="bf6b3-153">HoloLens Clicker 是专为 HoloLens 生成的第一个外围设备，包含与 HoloLens 1 Development Edition。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="bf6b3-154">HoloLens Clicker 允许用户单击与最小手运动和提交作为辅助输入。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="bf6b3-155">HoloLens clicker 连接到 HoloLens 1 或 2： 使用蓝牙低能耗 (BTLE)。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

![](images/hololens-clicker-500px.jpg)<br>
<span data-ttu-id="bf6b3-156">HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="bf6b3-156">HoloLens Clicker</span></span>

<span data-ttu-id="bf6b3-157">可以找到更多的信息和说明设备配对[此处](hardware-accessories.md#pairing-bluetooth-accessories)</span><span class="sxs-lookup"><span data-stu-id="bf6b3-157">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="gaze-and-xbox-wireless-controller"></a><span data-ttu-id="bf6b3-158">视线移动和 Xbox 无线控制器</span><span class="sxs-lookup"><span data-stu-id="bf6b3-158">Gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="bf6b3-159">Xbox 无线控制器允许执行"单击"传动作为辅助输入通过使用一个按钮。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-159">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="bf6b3-160">设备映射到一组默认的操作，可帮助导航和控制系统。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-160">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="bf6b3-161">如果你想要自定义控制器，使用 Xbox 附件应用来配置你的 Xbox 无线控制器。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-161">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

![](images/xboxcontroller.jpg)<br>
<span data-ttu-id="bf6b3-162">Xbox 无线控制器</span><span class="sxs-lookup"><span data-stu-id="bf6b3-162">Xbox Wireless Controller</span></span>

[<span data-ttu-id="bf6b3-163">配对使用 PC 的 Xbox 控制器</span><span class="sxs-lookup"><span data-stu-id="bf6b3-163">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="bf6b3-164">自适应的视线移动和 Xbox 控制器</span><span class="sxs-lookup"><span data-stu-id="bf6b3-164">Gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="bf6b3-165">主要旨在满足使用有限的移动游戏玩家的需求，Xbox 自适应控制器是统一的中心的设备，可帮助使混合现实更易于访问。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-165">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="bf6b3-166">Xbox 自适应控制器允许执行"单击"传动作为辅助输入通过使用一个按钮。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-166">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="bf6b3-167">设备映射到一组默认的操作，可帮助导航和控制系统。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-167">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="bf6b3-168">如果你想要自定义控制器，使用 Xbox 附件应用来配置你的 Xbox 自适应控制器。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-168">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

![](images/xbox-adaptive-controller-devices.jpg)<br>
<span data-ttu-id="bf6b3-169">Xbox 自适应控制器</span><span class="sxs-lookup"><span data-stu-id="bf6b3-169">Xbox Adaptive Controller</span></span>

<span data-ttu-id="bf6b3-170">将交换机、 按钮、 装载和游戏杆创建唯一是你的自定义控制器体验等外部设备的连接。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-170">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="bf6b3-171">与通过 3.5mm 插孔和 USB 端口连接的辅助设备控制按钮、 摇杆和触发器的输入。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-171">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

![](images/xbox-adaptive-controller-ports.jpg)<br>
<span data-ttu-id="bf6b3-172">Xbox 自适应控制器端口</span><span class="sxs-lookup"><span data-stu-id="bf6b3-172">Xbox Adaptive Controller ports</span></span>

[<span data-ttu-id="bf6b3-173">设备配对的说明</span><span class="sxs-lookup"><span data-stu-id="bf6b3-173">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="bf6b3-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Xbox 站点上可用的详细信息。</a></span><span class="sxs-lookup"><span data-stu-id="bf6b3-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


# <a name="device-support"></a><span data-ttu-id="bf6b3-175">设备支持</span><span class="sxs-lookup"><span data-stu-id="bf6b3-175">Device support</span></span>
<span data-ttu-id="bf6b3-176">Head 注视，可在所有混合的现实耳机上提交。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-176">Head gaze and commit is available on all mixed reality headsets.</span></span> <span data-ttu-id="bf6b3-177">是 HoloLens v1 上的主输入的模型。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-177">Is the primary input model on HoloLens v1.</span></span> <span data-ttu-id="bf6b3-178">其他耳机通常包含基于现有的指针机制，例如运动控制器或说明哪些情况下手动跟踪。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-178">Other headsets typically include a hand-based pointing mechanism, such as motion controllers or articulated hand tracking.</span></span> <span data-ttu-id="bf6b3-179">在这些设备上的应用程序应首选[点提交](point-and-commit.md)远端的交互，在可能的情况。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-179">On these devices, applications should prefer [point-and-commit](point-and-commit.md) for far interactions when possible.</span></span>

<span data-ttu-id="bf6b3-180">关注的视线移动和提交 HoloLens 2 上可用，但不是主输入的模型。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-180">Eye gaze and commit is available on HoloLens 2, but is not the primary input model.</span></span> <span data-ttu-id="bf6b3-181">跳转到讨论时，这可能会使您的应用程序的"关注的视线移动设计指南"部分。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-181">Jump to the "Eye gaze design guidelines" section for a discussion about when this might make sense for your application.</span></span>

# <a name="head-gaze-design-guidelines"></a><span data-ttu-id="bf6b3-182">Head 注视设计指南</span><span class="sxs-lookup"><span data-stu-id="bf6b3-182">Head gaze design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="bf6b3-183">特定看设计的更多指导[即将推出](index.md)。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-183">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="gaze-targeting"></a><span data-ttu-id="bf6b3-184">目标的视线移动</span><span class="sxs-lookup"><span data-stu-id="bf6b3-184">Gaze targeting</span></span>
<span data-ttu-id="bf6b3-185">用户能够针对他们想要进行交互，而不考虑输入模式的元素为基础构建的所有交互。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-185">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="bf6b3-186">在 Windows Mixed Reality，通常这是使用用户的视线移动。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-186">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="bf6b3-187">若要使用户能够成功使用体验，系统的计算的了解用户的意图和用户的实际目的，必须尽可能接近地对齐。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-187">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="bf6b3-188">某种程度上，系统将解释用户的预期的操作正确，满意度增加和性能提高。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-188">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="bf6b3-189">目标大小调整和反馈</span><span class="sxs-lookup"><span data-stu-id="bf6b3-189">Target sizing and feedback</span></span>
<span data-ttu-id="bf6b3-190">视线移动矢量具有已重复显示可用于面向正常，但通常最适合总目标 （获取稍大些目标）。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-190">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="bf6b3-191">1 到 1.5 度为单位的最小目标大小应在 3 个度的目标通常的速度更快，但在大多数情况下，允许用户成功操作。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-191">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="bf6b3-192">请注意，用户目标实际上是三维元素-甚至的 2D 区域的大小无论投影面向它们应该是定目标区域。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-192">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="bf6b3-193">提供一个元素是"活动"（该用户面向） 一些突出提示会非常有用-这可以包括处理，例如可见"悬停"效果、 音频突出显示或单击，或清除的元素的光标对齐方式。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-193">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="bf6b3-194">![2 个计量距离处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="bf6b3-194">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="bf6b3-195">*2 个计量距离处的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="bf6b3-195">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="bf6b3-196">![突出显示的视线移动目标的对象的一个示例](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="bf6b3-196">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="bf6b3-197">*突出显示的视线移动目标的对象的一个示例*</span><span class="sxs-lookup"><span data-stu-id="bf6b3-197">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="bf6b3-198">目标位置</span><span class="sxs-lookup"><span data-stu-id="bf6b3-198">Target placement</span></span>
<span data-ttu-id="bf6b3-199">用户将通常无法天线的视野中, 找到很高或极低定位 UI 元素将重点放大部分其关注其主要焦点 （通常大约为水平视线） 周围的区域。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-199">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="bf6b3-200">可帮助将大多数目标放入一些合理带围水平视线。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-200">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="bf6b3-201">给定用户的情况下往往会将焦点置于将 UI 元素组合在一起的程度上它们从概念上讲相关一个相对较小可视区域上随时 （视觉 attentional 圆锥体约为 10 度），可以利用从关注链接行为项目到项目的用户将其提供注视转到区域。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-201">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="bf6b3-202">在设计时用户界面，请记住在 HoloLens 和沉浸式耳机之间的字段的视图可能较大的变化。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-202">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="bf6b3-203">![举例说明如何更轻松的视线移动 Galaxy 资源管理器中的目标的分组 UI 元素](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="bf6b3-203">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="bf6b3-204">*举例说明如何更轻松的视线移动 Galaxy 资源管理器中的目标的分组 UI 元素*</span><span class="sxs-lookup"><span data-stu-id="bf6b3-204">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="bf6b3-205">提高目标行为</span><span class="sxs-lookup"><span data-stu-id="bf6b3-205">Improving targeting behaviors</span></span>
<span data-ttu-id="bf6b3-206">如果用户的意图以面向内容可以是确定 （或近似密切），它可以接受"near miss"会尝试在交互，就好像它们已正确目标很有帮助。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-206">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="bf6b3-207">有了一些可纳入混合的现实体验的成功方法：</span><span class="sxs-lookup"><span data-stu-id="bf6b3-207">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="gaze-stabilization-gravity-wells"></a><span data-ttu-id="bf6b3-208">提供注视稳定 ("重力 wells")</span><span class="sxs-lookup"><span data-stu-id="bf6b3-208">Gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="bf6b3-209">这应打开大多数/all 的时间。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-209">This should be turned on most/all of the time.</span></span> <span data-ttu-id="bf6b3-210">此方法中删除用户可能有自然的 head 颈部 jit 编译器。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-210">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="bf6b3-211">由于查找/谈到的行为也移动。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-211">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="bf6b3-212">最接近链接算法</span><span class="sxs-lookup"><span data-stu-id="bf6b3-212">Closest link algorithms</span></span>
<span data-ttu-id="bf6b3-213">这些效果最佳稀疏的交互式内容与几个方面。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-213">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="bf6b3-214">如果没有，您可以确定用户已尝试与之交互的可能性非常高，可以通过简单地假定某一级别的意图进行补充其目标的能力。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-214">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="bf6b3-215">Backdating/postdating 操作</span><span class="sxs-lookup"><span data-stu-id="bf6b3-215">Backdating/postdating actions</span></span>
<span data-ttu-id="bf6b3-216">此机制可在需要速度的任务。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-216">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="bf6b3-217">当用户要通过一系列的目标/激活 maneuvers 速度移动时，它可用于假定某些目的，并允许丢失的步骤执行操作目标的用户在具有焦点略有之前或之后 （50 毫秒前/后的有效期中点击略有前期测试）。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-217">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="bf6b3-218">平滑处理</span><span class="sxs-lookup"><span data-stu-id="bf6b3-218">Smoothing</span></span>
<span data-ttu-id="bf6b3-219">此机制可用于的路径移动，减少由于自然磁头运动特征轻微抖动/原因。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-219">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="bf6b3-220">通过路径动作，平滑大小/距离的移动而不是随着时间的推移通过平滑处理时</span><span class="sxs-lookup"><span data-stu-id="bf6b3-220">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="bf6b3-221">消除</span><span class="sxs-lookup"><span data-stu-id="bf6b3-221">Magnetism</span></span>
<span data-ttu-id="bf6b3-222">此机制可以看作"最靠近链接"算法的绘制光标向目标，或只需增加 hitboxes （无论是以可视方式还是不） 的更多常规版本用户达到可能的目标，如使用交互式布局与一些知识更好的方法用户的意图。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-222">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="bf6b3-223">这可以是小型的目标对于特别有用。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-223">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="bf6b3-224">焦点粘性</span><span class="sxs-lookup"><span data-stu-id="bf6b3-224">Focus stickiness</span></span>
<span data-ttu-id="bf6b3-225">在确定其附近的焦点转至交互式元素，提供对当前已设定焦点的元素偏移。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-225">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="bf6b3-226">这将有助于减少不正常时浮点位于自然干扰的两个元素之间的中点的切换行为的焦点。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-226">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="bf6b3-227">复合手势</span><span class="sxs-lookup"><span data-stu-id="bf6b3-227">Composite gestures</span></span>
<span data-ttu-id="bf6b3-228">应用程序可以识别多个不仅仅是单个的分流点。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-228">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="bf6b3-229">通过组合点击保存和发布通过的手形图标移动，可以执行更复杂的复合手势。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-229">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="bf6b3-230">低级别空间中的输入数据 （敲击和布隆） 的开发人员有权访问上生成这些复合或高级手势。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-230">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="bf6b3-231">敲击</span><span class="sxs-lookup"><span data-stu-id="bf6b3-231">Air tap</span></span>
<span data-ttu-id="bf6b3-232">以无线方式点击手势 （以及其他手势下面） 只对特定点击作出反应。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-232">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="bf6b3-233">若要检测其他分流点，如菜单或掌握，您的应用程序必须直接使用上述两个关键组件手势部分中所述的较低级别交互。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-233">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="bf6b3-234">Tap and hold</span><span class="sxs-lookup"><span data-stu-id="bf6b3-234">Tap and hold</span></span>
<span data-ttu-id="bf6b3-235">保留只需维护敲击的向下指位置。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-235">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="bf6b3-236">以无线方式 tap 和 hold 的组合允许各种更复杂"单击并拖动"交互与来回移动，例如选取对象而不是在激活结合使用时或"鼠标按下"辅助交互，如显示上下文菜单。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-236">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="bf6b3-237">时，此笔势但是，为用户设计可能很容易出现的任何扩展手势过程放宽其手 postures，应使用警告。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-237">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="bf6b3-238">操作</span><span class="sxs-lookup"><span data-stu-id="bf6b3-238">Manipulation</span></span>
<span data-ttu-id="bf6b3-239">操作笔势可以用于移动、 调整大小或旋转一张全息图时所需的全息图 1:1 到用户的手移动做出反应。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-239">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="bf6b3-240">此类 1:1 移动的一个用途是允许用户绘制或绘制世界中。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-240">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="bf6b3-241">应通过的视线移动或指向操作手势的初始目标。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-241">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="bf6b3-242">一旦点击并按住启动，该对象的任何操作然后处理手动移动，则释放要一下，尽管它们操作的用户。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-242">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="bf6b3-243">导航</span><span class="sxs-lookup"><span data-stu-id="bf6b3-243">Navigation</span></span>
<span data-ttu-id="bf6b3-244">导航笔势操作如虚拟游戏杆和可用于导航的 UI 小组件，如径向菜单。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-244">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="bf6b3-245">点击并按住启动手势，然后将移动您的手规范化 3D 多维数据集，以按下了初始中心内。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-245">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="bf6b3-246">为 1，其中 0 表示起始点，可以从值-1 移动您的手沿 X、 Y 或 Z 轴。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-246">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="bf6b3-247">导航可以用于生成基于速度的连续滚动或缩放手势，类似于通过单击鼠标中键，然后向上和向下移动鼠标滚动 2D UI。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-247">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="bf6b3-248">使用 rails 导航是指识别中某轴移动，直到该轴上达到特定阈值的能力。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-248">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="bf6b3-249">启用多个轴中的移动后的应用程序中由开发人员，例如，此操作才有用，如果应用程序配置为识别跨 X，Y 轴的导航操作但还指定 X 轴使用 rails。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-249">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="bf6b3-250">在这种情况下系统将在 X 轴的手移动，只要它们仍保持在假想 rails （指南） 在 X 轴，如果识别手动移动，也会发生 Y 轴。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-250">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="bf6b3-251">在 2D 应用程序，用户可以使用垂直导航笔势滚动、 缩放，或拖动在应用程序。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-251">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="bf6b3-252">这会注入到应用，以模拟相同类型的触摸手势的虚拟根手指收尾工作了。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-252">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="bf6b3-253">用户可以选择何种操作进行的上述应用程序，通过选择按钮或说 < 滚动/拖/缩放 > 工具栏上的工具之间切换。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-253">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="bf6b3-254">复合笔势的详细信息</span><span class="sxs-lookup"><span data-stu-id="bf6b3-254">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="bf6b3-255">笔势识别器</span><span class="sxs-lookup"><span data-stu-id="bf6b3-255">Gesture recognizers</span></span>

<span data-ttu-id="bf6b3-256">使用手势识别的一个好处是，您可以配置仅用于当前目标全息图可以接受的手势的手势识别程序。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-256">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="bf6b3-257">该平台将执行仅消除二义性要区分这些特定的受支持的手势。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-257">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="bf6b3-258">这样一来，只需支持敲击一张全息图可以接受任意长度的按下和释放之间的时间，一张全息图时支持同时点击并按住可升级到保留点击后保留时间阈值。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-258">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="bf6b3-259">手动识别</span><span class="sxs-lookup"><span data-stu-id="bf6b3-259">Hand recognition</span></span>
<span data-ttu-id="bf6b3-260">HoloLens 识别手势通过跟踪的一个或两个手中可看到设备的位置。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-260">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="bf6b3-261">HoloLens 它们处于就绪状态 （背面手形图标索引手指您朝上） 或按下的状态 （背面食指您朝下手形） 时看到了手中。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-261">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="bf6b3-262">其他带来手中时，HoloLens 将忽略它们。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-262">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="bf6b3-263">对于每个指针的 HoloLens 检测，可以访问它 （不带方向） 的位置和其按下的状态。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-263">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="bf6b3-264">当手形图标接近手势帧的边缘时，你要还提供方向矢量，让他们知道如何移动其手，若要获取其返回 HoloLens 可以看到它可以向用户显示。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-264">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="bf6b3-265">手势帧</span><span class="sxs-lookup"><span data-stu-id="bf6b3-265">Gesture frame</span></span>
<span data-ttu-id="bf6b3-266">对于 HoloLens 的手势，手形图标必须是"手势在范围内"，（非常大致从鼻子到处理，以及在了肩膀之间） 手势感知照相机可以适当地看到某个范围内。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-266">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="bf6b3-267">用户需要在此区域中 （许多用户最初假定手势框架必须在内通过 HoloLens，其视图和其手臂 uncomfortably 存放以进行交互） 的识别操作的成功和其自己舒适的训练。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-267">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="bf6b3-268">在使用 HoloLens Clicker，手不需要为手势范围内。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-268">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="bf6b3-269">在连续手势的情况下特别是，会出现风险移动中 （例如移动某些 holographic 对象） 时的中间笔势，笔势帧之外太多的事情并丢失它们的预期的结果的用户。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-269">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="bf6b3-270">有三个您应考虑的事项：</span><span class="sxs-lookup"><span data-stu-id="bf6b3-270">There are three things that you should consider:</span></span>

- <span data-ttu-id="bf6b3-271">手势帧存在并近似边界 （这教给 HoloLens 安装过程中） 上的用户培训。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-271">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="bf6b3-272">当其手势是接近最大/重大手势帧边界内应用程序，不需要的结果都将导致丢失的手势程度时通知用户。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-272">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="bf6b3-273">研究显示的此类通知系统的关键质量和 HoloLens shell 提供了此类型的通知 （视觉对象，指示的方向跨越正在进行中的边界对中央游标） 的一个很好示例。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-273">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="bf6b3-274">应尽量减少中断手势帧边界的后果。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-274">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="bf6b3-275">一般情况下，这意味着应停止在边界，但不是会反转手势的结果。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-275">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="bf6b3-276">例如，如果用户在一个房间跨移动某些 holographic 对象，手势帧被破坏，但不是能返回到起始点时，应停止移动。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-276">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="bf6b3-277">用户可能会遇到一些挫折然后，但可能更快地了解边界，而无需每次重新启动其完整的预期的操作。</span><span class="sxs-lookup"><span data-stu-id="bf6b3-277">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="bf6b3-278">请参阅</span><span class="sxs-lookup"><span data-stu-id="bf6b3-278">See also</span></span>
* [<span data-ttu-id="bf6b3-279">直接操作</span><span class="sxs-lookup"><span data-stu-id="bf6b3-279">Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="bf6b3-280">点和提交</span><span class="sxs-lookup"><span data-stu-id="bf6b3-280">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="bf6b3-281">交互基础知识</span><span class="sxs-lookup"><span data-stu-id="bf6b3-281">Interaction fundamentals</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="bf6b3-282">视线移动和停留</span><span class="sxs-lookup"><span data-stu-id="bf6b3-282">Gaze and dwell</span></span>](gaze-targeting.md)
* [<span data-ttu-id="bf6b3-283">视线移动和语音</span><span class="sxs-lookup"><span data-stu-id="bf6b3-283">Gaze and voice</span></span>](voice-design.md)





