---
title: 头部凝视和提交
description: 头部凝视和提交输入模型概述
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: 混合现实, 凝视, 设定凝视目标, 交互, 设计
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692311"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="753e9-104">头部凝视和提交</span><span class="sxs-lookup"><span data-stu-id="753e9-104">Head-gaze and commit</span></span>
<span data-ttu-id="753e9-105">头部凝视和提交是一种输入模型，它按照头部朝向前方（头部方向）的方向确定对象的位置，然后使用辅助输入（例如手势隔空敲击或语音命令“选择”）对其进行操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="753e9-106">它被视为一个可进行间接操作的“远”输入模型，这意味着它非常适合用于与不可触及的内容进行交互。</span><span class="sxs-lookup"><span data-stu-id="753e9-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="753e9-107">设备支持</span><span class="sxs-lookup"><span data-stu-id="753e9-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="753e9-108"><strong>输入模型</strong></span><span class="sxs-lookup"><span data-stu-id="753e9-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="753e9-109"><a href="hololens-hardware-details.md"><strong>HoloLens（第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="753e9-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="753e9-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="753e9-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="753e9-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></span><span class="sxs-lookup"><span data-stu-id="753e9-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="753e9-112">头部凝视和提交</span><span class="sxs-lookup"><span data-stu-id="753e9-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="753e9-113">✔️ 推荐</span><span class="sxs-lookup"><span data-stu-id="753e9-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="753e9-114">✔️推荐（第三个选择 - <a href="interaction-fundamentals.md">查看其他选项</a>）</span><span class="sxs-lookup"><span data-stu-id="753e9-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="753e9-115">➕ 备用选项</span><span class="sxs-lookup"><span data-stu-id="753e9-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="753e9-116">头部凝视</span><span class="sxs-lookup"><span data-stu-id="753e9-116">Head-gaze</span></span>
<span data-ttu-id="753e9-117">混合现实头戴显示设备根据用户头部的位置和方向来确定他们的头部方向向量。</span><span class="sxs-lookup"><span data-stu-id="753e9-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="753e9-118">你可以将其视为从用户两眼之间直指前方的激光。</span><span class="sxs-lookup"><span data-stu-id="753e9-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="753e9-119">这可粗略呈现出用户正查看的位置。</span><span class="sxs-lookup"><span data-stu-id="753e9-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="753e9-120">应用程序可以使此光线与虚拟或实际对象相交，并在该位置绘制光标，以便用户知道他们当前的目标。</span><span class="sxs-lookup"><span data-stu-id="753e9-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="753e9-121">除了头部凝视之外，HoloLens 2 等混合现实头戴显示设备还包括眼动跟踪系统，可以生产眼睛凝视向量。</span><span class="sxs-lookup"><span data-stu-id="753e9-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="753e9-122">这可精细测量用户正在查看的位置。</span><span class="sxs-lookup"><span data-stu-id="753e9-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="753e9-123">可以使用眼睛凝视来生成凝视和提交交互，但应遵循一组不尽相同的设计约束，[眼动跟踪文章](eye-tracking.md)中对这些约束进行了单独介绍。</span><span class="sxs-lookup"><span data-stu-id="753e9-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="753e9-124">提交</span><span class="sxs-lookup"><span data-stu-id="753e9-124">Commit</span></span>
<span data-ttu-id="753e9-125">定位对象或 UI 元素后，用户可以使用辅助输入与其交互或“单击”它。</span><span class="sxs-lookup"><span data-stu-id="753e9-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="753e9-126">这称为模型的提交步骤。</span><span class="sxs-lookup"><span data-stu-id="753e9-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="753e9-127">支持以下提交方法：</span><span class="sxs-lookup"><span data-stu-id="753e9-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="753e9-128">隔空敲击手势</span><span class="sxs-lookup"><span data-stu-id="753e9-128">Air Tap gesture</span></span>
- <span data-ttu-id="753e9-129">说出语音命令“选择”或一个目标语音命令</span><span class="sxs-lookup"><span data-stu-id="753e9-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="753e9-130">按 [HoloLens 遥控器](hardware-accessories.md#hololens-clicker)上的单个按钮</span><span class="sxs-lookup"><span data-stu-id="753e9-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="753e9-131">按 Xbox 游戏板上的“A”按钮</span><span class="sxs-lookup"><span data-stu-id="753e9-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="753e9-132">按 Xbox 自适应控制器上的“A”按钮</span><span class="sxs-lookup"><span data-stu-id="753e9-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="753e9-133">头部凝视和隔空敲击手势</span><span class="sxs-lookup"><span data-stu-id="753e9-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="753e9-134">隔空敲击是一种手部直立的点击手势。</span><span class="sxs-lookup"><span data-stu-id="753e9-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="753e9-135">若要执行隔空敲击，请将食指抬到预备位置，然后与拇指捏在一起并向上抬起食指以松开。</span><span class="sxs-lookup"><span data-stu-id="753e9-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="753e9-136">在 HoloLens 1 上，隔空敲击是最常见的辅助输入。</span><span class="sxs-lookup"><span data-stu-id="753e9-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![将手指放在预备位置，然后点击或单击](images/readyandpress.jpg)<br>

<span data-ttu-id="753e9-138">在 HoloLens 2 上也可使用隔空敲击，并且执行要求有所放宽。</span><span class="sxs-lookup"><span data-stu-id="753e9-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="753e9-139">几乎所有类型的捏合手势现在都受支持，只要手部直立并保持静止。</span><span class="sxs-lookup"><span data-stu-id="753e9-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="753e9-140">这使用户更容易学习和执行手势。</span><span class="sxs-lookup"><span data-stu-id="753e9-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="753e9-141">此新隔空敲击通过相同的 API 替换旧的隔空敲击，因此现有应用程序将在针对 HoloLens 2 进行重新编译后自动获得新的行为。</span><span class="sxs-lookup"><span data-stu-id="753e9-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="753e9-142">头部凝视和“选择”语音命令</span><span class="sxs-lookup"><span data-stu-id="753e9-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="753e9-143">语音命令是混合现实的主要交互方法之一。</span><span class="sxs-lookup"><span data-stu-id="753e9-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="753e9-144">它提供非常强大的“解放双手”的机制来控制系统。</span><span class="sxs-lookup"><span data-stu-id="753e9-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="753e9-145">可使用不同类型的语音交互模型：</span><span class="sxs-lookup"><span data-stu-id="753e9-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="753e9-146">通用命令“选择”，可用于以辅助输入的形式执行“单击”操作或提交。</span><span class="sxs-lookup"><span data-stu-id="753e9-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="753e9-147">对象命令（如“关闭”或“放大”），可用于以辅助输入的形式执行和提交操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="753e9-148">全局命令，如不需要目标的“开始”。</span><span class="sxs-lookup"><span data-stu-id="753e9-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="753e9-149">Cortana 等具有 AI 自然语言功能的对话用户界面或实体。</span><span class="sxs-lookup"><span data-stu-id="753e9-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="753e9-150">自定义命令</span><span class="sxs-lookup"><span data-stu-id="753e9-150">Custom commnads</span></span>

<span data-ttu-id="753e9-151">若要查找更多详细信息以及可用命令的完整列表和使用方法，请查看[语音命令](voice-design.md)指南。</span><span class="sxs-lookup"><span data-stu-id="753e9-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="753e9-152">头部凝视和 HoloLens 遥控器</span><span class="sxs-lookup"><span data-stu-id="753e9-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="753e9-153">HoloLens 遥控器是第一款专为 HoloLens 打造的外围设备，包含在 HoloLens 1 开发版中。</span><span class="sxs-lookup"><span data-stu-id="753e9-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="753e9-154">使用 HoloLens 遥控器，用户可通过最小幅度的手部动作进行单击操作并以辅助输入的形式进行提交。</span><span class="sxs-lookup"><span data-stu-id="753e9-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="753e9-155">HoloLens 遥控器使用低耗电蓝牙 (BTLE) 连接到 HoloLens 1 或 HoloLens 2。</span><span class="sxs-lookup"><span data-stu-id="753e9-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="753e9-156">![HoloLens 遥控器](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="753e9-157">*HoloLens 遥控器*</span><span class="sxs-lookup"><span data-stu-id="753e9-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="753e9-158">有关设备配对的详细信息和说明，请参阅[此处](hardware-accessories.md#pairing-bluetooth-accessories)</span><span class="sxs-lookup"><span data-stu-id="753e9-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="753e9-159">头部凝视和 Xbox 无线控制器</span><span class="sxs-lookup"><span data-stu-id="753e9-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="753e9-160">使用 Xbox 无线控制器，可通过使用 A 按钮以辅助输入的形式执行“单击”操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="753e9-161">设备映射到一组默认操作，以帮助导航和控制系统。</span><span class="sxs-lookup"><span data-stu-id="753e9-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="753e9-162">如果要自定义控制器，请使用 Xbox 附件应用来配置 Xbox 无线控制器。</span><span class="sxs-lookup"><span data-stu-id="753e9-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="753e9-163">![Xbox 无线控制器](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="753e9-164">*Xbox 无线控制器*</span><span class="sxs-lookup"><span data-stu-id="753e9-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="753e9-165">将 Xbox 控制器与电脑配对</span><span class="sxs-lookup"><span data-stu-id="753e9-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="753e9-166">头部凝视和 Xbox 自适应控制器</span><span class="sxs-lookup"><span data-stu-id="753e9-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="753e9-167">Xbox 自适应控制器是一个统一的设备中心，主要用于满足行动不便的玩家的需求，可帮助简化混合现实的使用。</span><span class="sxs-lookup"><span data-stu-id="753e9-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="753e9-168">使用 Xbox 自适应控制器，可通过使用 A 按钮以辅助输入的形式执行“单击”操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="753e9-169">设备映射到一组默认操作，以帮助导航和控制系统。</span><span class="sxs-lookup"><span data-stu-id="753e9-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="753e9-170">如果要自定义控制器，请使用 Xbox 附件应用来配置 Xbox 自适应控制器。</span><span class="sxs-lookup"><span data-stu-id="753e9-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="753e9-171">![Xbox 自适应控制器](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="753e9-172">*Xbox 自适应控制器*</span><span class="sxs-lookup"><span data-stu-id="753e9-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="753e9-173">连接外部设备（如开关、按钮、托架和游戏杆），创建独特的自定义控制器体验。</span><span class="sxs-lookup"><span data-stu-id="753e9-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="753e9-174">按钮、控制杆和触发器输入由通过 3.5 毫米插孔和 USB 端口连接的辅助设备控制。</span><span class="sxs-lookup"><span data-stu-id="753e9-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="753e9-175">![Xbox 自适应控制器端口](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="753e9-176">*Xbox 自适应控制器端口*</span><span class="sxs-lookup"><span data-stu-id="753e9-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="753e9-177">设备配对说明</span><span class="sxs-lookup"><span data-stu-id="753e9-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="753e9-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Xbox 网站上提供了更多信息</a></span><span class="sxs-lookup"><span data-stu-id="753e9-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="753e9-179">设计指南</span><span class="sxs-lookup"><span data-stu-id="753e9-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="753e9-180">[即将推出](index.md)有关凝视设计的更多指南。</span><span class="sxs-lookup"><span data-stu-id="753e9-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="753e9-181">头部凝视目标设定</span><span class="sxs-lookup"><span data-stu-id="753e9-181">Head-gaze targeting</span></span>
<span data-ttu-id="753e9-182">所有交互的基础都是用户能够将想要与之交互的元素设定为目标，而无论使用何种输入模态。</span><span class="sxs-lookup"><span data-stu-id="753e9-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="753e9-183">在 Windows Mixed Reality 中，通常通过用户凝视来完成此操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="753e9-184">为了实现成功使用，系统对用户意图的计算理解与用户的实际意图必须尽可能保持一致。</span><span class="sxs-lookup"><span data-stu-id="753e9-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="753e9-185">按照系统正确解释用户目标操作的程度，满意度提高，性能提高。</span><span class="sxs-lookup"><span data-stu-id="753e9-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="753e9-186">目标大小调整和反馈</span><span class="sxs-lookup"><span data-stu-id="753e9-186">Target sizing and feedback</span></span>
<span data-ttu-id="753e9-187">凝视向量已多次被证明可用于精确设定目标，但通常最适合粗略设定目标（获取较大的目标）。</span><span class="sxs-lookup"><span data-stu-id="753e9-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="753e9-188">最小目标尺寸为 1 到 1.5 度时，用户在大多数情况下都可成功执行操作，但目标尺寸为 3 度时通常可更快地设定目标。</span><span class="sxs-lookup"><span data-stu-id="753e9-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="753e9-189">请注意，即使对于 3D 元素，用户设定为目标的尺寸实际上也是 2D 区域，3D 元素的投影即是可设定为目标的区域。</span><span class="sxs-lookup"><span data-stu-id="753e9-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="753e9-190">提供一些明确的提示来表明一个元素“处于活动状态”（即用户将其设定为目标）非常有用，这可能包括可见的“悬停”效果、音频突出显示或单击，或光标与元素清晰对齐。</span><span class="sxs-lookup"><span data-stu-id="753e9-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="753e9-191">![2 米远处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="753e9-192">*2 米远处的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="753e9-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="753e9-193">![突出显示凝视目标对象的示例](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="753e9-194">*突出显示凝视目标对象的示例*</span><span class="sxs-lookup"><span data-stu-id="753e9-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="753e9-195">目标位置</span><span class="sxs-lookup"><span data-stu-id="753e9-195">Target placement</span></span>
<span data-ttu-id="753e9-196">用户经常无法找到位于其视野中非常高或非常低的位置的 UI 元素，大部分注意力集中在主要焦点（通常大致是视平线位置）周围的区域。</span><span class="sxs-lookup"><span data-stu-id="753e9-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="753e9-197">将大多数目标放在视平线位置附近的某个合理范围内可能有所帮助。</span><span class="sxs-lookup"><span data-stu-id="753e9-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="753e9-198">考虑到用户在任何时候都倾向于关注一个相对较小的可视区域（注意力视锥大约为 10 度），通过将 UI 元素分组到在概念上相关的位置，可以在用户的视线通过某个区域时利用各项目之间的注意力链锁作用。</span><span class="sxs-lookup"><span data-stu-id="753e9-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="753e9-199">在设计 UI 时，请注意 HoloLens 和沉浸式头戴显示设备之间视野的巨大差异。</span><span class="sxs-lookup"><span data-stu-id="753e9-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="753e9-200">![在 Galaxy Explorer 中使用分组 UI 元素简化凝视目标设定的示例](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="753e9-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="753e9-201">*在 Galaxy Explorer 中使用分组 UI 元素简化凝视目标设定的示例*</span><span class="sxs-lookup"><span data-stu-id="753e9-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="753e9-202">改进目标设定行为</span><span class="sxs-lookup"><span data-stu-id="753e9-202">Improving targeting behaviors</span></span>
<span data-ttu-id="753e9-203">如果能够确定（或非常近似地确定）用户目标，那么接受“差一点”的交互尝试非常有帮助，就好像它们是正确的目标一样。</span><span class="sxs-lookup"><span data-stu-id="753e9-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="753e9-204">有一些成功的方法可以融入混合现实体验中：</span><span class="sxs-lookup"><span data-stu-id="753e9-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="753e9-205">头部凝视防抖动（“重力井”）</span><span class="sxs-lookup"><span data-stu-id="753e9-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="753e9-206">应在大多数/所有时间启用此技术。</span><span class="sxs-lookup"><span data-stu-id="753e9-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="753e9-207">此技术消除了用户可能产生的自然头部/颈部抖动。</span><span class="sxs-lookup"><span data-stu-id="753e9-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="753e9-208">也可消除因看/说行为导致的运动。</span><span class="sxs-lookup"><span data-stu-id="753e9-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="753e9-209">最邻近链接算法</span><span class="sxs-lookup"><span data-stu-id="753e9-209">Closest link algorithms</span></span>
<span data-ttu-id="753e9-210">这些方法在交互内容稀少的区域效果最好。</span><span class="sxs-lookup"><span data-stu-id="753e9-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="753e9-211">如果你很有可能确定用户要尝试与之交互的内容，那么可以通过简单地假设某种程度的意图来补充其目标设定能力。</span><span class="sxs-lookup"><span data-stu-id="753e9-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="753e9-212">回溯/推迟操作</span><span class="sxs-lookup"><span data-stu-id="753e9-212">Backdating/postdating actions</span></span>
<span data-ttu-id="753e9-213">此机制非常适合需要快速完成的任务。</span><span class="sxs-lookup"><span data-stu-id="753e9-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="753e9-214">当用户在快速进行一系列定位/激活操作时，对在进行点击操作稍早或稍后之时（早期测试表明，在点击前/后 50 ms 内有效）位于用户焦点位置的目标假设一些意图和执行遗漏的步骤可能非常有用。</span><span class="sxs-lookup"><span data-stu-id="753e9-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="753e9-215">平滑处理</span><span class="sxs-lookup"><span data-stu-id="753e9-215">Smoothing</span></span>
<span data-ttu-id="753e9-216">此机制对于路径运动非常有用，可减少由于头部自然运动特征引起的轻微抖动/摆动。</span><span class="sxs-lookup"><span data-stu-id="753e9-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="753e9-217">对路径运动进行平滑处理时，根据运动幅度/距离（而非随着时间推移）进行平滑处理</span><span class="sxs-lookup"><span data-stu-id="753e9-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="753e9-218">磁吸</span><span class="sxs-lookup"><span data-stu-id="753e9-218">Magnetism</span></span>
<span data-ttu-id="753e9-219">此机制可被视为更通用的“最邻近链接”算法，可绘制靠近目标的光标，或者只是在用户接近可能的目标时增加有效范围（无论是否可见），使用一些交互式布局知识来更好地实现用户意图。</span><span class="sxs-lookup"><span data-stu-id="753e9-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="753e9-220">这对于小型目标尤其有用。</span><span class="sxs-lookup"><span data-stu-id="753e9-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="753e9-221">焦点粘性</span><span class="sxs-lookup"><span data-stu-id="753e9-221">Focus stickiness</span></span>
<span data-ttu-id="753e9-222">此机制可在确定要置于焦点的邻近交互元素时，提供其与当前置于焦点的元素的偏差。</span><span class="sxs-lookup"><span data-stu-id="753e9-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="753e9-223">这将有助于减少在具有自然噪声的两个元素之间的中点处浮动时的不稳定焦点切换行为。</span><span class="sxs-lookup"><span data-stu-id="753e9-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="753e9-224">复合手势</span><span class="sxs-lookup"><span data-stu-id="753e9-224">Composite gestures</span></span>
<span data-ttu-id="753e9-225">应用不只可以识别单独的点击手势。</span><span class="sxs-lookup"><span data-stu-id="753e9-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="753e9-226">通过将点击、保持和释放与手部移动结合，可以执行更复杂的复合手势。</span><span class="sxs-lookup"><span data-stu-id="753e9-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="753e9-227">这些复合手势或高级手势建立在开发人员可以访问的低级别空间输入数据（基于隔空敲击和使用开花手势）之上。</span><span class="sxs-lookup"><span data-stu-id="753e9-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="753e9-228">隔空敲击</span><span class="sxs-lookup"><span data-stu-id="753e9-228">Air tap</span></span>
<span data-ttu-id="753e9-229">隔空敲击手势（以及下面的其他手势）只对特定的点击做出反应。</span><span class="sxs-lookup"><span data-stu-id="753e9-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="753e9-230">若要检测其他点击，例如菜单或抓取，应用必须直接使用上面两个关键成分手势部分中描述的较低级别的互动。</span><span class="sxs-lookup"><span data-stu-id="753e9-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="753e9-231">Tap and hold</span><span class="sxs-lookup"><span data-stu-id="753e9-231">Tap and hold</span></span>
<span data-ttu-id="753e9-232">按住是指保持隔空敲击手指向下的位置。</span><span class="sxs-lookup"><span data-stu-id="753e9-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="753e9-233">通过与手臂运动（如拿起一个对象而不是激活它）或“鼠标向下”二级交互（如显示上下文菜单）结合，隔空敲击并按住组合手势可实现多种更复杂的“单击和拖动”交互。</span><span class="sxs-lookup"><span data-stu-id="753e9-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="753e9-234">但在设计此手势时请务必小心，因为用户在做出任何扩展手势的过程都很可能放松手部姿势。</span><span class="sxs-lookup"><span data-stu-id="753e9-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="753e9-235">操作</span><span class="sxs-lookup"><span data-stu-id="753e9-235">Manipulation</span></span>
<span data-ttu-id="753e9-236">如果希望全息影像 1:1 的比例反应出用户的手部运动，可以使用操作手势来移动、旋转全息影像或调整其大小。</span><span class="sxs-lookup"><span data-stu-id="753e9-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="753e9-237">此类 1:1 运动可让用户进行实际绘制或绘画。</span><span class="sxs-lookup"><span data-stu-id="753e9-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="753e9-238">操作手势的初始定位应通过凝视或指向来完成。</span><span class="sxs-lookup"><span data-stu-id="753e9-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="753e9-239">开始点击并按住后，对象的任何操作都将通过手部运动来处理，从而使用户可以在操作时环顾四周。</span><span class="sxs-lookup"><span data-stu-id="753e9-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="753e9-240">导航</span><span class="sxs-lookup"><span data-stu-id="753e9-240">Navigation</span></span>
<span data-ttu-id="753e9-241">导航手势就像一个虚拟游戏杆，可用于导航 UI 小组件（如径向菜单）。</span><span class="sxs-lookup"><span data-stu-id="753e9-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="753e9-242">点击并按住以开始手势，然后在标准化 3D 立方体中以初始按压位置为中心移动手部。</span><span class="sxs-lookup"><span data-stu-id="753e9-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="753e9-243">可以沿 X、Y 或 Z 轴移动，起点为 0，移动范围为 -1 到 1。</span><span class="sxs-lookup"><span data-stu-id="753e9-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="753e9-244">导航可用于生成基于速度的连续滚动或缩放手势，类似于通过单击鼠标按钮然后上下移动鼠标来滚动 2D UI。</span><span class="sxs-lookup"><span data-stu-id="753e9-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="753e9-245">轨道导航是指识别某个轴上的运动，直到达到该轴的特定阈值。</span><span class="sxs-lookup"><span data-stu-id="753e9-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="753e9-246">只有当开发人员在应用程序中启用多个轴中的移动时，轨道导航才有用，例如，如果应用程序被配置为能够识别 X 轴、Y 轴上的导航手势，并指定 X 轴包含轨道。</span><span class="sxs-lookup"><span data-stu-id="753e9-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="753e9-247">在这种情况下，如果 X 轴和 Y 轴上都出现了手部运动，则只要手部运动保持在 X 轴上的假想轨道（导轨）内，系统就可识别 X 轴上的手部运动。</span><span class="sxs-lookup"><span data-stu-id="753e9-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="753e9-248">在 2D 应用中，用户可以使用垂直导航手势在应用内进行滚动、缩放或拖动。</span><span class="sxs-lookup"><span data-stu-id="753e9-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="753e9-249">这会向应用注入虚拟手指触摸，以模拟相同类型的触摸手势。</span><span class="sxs-lookup"><span data-stu-id="753e9-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="753e9-250">通过选择按钮或说“<滚动/拖动/缩放> 工具”，用户可以通过在应用上方工具栏的工具之间进行切换来选择要执行的操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="753e9-251">有关复合手势的详细信息</span><span class="sxs-lookup"><span data-stu-id="753e9-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="753e9-252">手势识别器</span><span class="sxs-lookup"><span data-stu-id="753e9-252">Gesture recognizers</span></span>

<span data-ttu-id="753e9-253">使用手势识别的一个好处是可以专门为当前目标全息影像可接受的手势配置一个手势识别器。</span><span class="sxs-lookup"><span data-stu-id="753e9-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="753e9-254">该平台只会进行区分这些特定受支持手势所必需的消除歧义。</span><span class="sxs-lookup"><span data-stu-id="753e9-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="753e9-255">这样，仅支持隔空敲击的全息影像允许在按下和释放之间经历任意时长，而同时支持点击和按住的全息影像可在经历保持时间阈值之后将点击提升为按住状态。</span><span class="sxs-lookup"><span data-stu-id="753e9-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="753e9-256">手部识别</span><span class="sxs-lookup"><span data-stu-id="753e9-256">Hand recognition</span></span>
<span data-ttu-id="753e9-257">HoloLens 通过跟踪设备可识别的一只手或双手的位置来识别手势。</span><span class="sxs-lookup"><span data-stu-id="753e9-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="753e9-258">当手处于就绪状态（手背朝向自己，食指向上）或按下状态（手背朝向自己，食指向下）时，HoloLens 可检测到手部。</span><span class="sxs-lookup"><span data-stu-id="753e9-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="753e9-259">当手处于其他姿势时，HoloLens 将忽略它们。</span><span class="sxs-lookup"><span data-stu-id="753e9-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="753e9-260">对于 HoloLens 检测到的每只手，可访问其位置（无方向）及其按下状态。</span><span class="sxs-lookup"><span data-stu-id="753e9-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="753e9-261">当手接近手势范围的边缘时，可看到一个方向向量，可向用户显示该方向向量，以便他们知道如何将手移回 HoloLens 可检测的范围。</span><span class="sxs-lookup"><span data-stu-id="753e9-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="753e9-262">手势范围</span><span class="sxs-lookup"><span data-stu-id="753e9-262">Gesture frame</span></span>
<span data-ttu-id="753e9-263">对 HoloLens 做出手势时，手必须在“手势范围”内，即手势感应摄像头可以适当检测到的范围内（大致从鼻子到腰部，两肩之间）。</span><span class="sxs-lookup"><span data-stu-id="753e9-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="753e9-264">用户需要接受有关识别此区域的培训，以便成功且舒适地完成动作（许多用户最初认为手势范围必须在其通过 HoloLens 看到的视野内，并且为了进行交互以不舒服的姿势举起手臂）。</span><span class="sxs-lookup"><span data-stu-id="753e9-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="753e9-265">在使用 HoloLens 控制器时，手不需要在手势范围内。</span><span class="sxs-lookup"><span data-stu-id="753e9-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="753e9-266">特别是在使用连续手势时，用户在手势进行到一半时可能将手移出手势范围（例如移动某些全息对象），无法获得预期结果。</span><span class="sxs-lookup"><span data-stu-id="753e9-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="753e9-267">应考虑以下三个事项：</span><span class="sxs-lookup"><span data-stu-id="753e9-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="753e9-268">用户应接受关于手势范围位置和近似边界的培训（在 HoloLens 安装期间教授）。</span><span class="sxs-lookup"><span data-stu-id="753e9-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="753e9-269">在用户的手势接近/穿过应用程序的手势范围边界时通知用户，避免因丢失手势导致无法获得预期结果。</span><span class="sxs-lookup"><span data-stu-id="753e9-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="753e9-270">研究表明了此类通知系统的关键能力，而 HoloLens shell 提供了此类通知的一个良好示例（显示在中央光标处，指示超出边界的方向）。</span><span class="sxs-lookup"><span data-stu-id="753e9-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="753e9-271">应尽可能避免穿过手势范围的边界。</span><span class="sxs-lookup"><span data-stu-id="753e9-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="753e9-272">一般而言，这意味着手势应在边界处停止，而不是反转。</span><span class="sxs-lookup"><span data-stu-id="753e9-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="753e9-273">例如，用户在房间中移动某个全息对象时，应在穿过手势范围时停止运动，但不会返回到起点。</span><span class="sxs-lookup"><span data-stu-id="753e9-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="753e9-274">用户可能会遇到一些挫折，但可能更快理解边界，而不必每次都重新开始其完整的预期操作。</span><span class="sxs-lookup"><span data-stu-id="753e9-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="753e9-275">另请参阅</span><span class="sxs-lookup"><span data-stu-id="753e9-275">See also</span></span>
* [<span data-ttu-id="753e9-276">使用手直接操作</span><span class="sxs-lookup"><span data-stu-id="753e9-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="753e9-277">使用手指向和提交</span><span class="sxs-lookup"><span data-stu-id="753e9-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="753e9-278">本能交互</span><span class="sxs-lookup"><span data-stu-id="753e9-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="753e9-279">头部凝视和停留</span><span class="sxs-lookup"><span data-stu-id="753e9-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="753e9-280">语音命令</span><span class="sxs-lookup"><span data-stu-id="753e9-280">Voice commanding</span></span>](voice-design.md)





