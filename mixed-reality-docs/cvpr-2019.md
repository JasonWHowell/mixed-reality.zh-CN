---
title: CVPR 2019 的混合现实耳机讨论会的计算机视觉应用程序
description: 概述和计划混合现实耳机研讨会的计算机视觉应用程序, 在2019年6月 CVPR 会议上交付。
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: 事件, 研究模式, cvpr, 计算机视觉, 研究, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148710"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="e29f1-104">混合现实耳机的计算机视觉应用程序</span><span class="sxs-lookup"><span data-stu-id="e29f1-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="e29f1-105">与[CVPR 2019](http://cvpr2019.thecvf.com/)一起组织</span><span class="sxs-lookup"><span data-stu-id="e29f1-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="e29f1-106">长海滩 (CA)</span><span class="sxs-lookup"><span data-stu-id="e29f1-106">Long Beach (CA)</span></span>

<span data-ttu-id="e29f1-107">2019年6月17日-Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="e29f1-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="e29f1-108">者</span><span class="sxs-lookup"><span data-stu-id="e29f1-108">Organizers</span></span>
* <span data-ttu-id="e29f1-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="e29f1-109">Marc Pollefeys</span></span>
* <span data-ttu-id="e29f1-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="e29f1-110">Federica Bogo</span></span>
* <span data-ttu-id="e29f1-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="e29f1-111">Johannes Schönberger</span></span>
* <span data-ttu-id="e29f1-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="e29f1-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="e29f1-113">概述</span><span class="sxs-lookup"><span data-stu-id="e29f1-113">Overview</span></span>

![预告图](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="e29f1-115">混合现实耳机 (如 Microsoft HoloLens) 正在成为开发计算机视觉应用程序的强大平台。</span><span class="sxs-lookup"><span data-stu-id="e29f1-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="e29f1-116">HoloLens 研究模式通过提供对所有原始映像传感器流 (包括深度和 IR) 的访问权限, 在设备上启用计算机视觉调查。</span><span class="sxs-lookup"><span data-stu-id="e29f1-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="e29f1-117">由于我们自2018年5月推出了研究模式, 我们将开始为 HoloLens 开发一些有趣的演示和应用程序。</span><span class="sxs-lookup"><span data-stu-id="e29f1-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="e29f1-118">此研讨会的目标是将对混合现实应用程序感兴趣的学生和研究人员组合在一起。</span><span class="sxs-lookup"><span data-stu-id="e29f1-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="e29f1-119">该研讨会将为共享演示和应用程序提供场所, 并彼此了解, 以生成应用程序或将应用程序移植到混合现实。</span><span class="sxs-lookup"><span data-stu-id="e29f1-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="e29f1-120">我们鼓励在 (及其密友) 对象识别、手动和用户跟踪、活动识别、生成、3D 重构、场景理解、基于传感器的本地化、导航等主题上进行提交。</span><span class="sxs-lookup"><span data-stu-id="e29f1-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="e29f1-121">纸张提交</span><span class="sxs-lookup"><span data-stu-id="e29f1-121">Paper Submission</span></span>
* <span data-ttu-id="e29f1-122">纸张提交截止时间:5月17日</span><span class="sxs-lookup"><span data-stu-id="e29f1-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="e29f1-123">作者通知:5月24</span><span class="sxs-lookup"><span data-stu-id="e29f1-123">Notification to authors: May 24</span></span>

<span data-ttu-id="e29f1-124">提交的纸张应使用 CVPR 模板, 并限制为4页和引用。</span><span class="sxs-lookup"><span data-stu-id="e29f1-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="e29f1-125">此外, 我们鼓励作者展示其应用程序提交视频。</span><span class="sxs-lookup"><span data-stu-id="e29f1-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="e29f1-126">请注意, 允许提交以前发布的工作 (包括可接受到主要 CVPR 2019 会议的工作)。</span><span class="sxs-lookup"><span data-stu-id="e29f1-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="e29f1-127">可以将提交内容上传到 CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="e29f1-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="e29f1-128">将为研讨会中的口头演示文稿选择一小部分论文。</span><span class="sxs-lookup"><span data-stu-id="e29f1-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="e29f1-129">但是, 我们强烈建议所有作者在演示过程中显示其工作。</span><span class="sxs-lookup"><span data-stu-id="e29f1-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="e29f1-130">计划</span><span class="sxs-lookup"><span data-stu-id="e29f1-130">Schedule</span></span>
* <span data-ttu-id="e29f1-131">13:30-13:45:欢迎和打开备注。</span><span class="sxs-lookup"><span data-stu-id="e29f1-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="e29f1-132">13:45-14:15:**主题讨论**:盈利率. Marc Pollefeys,</span><span class="sxs-lookup"><span data-stu-id="e29f1-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="e29f1-133">词首HoloLens 上的 Egocentric 计算机视觉。</span><span class="sxs-lookup"><span data-stu-id="e29f1-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="e29f1-134">14:15-14:45:**主题讨论**:盈利率. Kris Kitani, Carnegie 卡内基梅隆大学。</span><span class="sxs-lookup"><span data-stu-id="e29f1-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="e29f1-135">词首Egocentric 活动和姿势预测。</span><span class="sxs-lookup"><span data-stu-id="e29f1-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="e29f1-136">14:45-15:15:**主题讨论**:Scripto美国 Liu 的一种技术。</span><span class="sxs-lookup"><span data-stu-id="e29f1-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="e29f1-137">词首利用增加的现实为盲人提供认知助手。</span><span class="sxs-lookup"><span data-stu-id="e29f1-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="e29f1-138">15:15-16:15:咖啡中断和演示。</span><span class="sxs-lookup"><span data-stu-id="e29f1-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="e29f1-139">16:15-16:45:**主题讨论**:盈利率. Kristen Grauman, 德克萨斯大学, 德克萨斯州</span><span class="sxs-lookup"><span data-stu-id="e29f1-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="e29f1-140">词首第一人员视频中的人机交互。</span><span class="sxs-lookup"><span data-stu-id="e29f1-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="e29f1-141">16:45-17:15:口头演示文稿:</span><span class="sxs-lookup"><span data-stu-id="e29f1-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="e29f1-142">通过 HoloLens, 可以轻松地进行注册-独立 orthopedic 导航。</span><span class="sxs-lookup"><span data-stu-id="e29f1-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="e29f1-143">果.</span><span class="sxs-lookup"><span data-stu-id="e29f1-143">F.</span></span> <span data-ttu-id="e29f1-144">Liebmann、Roner、Atzigen、von、Wanivenhaus、Neuhaus、Spirig、Scaramuzza、Sutter、Snedeker、Farshad、Furnstahl、、、。</span><span class="sxs-lookup"><span data-stu-id="e29f1-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="e29f1-145">通过使用 HoloLens 浏览, 学习立体声。</span><span class="sxs-lookup"><span data-stu-id="e29f1-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="e29f1-146">高.</span><span class="sxs-lookup"><span data-stu-id="e29f1-146">H.</span></span> <span data-ttu-id="e29f1-147">Zhan、Pekelny、Ulusoy。</span><span class="sxs-lookup"><span data-stu-id="e29f1-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="e29f1-148">17:15-17:30:最终备注。</span><span class="sxs-lookup"><span data-stu-id="e29f1-148">17:15-17:30: Final Remarks.</span></span>
