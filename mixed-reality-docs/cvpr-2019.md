---
title: 计算机视觉的 CVPR 2019 在混合现实耳机研讨会的应用程序
description: 概述和计划的计算机视觉应用程序混合现实耳机研讨会上年 6 月 2019 CVPR 大会上传递。
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: 事件、 研究模式、 cvpr、 计算机视觉、 研究、 HoloLens
ms.openlocfilehash: 138dda1e606ac1e34aa7237bd26bbb702befb71c
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 04/12/2019
ms.locfileid: "59590373"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="4f239-104">计算机视觉的混合的现实耳机的应用程序</span><span class="sxs-lookup"><span data-stu-id="4f239-104">Computer Vision Applications for Mixed Reality Headsets</span></span>
<span data-ttu-id="4f239-105">长时间海滩 (CA)-2019 年 6 月 17 日</span><span class="sxs-lookup"><span data-stu-id="4f239-105">Long Beach (CA) - June 17, 2019</span></span>

<span data-ttu-id="4f239-106">组织结合[CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="4f239-106">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

## <a name="organizers"></a><span data-ttu-id="4f239-107">组织者</span><span class="sxs-lookup"><span data-stu-id="4f239-107">Organizers</span></span>
* <span data-ttu-id="4f239-108">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="4f239-108">Marc Pollefeys</span></span>
* <span data-ttu-id="4f239-109">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="4f239-109">Federica Bogo</span></span>
* <span data-ttu-id="4f239-110">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="4f239-110">Johannes Schönberger</span></span>
* <span data-ttu-id="4f239-111">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="4f239-111">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="4f239-112">概述</span><span class="sxs-lookup"><span data-stu-id="4f239-112">Overview</span></span>

![预告图像](images/cvpr2019_teaser.jpg)

<span data-ttu-id="4f239-114">如 Microsoft HoloLens 混合的现实耳机变得越来越强大平台开发计算机视觉的应用程序。</span><span class="sxs-lookup"><span data-stu-id="4f239-114">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="4f239-115">HoloLens 研究模式允许在设备上的计算机视觉研究通过提供访问所有原始图像传感器流-包括深度和 ir。</span><span class="sxs-lookup"><span data-stu-id="4f239-115">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="4f239-116">因为自 2018 年 5 月以来研究模式现在可用，我们开始看到几个有趣的演示和要为 HoloLens 开发的应用程序。</span><span class="sxs-lookup"><span data-stu-id="4f239-116">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="4f239-117">此研讨会的目标是将组合在一起的学生和研究人员感兴趣计算机视觉的混合的现实应用程序。</span><span class="sxs-lookup"><span data-stu-id="4f239-117">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="4f239-118">该研讨会将提供共享演示和应用程序，并从其他生成了解某个地点或端口的应用程序混合现实。</span><span class="sxs-lookup"><span data-stu-id="4f239-118">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="4f239-119">我们鼓励主题上提交的 （自尊心构建以） 对象识别、 手和用户跟踪、 活动识别、 SLAM、 三维重建、 场景了解、 基于传感器的本地化、 导航和的详细信息。</span><span class="sxs-lookup"><span data-stu-id="4f239-119">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="4f239-120">纸张提交</span><span class="sxs-lookup"><span data-stu-id="4f239-120">Paper Submission</span></span>
* <span data-ttu-id="4f239-121">纸张提交截止日期：5 月 1</span><span class="sxs-lookup"><span data-stu-id="4f239-121">Paper submission deadline: May 1</span></span>
* <span data-ttu-id="4f239-122">向作者通知：5 月 15 日</span><span class="sxs-lookup"><span data-stu-id="4f239-122">Notification to authors: May 15</span></span>

<span data-ttu-id="4f239-123">纸张的提交应使用 CVPR 模板，但不限于 4 页，加上的引用。</span><span class="sxs-lookup"><span data-stu-id="4f239-123">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="4f239-124">此外，我们鼓励作者提交它展示了他们的应用程序的视频。</span><span class="sxs-lookup"><span data-stu-id="4f239-124">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="4f239-125">请注意 （包括工作接受向主要 CVPR 2019 会议） 允许提交以前已发布的工作。</span><span class="sxs-lookup"><span data-stu-id="4f239-125">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="4f239-126">提交可上载到 CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="4f239-126">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="4f239-127">将为该研讨会的口头演示选择论文的子集。</span><span class="sxs-lookup"><span data-stu-id="4f239-127">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="4f239-128">但是，我们强烈建议所有作者提供其演示会话期间的工作。</span><span class="sxs-lookup"><span data-stu-id="4f239-128">However, we strongly encourage all the authors to present their work during the demo session.</span></span>

<span data-ttu-id="4f239-129">_将使用特殊的-严格混合现实-奖品颁奖最佳论文。_</span><span class="sxs-lookup"><span data-stu-id="4f239-129">_The best papers will be awarded with a special -- rigorously mixed-reality -- prize._</span></span>

## <a name="schedule"></a><span data-ttu-id="4f239-130">计划</span><span class="sxs-lookup"><span data-stu-id="4f239-130">Schedule</span></span>
<span data-ttu-id="4f239-131">TBC.</span><span class="sxs-lookup"><span data-stu-id="4f239-131">TBC.</span></span>
