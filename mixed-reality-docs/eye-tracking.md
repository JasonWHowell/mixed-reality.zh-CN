---
title: 眼睛-注视
description: HoloLens 2 允许开发人员使用有关用户正在查看的信息的功能, 使开发人员能够在全息体验内实现新的上下文和人工理解。
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 眼睛跟踪, 混合现实, 输入, 眼睛, 眼睛, 眼睛
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387593"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="4f74f-104">目视-注视 HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="4f74f-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="4f74f-105">HoloLens 2 允许开发人员使用有关用户正在查看的信息的功能, 使开发人员能够在全息体验内实现新的上下文和人工理解。</span><span class="sxs-lookup"><span data-stu-id="4f74f-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="4f74f-106">本页告诉开发人员如何从各种用例的目视跟踪中获益, 以及在设计基于目视的用户界面时要查找的内容。</span><span class="sxs-lookup"><span data-stu-id="4f74f-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="4f74f-107">设备支持</span><span class="sxs-lookup"><span data-stu-id="4f74f-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="4f74f-108"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="4f74f-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="4f74f-109"><a href="hololens-hardware-details.md"><strong>HoloLens（第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="4f74f-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="4f74f-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="4f74f-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="4f74f-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></span><span class="sxs-lookup"><span data-stu-id="4f74f-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="4f74f-112">眼睛-注视</span><span class="sxs-lookup"><span data-stu-id="4f74f-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="4f74f-113">❌</span><span class="sxs-lookup"><span data-stu-id="4f74f-113">❌</span></span></td>
     <td><span data-ttu-id="4f74f-114">✔️</span><span class="sxs-lookup"><span data-stu-id="4f74f-114">✔️</span></span></td>
     <td><span data-ttu-id="4f74f-115">❌</span><span class="sxs-lookup"><span data-stu-id="4f74f-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="4f74f-116">用例</span><span class="sxs-lookup"><span data-stu-id="4f74f-116">Use cases</span></span>
<span data-ttu-id="4f74f-117">眼动跟踪可让应用程序实时跟踪用户正在注视的位置。</span><span class="sxs-lookup"><span data-stu-id="4f74f-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="4f74f-118">以下用例介绍了混合现实中的目视跟踪可能会发生的一些交互。</span><span class="sxs-lookup"><span data-stu-id="4f74f-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="4f74f-119">请记住,[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)对于使用目视跟踪提供几个有趣和强大的示例非常有用, 例如, 快速和轻松地支持目视的目标选项, 以及基于用户查看的内容。</span><span class="sxs-lookup"><span data-stu-id="4f74f-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="4f74f-120">用户意图</span><span class="sxs-lookup"><span data-stu-id="4f74f-120">User intent</span></span>    
<span data-ttu-id="4f74f-121">有关用户所在位置和内容的信息**为其他输入**提供了强大的上下文, 例如语音、动手和控制器。</span><span class="sxs-lookup"><span data-stu-id="4f74f-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="4f74f-122">可在各种任务中使用此信息。</span><span class="sxs-lookup"><span data-stu-id="4f74f-122">This can be used for various tasks.</span></span>
<span data-ttu-id="4f74f-123">例如,**在整个场景**中, 这种情况的范围包括: 只需查看一个全息影像[并显示 "](gaze-and-commit.md)选择" (还可以看到 "选择"), 或者说 "put ...", 然后查找用户要放置到的位置。全息图, 如 "...出现 "。</span><span class="sxs-lookup"><span data-stu-id="4f74f-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="4f74f-124">在[混合现实工具包 - 视线支持的目标选择](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合现实工具包 - 视线支持的目标定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中可以找到相关示例。</span><span class="sxs-lookup"><span data-stu-id="4f74f-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="4f74f-125">此外, 用户意向的示例可能包括使用用户查看的信息来增强使用所介绍的虚拟代理和交互式全息影像。</span><span class="sxs-lookup"><span data-stu-id="4f74f-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="4f74f-126">例如, 虚拟代理可能会根据当前查看的内容来调整可用选项及其行为。</span><span class="sxs-lookup"><span data-stu-id="4f74f-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="4f74f-127">隐式操作</span><span class="sxs-lookup"><span data-stu-id="4f74f-127">Implicit actions</span></span>
<span data-ttu-id="4f74f-128">隐式操作的类别与用户意图密切相关。</span><span class="sxs-lookup"><span data-stu-id="4f74f-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="4f74f-129">其思路是, 全息影像或用户界面元素以某种 instinctual 的方式做出反应, 甚至可能不会像用户同时与系统交互, 而是让系统和用户保持同步。例如,**基于眼睛的自动滚动**, 用户可在其中读取文本, 因为文本会继续与用户的眼睛一起滚动或流动。</span><span class="sxs-lookup"><span data-stu-id="4f74f-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with with the user's gaze.</span></span> <span data-ttu-id="4f74f-130">这种情况的一个关键方面是, 滚动速度可适应用户的读取速度。</span><span class="sxs-lookup"><span data-stu-id="4f74f-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="4f74f-131">另一个示例是**支持目视的缩放和平移**, 其中用户可以感觉到他或她的聚焦复杂度完全接近。</span><span class="sxs-lookup"><span data-stu-id="4f74f-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused o.</span></span> <span data-ttu-id="4f74f-132">触发缩放和控制缩放速度可以通过语音或手写输入来控制, 这对于向用户提供控制感受, 同时避免被淹没非常重要。</span><span class="sxs-lookup"><span data-stu-id="4f74f-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="4f74f-133">下面将更详细地讨论这些设计指南。</span><span class="sxs-lookup"><span data-stu-id="4f74f-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="4f74f-134">放大后, 用户可以顺利地执行操作, 例如, 街道的学习过程只需使用其眼睛来浏览其邻居即可。</span><span class="sxs-lookup"><span data-stu-id="4f74f-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="4f74f-135">[混合现实工具包 - 视线支持的导航](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)示例中可以找到此类交互的演示。</span><span class="sxs-lookup"><span data-stu-id="4f74f-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="4f74f-136">_隐式操作_的其他用例包括:</span><span class="sxs-lookup"><span data-stu-id="4f74f-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="4f74f-137">**智能通知：** 当你专心浏览某段内容时，突然弹出的通知是否让你觉得很恼火？</span><span class="sxs-lookup"><span data-stu-id="4f74f-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="4f74f-138">考虑到用户正在关注的内容, 你可以通过从当前 gazing 用户的位置偏移通知来更好地进行此体验。</span><span class="sxs-lookup"><span data-stu-id="4f74f-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="4f74f-139">这会限制干扰, 并在用户完成读取后自动将其关闭。</span><span class="sxs-lookup"><span data-stu-id="4f74f-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="4f74f-140">**体贴入微的全息影像：** 在 gazed 时, 会对影像进行细微反应。</span><span class="sxs-lookup"><span data-stu-id="4f74f-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="4f74f-141">这种情况的范围包括: 从稍微光亮的 UI 元素到缓慢的百花齐放花给虚拟宠物, 开始回顾用户, 或尝试避免在长时间的琢磨后出现用户的眼睛。</span><span class="sxs-lookup"><span data-stu-id="4f74f-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="4f74f-142">这种交互可能会在应用程序中提供更有趣的连接和满意度。</span><span class="sxs-lookup"><span data-stu-id="4f74f-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="4f74f-143">注意力跟踪</span><span class="sxs-lookup"><span data-stu-id="4f74f-143">Attention tracking</span></span>   
<span data-ttu-id="4f74f-144">有关用户所在位置或内容的信息是一个非常强大的工具, 可用于评估设计的可用性, 并确定有效工作流中的问题。</span><span class="sxs-lookup"><span data-stu-id="4f74f-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="4f74f-145">目视跟踪可视化和分析是各种应用程序领域的常见做法。</span><span class="sxs-lookup"><span data-stu-id="4f74f-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="4f74f-146">在 HoloLens 2 中, 我们提供了一种新的维度来理解, 因为3D 全息图可以放置在真实的上下文中并进行相应的评估。</span><span class="sxs-lookup"><span data-stu-id="4f74f-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="4f74f-147">[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供了用于记录和加载目视跟踪数据的基本示例, 以及如何对其进行可视化。</span><span class="sxs-lookup"><span data-stu-id="4f74f-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="4f74f-148">此区域中的其他应用程序可以包括:</span><span class="sxs-lookup"><span data-stu-id="4f74f-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="4f74f-149">**远程目视视觉视觉对象:** 可视化远程协作者正在寻找的内容, 以确保正确理解并遵循说明。</span><span class="sxs-lookup"><span data-stu-id="4f74f-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="4f74f-150">**用户调研：** 注意跟踪可用于探索初级用户与专家用户直观地分析内容的方式, 或者对复杂任务 (例如分析医疗数据或操作机械) 进行实时协调。</span><span class="sxs-lookup"><span data-stu-id="4f74f-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="4f74f-151">**训练模拟和性能监视：** 更有效地识别执行流中的瓶颈，实践并优化任务的执行。</span><span class="sxs-lookup"><span data-stu-id="4f74f-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="4f74f-152">**设计评估、广告和营销调查：** 在 evaluateing 网站和产品设计时, 目视跟踪是市场调查的常用工具。</span><span class="sxs-lookup"><span data-stu-id="4f74f-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluateing website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="4f74f-153">其他用例</span><span class="sxs-lookup"><span data-stu-id="4f74f-153">Additional use cases</span></span>
- <span data-ttu-id="4f74f-154">**游戏：** 是否曾经想过拥有超能力？</span><span class="sxs-lookup"><span data-stu-id="4f74f-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="4f74f-155">机会来了！</span><span class="sxs-lookup"><span data-stu-id="4f74f-155">Here's your chance!</span></span> <span data-ttu-id="4f74f-156">可以通过起始在 levitate 全息影像。</span><span class="sxs-lookup"><span data-stu-id="4f74f-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="4f74f-157">从眼睛发射激光束。</span><span class="sxs-lookup"><span data-stu-id="4f74f-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="4f74f-158">将敌人变成石子, 或将其冻结。</span><span class="sxs-lookup"><span data-stu-id="4f74f-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="4f74f-159">使用 X 光透视来扫描建筑物。</span><span class="sxs-lookup"><span data-stu-id="4f74f-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="4f74f-160">没有做不到，只有想不到！</span><span class="sxs-lookup"><span data-stu-id="4f74f-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="4f74f-161">**富有表现力的虚拟形象：** 目视跟踪通过使用实时跟踪日期对虚拟形象的眼睛进行动画处理, 使其看起来用户正在寻找的内容, 以更具表现力的方式跟踪三维头像。</span><span class="sxs-lookup"><span data-stu-id="4f74f-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live-eye tracking date to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="4f74f-162">它还能添加更多的眨单眼和眨眼表情。</span><span class="sxs-lookup"><span data-stu-id="4f74f-162">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="4f74f-163">**文本输入：** 目视跟踪可用作低工作量文本输入的替代方案, 特别是当语音或手不方便使用时。</span><span class="sxs-lookup"><span data-stu-id="4f74f-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="4f74f-164">眼动跟踪 API</span><span class="sxs-lookup"><span data-stu-id="4f74f-164">Eye tracking API</span></span>
<span data-ttu-id="4f74f-165">在深入了解有关目视目视交互的特定设计准则的详细信息之前, 我们想要简要指出 HoloLens 2 目视跟踪器 API 为开发人员提供的功能。</span><span class="sxs-lookup"><span data-stu-id="4f74f-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="4f74f-166">它提供一只眼睛的眼睛和方向, 提供大约_30 FPS_的数据。</span><span class="sxs-lookup"><span data-stu-id="4f74f-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 FPS_.</span></span> 

<span data-ttu-id="4f74f-167">预期的眼睛在 ca 中。</span><span class="sxs-lookup"><span data-stu-id="4f74f-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="4f74f-168">1.0-1.5 度 (以视觉角度表示的实际目标)。</span><span class="sxs-lookup"><span data-stu-id="4f74f-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="4f74f-169">预期存在轻微的不精确性，因此，应该围绕此下限值规划好一定的余隙。</span><span class="sxs-lookup"><span data-stu-id="4f74f-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="4f74f-170">下面会更详细地讨论此问题。</span><span class="sxs-lookup"><span data-stu-id="4f74f-170">We will discuss this more below.</span></span> <span data-ttu-id="4f74f-171">要准确运行眼动跟踪，每个用户需要完成眼动跟踪用户校准。</span><span class="sxs-lookup"><span data-stu-id="4f74f-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="4f74f-172">![2 米远处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="4f74f-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="4f74f-173">*以2米距离为目标的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="4f74f-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="4f74f-174">可以通过 "EyesPose" 访问[目视跟踪 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) 。</span><span class="sxs-lookup"><span data-stu-id="4f74f-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="4f74f-175">目视设计准则</span><span class="sxs-lookup"><span data-stu-id="4f74f-175">Eye-gaze design guidelines</span></span>
<span data-ttu-id="4f74f-176">构建利用快速移动的视线定位功能的交互式应用可能有难度。</span><span class="sxs-lookup"><span data-stu-id="4f74f-176">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="4f74f-177">在本部分中, 我们总结了在设计应用程序时要考虑的主要优点和挑战。</span><span class="sxs-lookup"><span data-stu-id="4f74f-177">In this section, we summarize the key advantages and challenges to take into account when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="4f74f-178">目视输入的优点</span><span class="sxs-lookup"><span data-stu-id="4f74f-178">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="4f74f-179">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="4f74f-179">**High speed pointing.**</span></span> <span data-ttu-id="4f74f-180">眼部肌肉在人体中是反应速度最快的肌肉。</span><span class="sxs-lookup"><span data-stu-id="4f74f-180">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="4f74f-181">**不费力。**</span><span class="sxs-lookup"><span data-stu-id="4f74f-181">**Low effort.**</span></span> <span data-ttu-id="4f74f-182">几乎没有任何身体动作。</span><span class="sxs-lookup"><span data-stu-id="4f74f-182">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="4f74f-183">**隐含性。**</span><span class="sxs-lookup"><span data-stu-id="4f74f-183">**Implicitness.**</span></span> <span data-ttu-id="4f74f-184">用户通常会将其描述为 "构思阅读", 有关用户的目视变动的信息使系统可以知道用户打算参与哪个目标。</span><span class="sxs-lookup"><span data-stu-id="4f74f-184">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="4f74f-185">**备选的输入通道。**</span><span class="sxs-lookup"><span data-stu-id="4f74f-185">**Alternative input channel.**</span></span> <span data-ttu-id="4f74f-186">眼睛可为用户提供强大的支持输入, 并根据用户的手眼协调从用户的经验中生成。</span><span class="sxs-lookup"><span data-stu-id="4f74f-186">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="4f74f-187">**视觉注意力。**</span><span class="sxs-lookup"><span data-stu-id="4f74f-187">**Visual attention.**</span></span> <span data-ttu-id="4f74f-188">另一个重要的优点是可以推断出用户正在关注的内容。</span><span class="sxs-lookup"><span data-stu-id="4f74f-188">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="4f74f-189">这可以帮助不同的应用程序领域, 从更有效地评估不同设计, 到协助的用户界面, 增加了社交提示以进行远程通信。</span><span class="sxs-lookup"><span data-stu-id="4f74f-189">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="4f74f-190">简而言之, 使用眼睛眼睛作为输入可提供快速且简单的上下文信号。</span><span class="sxs-lookup"><span data-stu-id="4f74f-190">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="4f74f-191">与其他输入 (如*语音*和*手动*输入) 相结合时, 此功能特别强大, 可以确认用户的意图。</span><span class="sxs-lookup"><span data-stu-id="4f74f-191">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="4f74f-192">眼睛为输入的挑战</span><span class="sxs-lookup"><span data-stu-id="4f74f-192">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="4f74f-193">如果有大量的强大功能, 就有了许多责任。</span><span class="sxs-lookup"><span data-stu-id="4f74f-193">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="4f74f-194">虽然眼睛可用于创建符合用户体验, thata 使你感觉像是 superhero, 但是, 了解这一点也很重要。</span><span class="sxs-lookup"><span data-stu-id="4f74f-194">While eye-gaze can be used to create satisfying user experiences thata makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="4f74f-195">下面讨论了一些需要考虑的挑战, 以及如何解决这些*难题*:</span><span class="sxs-lookup"><span data-stu-id="4f74f-195">The following discusses some *challenges* to take into account as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="4f74f-196">**眼睛为 "始终打开"** 打开眼睛护盖后, 眼睛开始 fixating 环境中的东西。</span><span class="sxs-lookup"><span data-stu-id="4f74f-196">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="4f74f-197">对每个外观进行操作并意外发出操作, 因为您查看的内容太长会导致 unsatisfying 体验。</span><span class="sxs-lookup"><span data-stu-id="4f74f-197">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="4f74f-198">这就是我们建议你将眼睛与*声音命令*、*笔势*、*按钮单击*或扩展停留结合起来以触发选择目标的原因。</span><span class="sxs-lookup"><span data-stu-id="4f74f-198">This is why we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="4f74f-199">此解决方案还允许使用一种模式, 在该模式下, 用户可以自由地查找, 而不会因触发某些事情而 involuntarily。</span><span class="sxs-lookup"><span data-stu-id="4f74f-199">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="4f74f-200">设计视觉和听觉反馈（只需注视某个目标）时，也应考虑到此问题。</span><span class="sxs-lookup"><span data-stu-id="4f74f-200">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="4f74f-201">不要使用即时弹出式效果或惊悚的声音来让用户感到不知所措。</span><span class="sxs-lookup"><span data-stu-id="4f74f-201">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="4f74f-202">个很微妙为 key。</span><span class="sxs-lookup"><span data-stu-id="4f74f-202">Subtlety is key.</span></span> <span data-ttu-id="4f74f-203">稍后在谈到设计建议时，我们会进一步讨论一些最佳做法。</span><span class="sxs-lookup"><span data-stu-id="4f74f-203">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="4f74f-204">**观察与控制**假设您想要在墙壁上精确地伸直照片。</span><span class="sxs-lookup"><span data-stu-id="4f74f-204">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="4f74f-205">你会参照它的边框和四周，检查它是否平齐。</span><span class="sxs-lookup"><span data-stu-id="4f74f-205">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="4f74f-206">现在, 如果您想要使用眼睛作为输入来移动图片, 则可以想象出如何实现此目的。</span><span class="sxs-lookup"><span data-stu-id="4f74f-206">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="4f74f-207">有点难度，对不对？</span><span class="sxs-lookup"><span data-stu-id="4f74f-207">Difficult, isn't it?</span></span> <span data-ttu-id="4f74f-208">这介绍了输入和控制需要时, 眼睛的双重角色。</span><span class="sxs-lookup"><span data-stu-id="4f74f-208">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="4f74f-209">**点击之前离开目标：** 对于快速目标选择, 研究表明, 用户的眼睛可以在结束手动单击之前继续进行 (例如, airtap)。</span><span class="sxs-lookup"><span data-stu-id="4f74f-209">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="4f74f-210">因此, 必须特别注意的是, 将快速目视眼睛的信号与慢速控制输入 (例如语音、双手、控制器) 进行同步。</span><span class="sxs-lookup"><span data-stu-id="4f74f-210">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="4f74f-211">**小目标：** 当您尝试读取只是太小而无法阅读的文本时, 您是否知道这种感觉？</span><span class="sxs-lookup"><span data-stu-id="4f74f-211">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortable?</span></span> <span data-ttu-id="4f74f-212">这会使您感到非常紧张, 因为您尝试重新调整您的眼睛, 使您能够更好地专注。</span><span class="sxs-lookup"><span data-stu-id="4f74f-212">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="4f74f-213">当你强制用户使用目视目标选择在你的应用程序中太小的目标时, 你可以在用户中调用这种感觉。</span><span class="sxs-lookup"><span data-stu-id="4f74f-213">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="4f74f-214">在设计方面，为了给用户建立一种愉悦舒适的体验，我们建议目标至少在 2° 的视角范围内，最好是再大一些。</span><span class="sxs-lookup"><span data-stu-id="4f74f-214">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="4f74f-215">**眼睛不规则的运动**我们的眼睛执行从固定到固定的快速移动。</span><span class="sxs-lookup"><span data-stu-id="4f74f-215">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="4f74f-216">观察录制的眼部运动扫描路径时你会发现，这些路径看起来是不规则的。</span><span class="sxs-lookup"><span data-stu-id="4f74f-216">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="4f74f-217">与头部跟踪视线和手部运动相比，眼睛的移动速度飞快，是本能跳动的。</span><span class="sxs-lookup"><span data-stu-id="4f74f-217">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="4f74f-218">**跟踪可靠性：** 当眼睛在光线变化的环境中适应新的条件时，眼动跟踪准确度可能会略有下降。</span><span class="sxs-lookup"><span data-stu-id="4f74f-218">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="4f74f-219">虽然这应该不会影响应用程序的设计, 因为准确性应该在2°限制范围内, 因此, 用户可能需要运行其他校准。</span><span class="sxs-lookup"><span data-stu-id="4f74f-219">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to run another calibration.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="4f74f-220">设计建议</span><span class="sxs-lookup"><span data-stu-id="4f74f-220">Design recommendations</span></span>
<span data-ttu-id="4f74f-221">下面是基于目视输入的所述优点和挑战的特定设计建议列表:</span><span class="sxs-lookup"><span data-stu-id="4f74f-221">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="4f74f-222">**眼睛! = 机头:**</span><span class="sxs-lookup"><span data-stu-id="4f74f-222">**Eye-gaze != Head-gaze:**</span></span>
    - <span data-ttu-id="4f74f-223">**考虑快速且不规则的眼部运动是否适合你的输入任务：** 虽然我们的快速和不规则的眼睛非常适合于在我们的视图 (FoV) 领域快速选择目标, 但它不适用于需要平滑输入轨迹的任务 (例如, 绘制或 encircling 批注)。</span><span class="sxs-lookup"><span data-stu-id="4f74f-223">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view (FoV), it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="4f74f-224">在这种情况下，应该首选手部或头部指向。</span><span class="sxs-lookup"><span data-stu-id="4f74f-224">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="4f74f-225">**避免直接将某些内容附加到用户的眼睛, 如滑块或光标。**</span><span class="sxs-lookup"><span data-stu-id="4f74f-225">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="4f74f-226">如果是游标, 这可能会导致 "fleeing cursor" 效果, 原因是预计的眼睛眼睛略有偏差。</span><span class="sxs-lookup"><span data-stu-id="4f74f-226">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="4f74f-227">如果是滑块, 则它可能与用眼睛控制滑块的双角色冲突, 同时也需要检查对象是否位于正确的位置。</span><span class="sxs-lookup"><span data-stu-id="4f74f-227">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="4f74f-228">简而言之, 用户可能会被淹没和分散注意力, 尤其是在信号对于该用户不精确的情况下。</span><span class="sxs-lookup"><span data-stu-id="4f74f-228">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="4f74f-229">**将眼睛与其他输入组合在一起:** 将眼睛跟踪与其他输入 (如手势、语音命令或按钮按下) 的集成具有以下优点:</span><span class="sxs-lookup"><span data-stu-id="4f74f-229">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="4f74f-230">**可以自由观察：** 考虑到我们的主要角色是观察我们的环境, 这是一项重要的用户, 而不触发任何 (视觉、听觉等) 反馈或操作。</span><span class="sxs-lookup"><span data-stu-id="4f74f-230">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="4f74f-231">将目视跟踪与其他输入控件结合起来允许在目视跟踪观察和输入控制模式之间平稳过渡。</span><span class="sxs-lookup"><span data-stu-id="4f74f-231">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="4f74f-232">**强大的上下文提供程序：** 使用有关用户在 uttering 语音命令或执行手手势时所处的位置和内容的信息, 可以在视图字段间无缝排列输入。</span><span class="sxs-lookup"><span data-stu-id="4f74f-232">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="4f74f-233">例如：发出“放在这里”语音命令后，只需注视某个目标和目的地，就能快速顺畅地在场景中选择和放置全息影像。</span><span class="sxs-lookup"><span data-stu-id="4f74f-233">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="4f74f-234">**同步多模输入的需求（“点击之前离开”问题）：** 将快速目视运动与更复杂的附加输入 (例如长的语音命令或手势) 相结合, 就能在完成附加输入命令之前继续眼睛的风险。</span><span class="sxs-lookup"><span data-stu-id="4f74f-234">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="4f74f-235">因此，如果你要创建自己的输入控件（例如自定义手势），请务必记录此输入的发生时间或近似持续时间，使之与用户过去注视的物件相关联。</span><span class="sxs-lookup"><span data-stu-id="4f74f-235">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="4f74f-236">**眼动追踪输入的微妙反馈：** 当查看目标以指示系统正在按预期工作时提供反馈, 但应保持微妙, 这非常有用。</span><span class="sxs-lookup"><span data-stu-id="4f74f-236">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended, but should be kept subtle.</span></span> <span data-ttu-id="4f74f-237">这可能包括缓慢混合、放大和缩小、视觉对象突出显示或执行其他细微目标行为 (如缓慢增加目标), 以指示系统正确检测到用户正在查看目标而不不必要地中断用户的当前工作流。</span><span class="sxs-lookup"><span data-stu-id="4f74f-237">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="4f74f-238">**避免强制使用非自然的眼部运动作为输入：** 不要强制用户执行特定的目视运动 (注视手势) 来触发应用程序中的操作。</span><span class="sxs-lookup"><span data-stu-id="4f74f-238">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="4f74f-239">**考虑不精确性：** 我们区分对用户显而易见的两种类型的 imprecisions: 偏移和抖动。</span><span class="sxs-lookup"><span data-stu-id="4f74f-239">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="4f74f-240">解决偏移量的最简单方法是提供足够大的目标来与进行交互。</span><span class="sxs-lookup"><span data-stu-id="4f74f-240">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="4f74f-241">建议使用大于2°的视觉角度作为参考。</span><span class="sxs-lookup"><span data-stu-id="4f74f-241">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="4f74f-242">例如, 当您拉伸 arm 时, 缩略图约为2°。</span><span class="sxs-lookup"><span data-stu-id="4f74f-242">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="4f74f-243">因此，我们的指导如下：</span><span class="sxs-lookup"><span data-stu-id="4f74f-243">This leads to the following guidance:</span></span>
    - <span data-ttu-id="4f74f-244">不要强制用户选择 "小目标"。</span><span class="sxs-lookup"><span data-stu-id="4f74f-244">Do not force users to select tiny targets.</span></span> <span data-ttu-id="4f74f-245">研究表明, 如果目标足够大, 并且系统设计良好, 则用户会将其交互描述为轻松和神奇。</span><span class="sxs-lookup"><span data-stu-id="4f74f-245">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="4f74f-246">如果目标太小，则用户就会将体验描述为费力、令人沮丧。</span><span class="sxs-lookup"><span data-stu-id="4f74f-246">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="4f74f-247">请参阅</span><span class="sxs-lookup"><span data-stu-id="4f74f-247">See also</span></span>
* [<span data-ttu-id="4f74f-248">头部凝视并提交</span><span class="sxs-lookup"><span data-stu-id="4f74f-248">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="4f74f-249">在 DirectX 中的打印头和眼睛</span><span class="sxs-lookup"><span data-stu-id="4f74f-249">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="4f74f-250">目视看 Unity (混合现实工具包)</span><span class="sxs-lookup"><span data-stu-id="4f74f-250">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="4f74f-251">手势</span><span class="sxs-lookup"><span data-stu-id="4f74f-251">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="4f74f-252">语音输入</span><span class="sxs-lookup"><span data-stu-id="4f74f-252">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="4f74f-253">运动控制器</span><span class="sxs-lookup"><span data-stu-id="4f74f-253">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="4f74f-254">舒适</span><span class="sxs-lookup"><span data-stu-id="4f74f-254">Comfort</span></span>](comfort.md)
