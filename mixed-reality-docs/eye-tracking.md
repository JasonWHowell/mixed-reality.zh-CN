---
title: 眼动跟踪
description: HoloLens 2 允许开发人员使用有关用户正在查看的内容的信息，从而实现全新的上下文和人工理解。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 眼睛跟踪，混合现实，输入，眼睛，校准
ms.openlocfilehash: 63520ee8d7d3ce73405776fccc62290cbbadd0a8
ms.sourcegitcommit: 2e54d0aff91dc31aa0020c865dada3ae57ae0ffc
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 11/06/2019
ms.locfileid: "73641143"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="a1e41-104">HoloLens 2 中的眼动跟踪</span><span class="sxs-lookup"><span data-stu-id="a1e41-104">Eye tracking on HoloLens 2</span></span>

![MRTK 中的眼睛跟踪演示](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="a1e41-106">HoloLens 2 允许开发人员使用有关用户正在查看的内容的信息，从而实现全新的上下文和人工理解。</span><span class="sxs-lookup"><span data-stu-id="a1e41-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="a1e41-107">此页概述了面向开发人员和设计人员的这项新功能，这些功能可让开发人员和设计人员从各种用例和基本开发人员指南中获益。</span><span class="sxs-lookup"><span data-stu-id="a1e41-107">This page provides an overview of this new capability to developers and designers on how they can benefit from eye tracking for various use cases and basic developer guidance.</span></span> 

### <a name="device-support"></a><span data-ttu-id="a1e41-108">设备支持</span><span class="sxs-lookup"><span data-stu-id="a1e41-108">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="a1e41-109"><strong>具有</strong></span><span class="sxs-lookup"><span data-stu-id="a1e41-109"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="a1e41-110"><a href="hololens-hardware-details.md"><strong>HoloLens（第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="a1e41-110"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="a1e41-111"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="a1e41-111"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="a1e41-112"><a href="immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></span><span class="sxs-lookup"><span data-stu-id="a1e41-112"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="a1e41-113">眼睛-注视</span><span class="sxs-lookup"><span data-stu-id="a1e41-113">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="a1e41-114">✔️</span><span class="sxs-lookup"><span data-stu-id="a1e41-114">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="calibration"></a><span data-ttu-id="a1e41-115">校准</span><span class="sxs-lookup"><span data-stu-id="a1e41-115">Calibration</span></span> 
<span data-ttu-id="a1e41-116">为了使目视跟踪能准确地工作，每个用户都需要经历[跟踪用户校准](calibration.md)，用户必须查看一组全息目标。</span><span class="sxs-lookup"><span data-stu-id="a1e41-116">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="a1e41-117">这允许设备调整系统，以便为用户提供更舒适和更高的质量查看体验，并确保同时进行准确的目视跟踪。</span><span class="sxs-lookup"><span data-stu-id="a1e41-117">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="a1e41-118">目视跟踪应该适用于大多数用户，但在极少数情况下，用户可能无法成功校准。</span><span class="sxs-lookup"><span data-stu-id="a1e41-118">Eye tracking should work for most users, but there are rare cases in which a user might not be able to calibrate successfully.</span></span> <span data-ttu-id="a1e41-119">校准可能因多种原因而失败，其中包括但不限于：</span><span class="sxs-lookup"><span data-stu-id="a1e41-119">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="a1e41-120">用户以前选择退出校准过程</span><span class="sxs-lookup"><span data-stu-id="a1e41-120">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="a1e41-121">用户已分散注意力，未遵循校准目标</span><span class="sxs-lookup"><span data-stu-id="a1e41-121">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="a1e41-122">用户具有特定类型的 contact 重用功能区和眼镜，其中系统尚不支持</span><span class="sxs-lookup"><span data-stu-id="a1e41-122">The user has certain types of contact lenses and glasses which the system doesn't yet support</span></span> 
* <span data-ttu-id="a1e41-123">用户具有某些眼睛 physiology、目视的状况，或者系统尚不支持的目视外科</span><span class="sxs-lookup"><span data-stu-id="a1e41-123">The user has certain eye physiology, eye conditions or had eye surgery which the system doesn't yet support</span></span>  
* <span data-ttu-id="a1e41-124">外部因素抑制了可靠的眼睛跟踪，如污迹面板上的污迹、眼镜、强烈的直接阳光和 occlusions，因为眼睛正面的头发</span><span class="sxs-lookup"><span data-stu-id="a1e41-124">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="a1e41-125">开发人员应确保向用户提供对目视跟踪数据可能不可用的适当支持（无法成功校准）。</span><span class="sxs-lookup"><span data-stu-id="a1e41-125">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who are not able to calibrate successfully).</span></span> <span data-ttu-id="a1e41-126">我们已在本页底部的部分中提供了有关后备解决方案的建议。</span><span class="sxs-lookup"><span data-stu-id="a1e41-126">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="a1e41-127">若要了解有关校准的详细信息以及如何确保流畅的体验，请查看我们的[眼睛跟踪用户校准](calibration.md)页面。</span><span class="sxs-lookup"><span data-stu-id="a1e41-127">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="a1e41-128">可用的目视跟踪数据</span><span class="sxs-lookup"><span data-stu-id="a1e41-128">Available eye tracking data</span></span>
<span data-ttu-id="a1e41-129">在深入了解有关目视输入的特定用例的详细信息之前，我们想要简要指出 HoloLens 2[目视跟踪 API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose)提供的功能。</span><span class="sxs-lookup"><span data-stu-id="a1e41-129">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="a1e41-130">开发人员可在大约_30 FPS （30 Hz）_ 的情况中访问一只眼睛眼睛（看原点和方向）。</span><span class="sxs-lookup"><span data-stu-id="a1e41-130">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="a1e41-131">有关如何访问目视跟踪数据的更多详细信息，请参阅我们的开发人员指南了解如何使用[DirectX 中的眼睛](gaze-in-directx.md)，并看看[Unity](https://aka.ms/mrtk-eyes)。</span><span class="sxs-lookup"><span data-stu-id="a1e41-131">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="a1e41-132">围绕实际目标围绕视觉角度，眼睛的眼睛约在1.5 度内（请参阅下图）。</span><span class="sxs-lookup"><span data-stu-id="a1e41-132">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="a1e41-133">由于预期的轻微 imprecisions，开发人员应计划围绕此下限值（例如 2.0-3.0 度）的某些边距，这可能会导致更舒适的体验。</span><span class="sxs-lookup"><span data-stu-id="a1e41-133">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="a1e41-134">下面将详细介绍如何处理小目标的选择。</span><span class="sxs-lookup"><span data-stu-id="a1e41-134">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="a1e41-135">要准确运行眼动跟踪，每个用户需要完成眼动跟踪用户校准。</span><span class="sxs-lookup"><span data-stu-id="a1e41-135">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="a1e41-136">![2 米远处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="a1e41-136">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="a1e41-137">*以2米距离为目标的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="a1e41-137">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="a1e41-138">用例</span><span class="sxs-lookup"><span data-stu-id="a1e41-138">Use cases</span></span>
<span data-ttu-id="a1e41-139">眼动跟踪可让应用程序实时跟踪用户正在注视的位置。</span><span class="sxs-lookup"><span data-stu-id="a1e41-139">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="a1e41-140">以下用例描述了在混合现实中，在 HoloLens 2 上使用目视跟踪可能会发生的一些交互。</span><span class="sxs-lookup"><span data-stu-id="a1e41-140">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="a1e41-141">请注意，这些用例不是全息 Shell 体验的一部分（即启动 HoloLens 2 时显示的接口）。</span><span class="sxs-lookup"><span data-stu-id="a1e41-141">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="a1e41-142">你可以在[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)中试用其中一些功能，其中提供了几个有趣且功能强大的示例来使用目视跟踪，例如快速而轻松地使用目视跟踪的目标选项以及基于文本自动滚动用户查看的内容。</span><span class="sxs-lookup"><span data-stu-id="a1e41-142">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="a1e41-143">用户意图</span><span class="sxs-lookup"><span data-stu-id="a1e41-143">User intent</span></span>    
<span data-ttu-id="a1e41-144">有关用户所在位置和内容的信息**为其他输入**提供了强大的上下文，例如语音、动手和控制器。</span><span class="sxs-lookup"><span data-stu-id="a1e41-144">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="a1e41-145">可在各种任务中使用此信息。</span><span class="sxs-lookup"><span data-stu-id="a1e41-145">This can be used for various tasks.</span></span>
<span data-ttu-id="a1e41-146">例如，这种情况的范围包括：只需查看全息影像并显示 *"选择"* （另请参阅 "注视" 和 "[提交](gaze-and-commit.md)"），或者说 *"put ..."* ，然后查看用户想要放置全息图，并说 *".。。出现 "* 。</span><span class="sxs-lookup"><span data-stu-id="a1e41-146">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="a1e41-147">在[混合现实工具包 - 视线支持的目标选择](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合现实工具包 - 视线支持的目标定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中可以找到相关示例。</span><span class="sxs-lookup"><span data-stu-id="a1e41-147">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="a1e41-148">此外，用户意向的示例可能包括使用用户查看的信息来增强使用所介绍的虚拟代理和交互式全息影像。</span><span class="sxs-lookup"><span data-stu-id="a1e41-148">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="a1e41-149">例如，虚拟代理可能会根据当前查看的内容来调整可用选项及其行为。</span><span class="sxs-lookup"><span data-stu-id="a1e41-149">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="a1e41-150">隐式操作</span><span class="sxs-lookup"><span data-stu-id="a1e41-150">Implicit actions</span></span>
<span data-ttu-id="a1e41-151">隐式操作的类别与用户意图密切相关。</span><span class="sxs-lookup"><span data-stu-id="a1e41-151">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="a1e41-152">其思路是，全息影像或用户界面元素会以 instinctual 的方式做出反应，甚至可能不会像用户同时与系统交互，而是让系统和用户保持同步。例如，**基于目视的自动滚动**，用户可以在其中读取长文本，该文本会在用户进入文本框底部时自动开始滚动，以使用户处于阅读流中而不抬起手指。</span><span class="sxs-lookup"><span data-stu-id="a1e41-152">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="a1e41-153">这种情况的一个关键方面是，滚动速度可适应用户的读取速度。</span><span class="sxs-lookup"><span data-stu-id="a1e41-153">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="a1e41-154">另一个例子就是**受支持的目视缩放和平移**，用户可以感觉到他或她所关注的内容完全接近。</span><span class="sxs-lookup"><span data-stu-id="a1e41-154">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="a1e41-155">触发缩放和控制缩放速度可以通过语音或手写输入来控制，这对于向用户提供控制感受，同时避免被淹没非常重要。</span><span class="sxs-lookup"><span data-stu-id="a1e41-155">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="a1e41-156">下面将更详细地讨论这些设计注意事项。</span><span class="sxs-lookup"><span data-stu-id="a1e41-156">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="a1e41-157">放大后，用户可以顺利地执行操作，例如，街道的学习过程只需使用其眼睛来浏览其邻居即可。</span><span class="sxs-lookup"><span data-stu-id="a1e41-157">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="a1e41-158">[混合现实工具包 - 视线支持的导航](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)示例中可以找到此类交互的演示。</span><span class="sxs-lookup"><span data-stu-id="a1e41-158">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="a1e41-159">隐式操作的其他用例包括：</span><span class="sxs-lookup"><span data-stu-id="a1e41-159">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="a1e41-160">**智能通知：** 如果在你要查找的位置，通知弹出的厌恶，</span><span class="sxs-lookup"><span data-stu-id="a1e41-160">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="a1e41-161">考虑到用户正在关注的内容，你可以通过从当前 gazing 用户的位置偏移通知来更好地进行此体验。</span><span class="sxs-lookup"><span data-stu-id="a1e41-161">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="a1e41-162">这会限制干扰，并在用户完成读取后自动将其关闭。</span><span class="sxs-lookup"><span data-stu-id="a1e41-162">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="a1e41-163">**留心全息影像：** 在 gazed 时，会对影像进行细微反应。</span><span class="sxs-lookup"><span data-stu-id="a1e41-163">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="a1e41-164">这可能包括稍微光亮的 UI 元素，这是一种对虚拟狗的缓慢百花齐放花，开始回顾用户并 wagging 其尾部。</span><span class="sxs-lookup"><span data-stu-id="a1e41-164">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="a1e41-165">这种交互可能会在应用程序中提供更有趣的连接和满意度。</span><span class="sxs-lookup"><span data-stu-id="a1e41-165">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="a1e41-166">注意力跟踪</span><span class="sxs-lookup"><span data-stu-id="a1e41-166">Attention tracking</span></span>   
<span data-ttu-id="a1e41-167">有关用户所在位置或内容的信息是一个非常强大的工具，可用于评估设计的可用性，并确定有效工作流中的问题。</span><span class="sxs-lookup"><span data-stu-id="a1e41-167">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="a1e41-168">目视跟踪可视化和分析是各种应用程序领域的常见做法。</span><span class="sxs-lookup"><span data-stu-id="a1e41-168">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="a1e41-169">在 HoloLens 2 中，我们提供了一种新的维度来理解，因为3D 全息图可以放置在真实的上下文中并进行相应的评估。</span><span class="sxs-lookup"><span data-stu-id="a1e41-169">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="a1e41-170">[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供了用于记录和加载目视跟踪数据的基本示例，以及如何对其进行可视化。</span><span class="sxs-lookup"><span data-stu-id="a1e41-170">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>

<span data-ttu-id="a1e41-171">此领域的其他应用场景包括：</span><span class="sxs-lookup"><span data-stu-id="a1e41-171">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="a1e41-172">**远程目视视觉视觉对象：** 可视化远程协作者正在寻找的内容，以增加共享理解。</span><span class="sxs-lookup"><span data-stu-id="a1e41-172">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to increase shared understanding.</span></span>
-   <span data-ttu-id="a1e41-173">**用户研究研究：** 关注跟踪有助于更好地了解我们如何感知和与我们的环境接洽，这有助于更好地 instinctual 人工意向模型，以实现更高的人工计算机交互。</span><span class="sxs-lookup"><span data-stu-id="a1e41-173">**User research studies:** Attention tracking can help better understanding how we perceive and engage with our environment which may help in better human intent models for more instinctual human-computer-interactions.</span></span> 
-   <span data-ttu-id="a1e41-174">**培训：** 通过更好地了解专家的视觉搜索模式和对复杂任务（例如，用于分析医疗数据或操作机械）的密切关注，改进了新手的培训。</span><span class="sxs-lookup"><span data-stu-id="a1e41-174">**Training:** Improved training of novices by better understanding experts' visual search patterns and their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="a1e41-175">**设计评估和市场研究：** 在评估网站和产品设计时，目视跟踪是一种用于市场研究的常用工具。</span><span class="sxs-lookup"><span data-stu-id="a1e41-175">**Design evaluations and market research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span> <span data-ttu-id="a1e41-176">使用 HoloLens 2，可以通过将数字产品设计变型与物理环境合并来将此扩展到3D 空间。</span><span class="sxs-lookup"><span data-stu-id="a1e41-176">With HoloLens 2, we can extend this to 3D spaces by merging digital product design variants with the physical environment.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="a1e41-177">其他用例</span><span class="sxs-lookup"><span data-stu-id="a1e41-177">Additional use cases</span></span>
- <span data-ttu-id="a1e41-178">**游戏：** 您是否曾经想过强大？</span><span class="sxs-lookup"><span data-stu-id="a1e41-178">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="a1e41-179">机会来了！</span><span class="sxs-lookup"><span data-stu-id="a1e41-179">Here's your chance!</span></span> <span data-ttu-id="a1e41-180">可以通过起始在 levitate 全息影像。</span><span class="sxs-lookup"><span data-stu-id="a1e41-180">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="a1e41-181">从眼睛开始拍摄激光光标，试用[RoboRaid](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)</span><span class="sxs-lookup"><span data-stu-id="a1e41-181">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="a1e41-182">将敌人变成石子，或将其冻结。</span><span class="sxs-lookup"><span data-stu-id="a1e41-182">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="a1e41-183">使用 X 光透视来扫描建筑物。</span><span class="sxs-lookup"><span data-stu-id="a1e41-183">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="a1e41-184">没有做不到，只有想不到！</span><span class="sxs-lookup"><span data-stu-id="a1e41-184">Your imagination is the limit!</span></span>
<span data-ttu-id="a1e41-185">请注意，用户要了解详细信息，请注意我们的[基于眼睛的输入设计准则](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="a1e41-185">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="a1e41-186">**表现力头像：** 目视跟踪通过使用实时眼睛跟踪数据来使真实的头像显示用户正在查看的内容，以更有意义的3D 头像为目标。</span><span class="sxs-lookup"><span data-stu-id="a1e41-186">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="a1e41-187">**文本条目：** 目视跟踪可用作低工作量文本输入的替代方案，特别是当语音或手不方便使用时。</span><span class="sxs-lookup"><span data-stu-id="a1e41-187">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="a1e41-188">使用目视查看交互</span><span class="sxs-lookup"><span data-stu-id="a1e41-188">Using eye-gaze for interaction</span></span>
<span data-ttu-id="a1e41-189">构建充分利用快速移动目视目标的交互可能会很困难。</span><span class="sxs-lookup"><span data-stu-id="a1e41-189">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="a1e41-190">一方面，眼睛的移动速度非常快，你需要小心地使用眼睛眼睛，因为否则用户可能会发现体验太多或分散注意力。</span><span class="sxs-lookup"><span data-stu-id="a1e41-190">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="a1e41-191">另一方面，你还可以创建真正的神奇体验，将激发你的用户！</span><span class="sxs-lookup"><span data-stu-id="a1e41-191">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="a1e41-192">若要帮助你了解关键优势、挑战和设计建议，了解如何进行[互动](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="a1e41-192">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 

<br>
 
## <a name="fallback-solutions-when-eye-tracking-is-not-available"></a><span data-ttu-id="a1e41-193">目视跟踪不可用时的回退解决方案</span><span class="sxs-lookup"><span data-stu-id="a1e41-193">Fallback solutions when eye tracking is not available</span></span>
<span data-ttu-id="a1e41-194">在极少数情况下，目视跟踪数据可能不可用。</span><span class="sxs-lookup"><span data-stu-id="a1e41-194">In rare cases eye tracking data might not be available.</span></span>
<span data-ttu-id="a1e41-195">这可能是由于下面列出了最常见的原因：</span><span class="sxs-lookup"><span data-stu-id="a1e41-195">This can be due to different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="a1e41-196">系统未能[校准用户](calibration.md)。</span><span class="sxs-lookup"><span data-stu-id="a1e41-196">The system failed to [calibrate the user](calibration.md).</span></span>
* <span data-ttu-id="a1e41-197">用户跳过了[校准](calibration.md)。</span><span class="sxs-lookup"><span data-stu-id="a1e41-197">The user skipped the [calibration](calibration.md).</span></span>   
* <span data-ttu-id="a1e41-198">用户进行了校准，但决定不向应用程序授予使用其眼睛跟踪数据的权限。</span><span class="sxs-lookup"><span data-stu-id="a1e41-198">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="a1e41-199">用户具有唯一的眼镜，或系统尚不支持的某种眼睛状态。</span><span class="sxs-lookup"><span data-stu-id="a1e41-199">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>    
* <span data-ttu-id="a1e41-200">外部因素抑制了一种可靠的眼睛跟踪，如在眼睛前面的头发上出现污迹面板或眼镜、强烈直接阳光和 occlusions。</span><span class="sxs-lookup"><span data-stu-id="a1e41-200">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>   
<span data-ttu-id="a1e41-201">因此，开发人员应确保为这些用户提供适当的后备支持。</span><span class="sxs-lookup"><span data-stu-id="a1e41-201">Hence, developers should ensure that there is appropriate fallback support for these users.</span></span> <span data-ttu-id="a1e41-202">在 " [DirectX 中的目视跟踪](gaze-in-directx.md#fallback-when-eye-tracking-is-not-available)" 页上，我们介绍了检测目视跟踪数据是否可用所需的 api。</span><span class="sxs-lookup"><span data-stu-id="a1e41-202">On the [Eye Tracking in DirectX](gaze-in-directx.md#fallback-when-eye-tracking-is-not-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="a1e41-203">如上所述，眼睛跟踪数据可能不可用的原因有多种。</span><span class="sxs-lookup"><span data-stu-id="a1e41-203">As described above, there are several reasons why eye tracking data may not be available.</span></span>   
<span data-ttu-id="a1e41-204">尽管某些用户可能已特意决定撤消对其眼睛跟踪数据的访问，但对于不提供对其眼睛跟踪数据的访问权限的隐私性的用户体验的不满，这一点很有可能是不可能的。</span><span class="sxs-lookup"><span data-stu-id="a1e41-204">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span>  
<span data-ttu-id="a1e41-205">因此，如果你的应用程序使用目视跟踪，并且这是体验的重要部分，我们建议你清楚地将此信息传递给用户。</span><span class="sxs-lookup"><span data-stu-id="a1e41-205">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>     
<span data-ttu-id="a1e41-206">请通知用户，目视跟踪对于你的应用程序至关重要（甚至可能会列出一些增强的功能）以充分利用你的应用程序，从而帮助用户更好地了解他们所放弃的内容。</span><span class="sxs-lookup"><span data-stu-id="a1e41-206">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span>    
<span data-ttu-id="a1e41-207">帮助用户确定目视跟踪可能不工作的原因（基于上述检查），并提供一些建议来快速解决潜在问题。</span><span class="sxs-lookup"><span data-stu-id="a1e41-207">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span>  
<span data-ttu-id="a1e41-208">例如，如果您可以检测到系统支持目视跟踪，则用户会进行校准，甚至会获得其权限，但不会收到任何眼睛跟踪数据，这可能会导致某些其他问题，如污迹或眼睛封闭像素。</span><span class="sxs-lookup"><span data-stu-id="a1e41-208">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span>    
<span data-ttu-id="a1e41-209">但请注意，在某些情况下，眼睛跟踪可能只是不能正常工作。</span><span class="sxs-lookup"><span data-stu-id="a1e41-209">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span>    
<span data-ttu-id="a1e41-210">因此，在应用中启用眼睛跟踪时，可以通过允许消除甚至禁用提醒来过于这种情况。</span><span class="sxs-lookup"><span data-stu-id="a1e41-210">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="a1e41-211">使用红眼作为主要输入指针的应用回退</span><span class="sxs-lookup"><span data-stu-id="a1e41-211">Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="a1e41-212">如果你的应用程序使用目视看眼作为指针输入来快速选择场景中的全息影像，但眼睛跟踪数据不可用，则建议回退到打印头并开始显示眼睛良好的光标。</span><span class="sxs-lookup"><span data-stu-id="a1e41-212">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="a1e41-213">建议使用超时值（例如500–1500毫秒）来确定是否要切换。</span><span class="sxs-lookup"><span data-stu-id="a1e41-213">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="a1e41-214">这是为了防止在系统每次由于快速目视动作或传情动漫或传情动漫而发生跟踪时弹出游标。</span><span class="sxs-lookup"><span data-stu-id="a1e41-214">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="a1e41-215">如果你是一名 Unity 开发人员，则已在混合现实工具包中处理自动回退到打印头。</span><span class="sxs-lookup"><span data-stu-id="a1e41-215">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="a1e41-216">如果你是 DirectX 开发人员，则需要自行处理此开关。</span><span class="sxs-lookup"><span data-stu-id="a1e41-216">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="a1e41-217">其他目视跟踪特定应用程序的回退</span><span class="sxs-lookup"><span data-stu-id="a1e41-217">Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="a1e41-218">您的应用程序可以采用专门为眼睛定制的独特方式（例如，为头像形象提供动画或基于眼睛的关注热图，它依赖于有关视觉对象的精确信息）。</span><span class="sxs-lookup"><span data-stu-id="a1e41-218">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="a1e41-219">在这种情况下，不会有任何明确的回退。</span><span class="sxs-lookup"><span data-stu-id="a1e41-219">In this case, there is no clear fallback.</span></span> <span data-ttu-id="a1e41-220">如果目视跟踪不可用，则可能只需禁用这些功能。</span><span class="sxs-lookup"><span data-stu-id="a1e41-220">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="a1e41-221">同样，我们建议你清楚地将其传达给可能未意识到该功能无法正常工作的用户。</span><span class="sxs-lookup"><span data-stu-id="a1e41-221">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="a1e41-222">在此页面中，你可以获得一个良好的概述，使你开始了解 HoloLens 2 的眼睛跟踪和目视眼睛输入的角色。</span><span class="sxs-lookup"><span data-stu-id="a1e41-222">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="a1e41-223">若要开始开发，请查看我们的信息，了解如何[与全息影像交互](eye-gaze-interaction.md)、[在 Unity 中目视](https://aka.ms/mrtk-eyes)看，以及如何[在 DirectX 中观看眼](gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="a1e41-223">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="a1e41-224">另请参阅</span><span class="sxs-lookup"><span data-stu-id="a1e41-224">See also</span></span>
* [<span data-ttu-id="a1e41-225">校准</span><span class="sxs-lookup"><span data-stu-id="a1e41-225">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="a1e41-226">舒适</span><span class="sxs-lookup"><span data-stu-id="a1e41-226">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="a1e41-227">目视的交互</span><span class="sxs-lookup"><span data-stu-id="a1e41-227">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="a1e41-228">目视观察 DirectX</span><span class="sxs-lookup"><span data-stu-id="a1e41-228">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="a1e41-229">目视看 Unity （混合现实工具包）</span><span class="sxs-lookup"><span data-stu-id="a1e41-229">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="a1e41-230">注视并提交</span><span class="sxs-lookup"><span data-stu-id="a1e41-230">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="a1e41-231">语音输入</span><span class="sxs-lookup"><span data-stu-id="a1e41-231">Voice input</span></span>](voice-design.md)


