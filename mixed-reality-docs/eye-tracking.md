---
title: 眼睛追踪
description: 眼睛追踪
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 混合现实、 输入、 关注的视线移动的眼跟踪
ms.openlocfilehash: f61f813c702cbeaa03ddc50c6a1958af3566bc1c
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730767"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="d7298-104">眼睛追踪 HoloLens 2 上</span><span class="sxs-lookup"><span data-stu-id="d7298-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="d7298-105">HoloLens 2，以允许的上下文和全息版中的人理解了一个新水平的开发人员提供了令人难以置信的使用有关用户正在查看的信息的体验。</span><span class="sxs-lookup"><span data-stu-id="d7298-105">HoloLens 2 allows for a whole new level of context and human understanding within the Holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="d7298-106">此页概述了如何开发人员可以受益于不同用例的眼跟踪以及将来需要注意的设计的视线移动基于关注的用户界面时。</span><span class="sxs-lookup"><span data-stu-id="d7298-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="d7298-107">用例</span><span class="sxs-lookup"><span data-stu-id="d7298-107">Use cases</span></span>
<span data-ttu-id="d7298-108">眼跟踪使应用程序可以跟踪用户在真实时间中的查找位置。</span><span class="sxs-lookup"><span data-stu-id="d7298-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="d7298-109">本部分介绍的一些潜在的用例和成为可能的眼跟踪混合现实中使用的新颖交互。</span><span class="sxs-lookup"><span data-stu-id="d7298-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="d7298-110">开始之前，在下面我们将提及[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)几次，因为它为使用如快速、 轻松支持关注的目标的眼跟踪提供了几个有趣且功能强大的示例选择并通过基于用户查看的文本自动滚动。</span><span class="sxs-lookup"><span data-stu-id="d7298-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="d7298-111">用户的意图</span><span class="sxs-lookup"><span data-stu-id="d7298-111">User intent</span></span>    
<span data-ttu-id="d7298-112">有关用户查看的信息提供了一个强大**上下文的其他输入**，例如语音、 手和控制器。</span><span class="sxs-lookup"><span data-stu-id="d7298-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="d7298-113">这可以用于各种任务。</span><span class="sxs-lookup"><span data-stu-id="d7298-113">This can be used for various tasks.</span></span>
<span data-ttu-id="d7298-114">例如，这可能包括上快速高效地**面向**跨通过只查看一张全息图并说"选择"场景 (另请参阅[Head 注视和提交](gaze-and-commit.md)) 或者说"将放这..."，然后查找到你想要放置全息图，说"...there"。</span><span class="sxs-lookup"><span data-stu-id="d7298-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="d7298-115">此示例可在[混合现实工具包-关注支持选择目标](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)并[混合现实工具包-关注支持目标定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)。</span><span class="sxs-lookup"><span data-stu-id="d7298-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="d7298-116">用户的意图的其他示例可能包括使用用户查看有关的信息来增强与 embodied 虚拟代理和交互式全息的合作。</span><span class="sxs-lookup"><span data-stu-id="d7298-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="d7298-117">例如，虚拟代理可能会调整可用的选项，其行为当前基于查看内容。</span><span class="sxs-lookup"><span data-stu-id="d7298-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="d7298-118">隐式操作</span><span class="sxs-lookup"><span data-stu-id="d7298-118">Implicit actions</span></span>
<span data-ttu-id="d7298-119">与用户的意图密切相关的隐式操作的类别。</span><span class="sxs-lookup"><span data-stu-id="d7298-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="d7298-120">其理念是可能会不甚至觉得自己与系统交互的而系统的用户是同步的某种程度上 instinctual 方式作出反应全息或用户界面元素。例如，一个非常成功的例子是**关注的视线移动基于自动滚动**。</span><span class="sxs-lookup"><span data-stu-id="d7298-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="d7298-121">其理念是一样简单：用户读取文本，并可以只需继续阅读。</span><span class="sxs-lookup"><span data-stu-id="d7298-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="d7298-122">文本逐渐向上移动用户保持其读取流。</span><span class="sxs-lookup"><span data-stu-id="d7298-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="d7298-123">一个重要方面是滚动速度适应用户的读取速度。</span><span class="sxs-lookup"><span data-stu-id="d7298-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="d7298-124">另一个示例是**关注支持缩放和平移**为该用户可以让人感觉完全入什么他或她将重点放在深入探讨其功能。</span><span class="sxs-lookup"><span data-stu-id="d7298-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="d7298-125">触发缩放和控制缩放速度可通过语音控制或手动输入这是非常重要的方面提供控制的感觉，避免庞大的用户 （我们将介绍有关更详细地下面这些设计指导原则）。</span><span class="sxs-lookup"><span data-stu-id="d7298-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="d7298-126">后放大，用户可以顺利按照，例如，street 来浏览他或她的邻域只是通过使用其关注的视线移动的过程。</span><span class="sxs-lookup"><span data-stu-id="d7298-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="d7298-127">这些类型的交互的演示示例可在[混合现实工具包-关注支持导航](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)示例。</span><span class="sxs-lookup"><span data-stu-id="d7298-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="d7298-128">其他使用情况_隐式操作_可能包括：</span><span class="sxs-lookup"><span data-stu-id="d7298-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="d7298-129">**智能通知：** 曾经会很苦恼由上一次您重点放在其中弹出通知？</span><span class="sxs-lookup"><span data-stu-id="d7298-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="d7298-130">考虑到用户当前并关注，您可以进行更好 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="d7298-131">显示相对于用户当前在其中想要限制尽量减少干扰，并自动一次取消偏移量的通知完成读取。</span><span class="sxs-lookup"><span data-stu-id="d7298-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="d7298-132">**细心全息：** 正在调查时略有做出反应的全息。</span><span class="sxs-lookup"><span data-stu-id="d7298-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="d7298-133">这可能包括略有发光的 UI 元素，缓慢 blooming 花卉虚拟宠物启动要回顾一下您或尝试避免长时间观察后你关注的视线移动。</span><span class="sxs-lookup"><span data-stu-id="d7298-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="d7298-134">这可能提供有趣的意义上的连接和应用程序中的满意度。</span><span class="sxs-lookup"><span data-stu-id="d7298-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="d7298-135">注意跟踪</span><span class="sxs-lookup"><span data-stu-id="d7298-135">Attention tracking</span></span>   
<span data-ttu-id="d7298-136">有关用户查看的信息是一个极其强大的工具来评估可用性的设计并识别有效的工作流中的问题。</span><span class="sxs-lookup"><span data-stu-id="d7298-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="d7298-137">到目前为止，眼睛追踪可视化和分析都已在各种应用程序领域中常见的做法。</span><span class="sxs-lookup"><span data-stu-id="d7298-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="d7298-138">HoloLens 2 中，我们将提供此了解新的维度，3D 全息可以放置在实际的上下文中，并评估以及。</span><span class="sxs-lookup"><span data-stu-id="d7298-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="d7298-139">[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供基本示例，用于日志记录和加载的眼跟踪数据以及如何将其可视化。</span><span class="sxs-lookup"><span data-stu-id="d7298-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="d7298-140">此区域中的其他应用程序可能包括：</span><span class="sxs-lookup"><span data-stu-id="d7298-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="d7298-141">**远程关注的视线移动可视化效果：** 可视化什么远程协作者正在查看到，例如，请确保是否在正确了解并遵循说明进行操作。</span><span class="sxs-lookup"><span data-stu-id="d7298-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="d7298-142">**用户研究研究：** 注意跟踪可用于浏览新手与专家用户直观地分析内容或对复杂任务 （例如，用于分析的医疗数据，或者同时机制） 其手关注协调的方式。</span><span class="sxs-lookup"><span data-stu-id="d7298-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="d7298-143">**模拟培训和性能监视：** 练习，并通过找出瓶颈问题更有效地在执行流优化任务的执行。</span><span class="sxs-lookup"><span data-stu-id="d7298-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="d7298-144">**设计评估、 广告和营销研究：** 眼睛追踪是用于市场调查，以评估网站和产品设计的通用工具。</span><span class="sxs-lookup"><span data-stu-id="d7298-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="d7298-145">其他用例</span><span class="sxs-lookup"><span data-stu-id="d7298-145">Additional use cases</span></span>
- <span data-ttu-id="d7298-146">**游戏：** 是否曾经希望可以具有强大功能？</span><span class="sxs-lookup"><span data-stu-id="d7298-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="d7298-147">下面是您将有机会 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-147">Here's your chance!</span></span> <span data-ttu-id="d7298-148">通过在它们 levitate 全息。</span><span class="sxs-lookup"><span data-stu-id="d7298-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="d7298-149">投篮机会控制在从你自己的激光光标。</span><span class="sxs-lookup"><span data-stu-id="d7298-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="d7298-150">将变成 stone 敌人否则请冻结这些 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="d7298-151">使用 x 射线视力浏览建筑物。</span><span class="sxs-lookup"><span data-stu-id="d7298-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="d7298-152">您的想象力是限制 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="d7298-153">**表达虚拟形象：** 使用实时的眼跟踪日期进行动画处理的虚拟形象的眼睛，以指示哪些用户当前正在考虑在跟踪中更有意义的 3D 虚拟形象的辅助工具的关注。</span><span class="sxs-lookup"><span data-stu-id="d7298-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="d7298-154">它还通过添加传情和眨眼添加更多的表现力。</span><span class="sxs-lookup"><span data-stu-id="d7298-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="d7298-155">**文本输入：** 眼睛追踪可作为备用有趣低工作量文本输入尤其是当不太方便使用，语音或手。</span><span class="sxs-lookup"><span data-stu-id="d7298-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="d7298-156">关注跟踪 API</span><span class="sxs-lookup"><span data-stu-id="d7298-156">Eye tracking API</span></span>
<span data-ttu-id="d7298-157">然后再转到有关关注注视交互的特定的设计准则的详细信息，我们想要简要指向 HoloLens 2 眼跟踪程序提供的功能。</span><span class="sxs-lookup"><span data-stu-id="d7298-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="d7298-158">[眼跟踪 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)可通过访问： `Windows.Perception.People.EyesPose`。</span><span class="sxs-lookup"><span data-stu-id="d7298-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="d7298-159">它向开发人员提供单一关注的视线移动 ray （注视起点和方向）。</span><span class="sxs-lookup"><span data-stu-id="d7298-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="d7298-160">眼睛追踪器上的数据提供有关_30 FPS_。</span><span class="sxs-lookup"><span data-stu-id="d7298-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="d7298-161">预测的关注注视位于 ca。</span><span class="sxs-lookup"><span data-stu-id="d7298-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="d7298-162">1.0-1.5 度在周围的实际 visual 角度探讨了目标。</span><span class="sxs-lookup"><span data-stu-id="d7298-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="d7298-163">如需要略微不精确性，应规划一些边距围绕此下限值。</span><span class="sxs-lookup"><span data-stu-id="d7298-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="d7298-164">我们将对此进行讨论更下面。</span><span class="sxs-lookup"><span data-stu-id="d7298-164">We will discuss this more below.</span></span> <span data-ttu-id="d7298-165">眼睛追踪准确地工作，对于每个用户需要通过跟踪用户校准关注。</span><span class="sxs-lookup"><span data-stu-id="d7298-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="d7298-166">![2 个计量距离处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="d7298-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="d7298-167">*2 个计量距离处的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="d7298-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="d7298-168">关注的视线移动设计指南</span><span class="sxs-lookup"><span data-stu-id="d7298-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="d7298-169">构建充分利用快速移动密切关注面向的交互可能很困难。</span><span class="sxs-lookup"><span data-stu-id="d7298-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="d7298-170">在本部分中，我们汇总的主要优势和挑战设计您的应用程序时需要考虑。</span><span class="sxs-lookup"><span data-stu-id="d7298-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="d7298-171">关注注视输入的优点</span><span class="sxs-lookup"><span data-stu-id="d7298-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="d7298-172">**指向高速度。**</span><span class="sxs-lookup"><span data-stu-id="d7298-172">**High speed pointing.**</span></span> <span data-ttu-id="d7298-173">关注这个功能是我们的正文中速度最快 reacting 这个功能。</span><span class="sxs-lookup"><span data-stu-id="d7298-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="d7298-174">**低工作量。**</span><span class="sxs-lookup"><span data-stu-id="d7298-174">**Low effort.**</span></span> <span data-ttu-id="d7298-175">几乎没有任何物理移动是必需的。</span><span class="sxs-lookup"><span data-stu-id="d7298-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="d7298-176">**Implicitness。**</span><span class="sxs-lookup"><span data-stu-id="d7298-176">**Implicitness.**</span></span> <span data-ttu-id="d7298-177">有关用户的关注动作的信息通常由用户描述为"注意资料"，可让系统在知道的目标用户计划来处理。</span><span class="sxs-lookup"><span data-stu-id="d7298-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="d7298-178">**替代输入的通道。**</span><span class="sxs-lookup"><span data-stu-id="d7298-178">**Alternative input channel.**</span></span> <span data-ttu-id="d7298-179">关注的视线移动可以为手动和语音输入昔日的年的经验基于其手眼协调用户从提供的功能强大的支持输入。</span><span class="sxs-lookup"><span data-stu-id="d7298-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="d7298-180">**Visual 引起注意。**</span><span class="sxs-lookup"><span data-stu-id="d7298-180">**Visual attention.**</span></span> <span data-ttu-id="d7298-181">另一个重要优点是能够推断出哪些用户关注。</span><span class="sxs-lookup"><span data-stu-id="d7298-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="d7298-182">这可帮助在各种应用程序方面，范围为从有效地评估不同的设计为帮助在更智能的用户界面中的详细信息和增强的社交提示进行远程通信。</span><span class="sxs-lookup"><span data-stu-id="d7298-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="d7298-183">简单地说，因为输入可能会提供快速且轻松上下文信号-使用关注的视线移动时尤为强大结合其他输入如*语音*并*手动*输入到确认用户的意图。</span><span class="sxs-lookup"><span data-stu-id="d7298-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="d7298-184">挑战的眼睛看作为输入</span><span class="sxs-lookup"><span data-stu-id="d7298-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="d7298-185">具有大量电源，附带了诸多的责任：关注的视线移动可用于创建还觉得自己象作者的神奇的用户体验，而是还必须知道什么不是好地应对此适当。</span><span class="sxs-lookup"><span data-stu-id="d7298-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="d7298-186">在下面的示例，我们将讨论一些*挑战*要考虑到帐户以及如何解决它们时使用的眼睛注视输入：</span><span class="sxs-lookup"><span data-stu-id="d7298-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="d7298-187">**你关注的视线移动为"always on"** 打开你关注盖，目前你自己开始 fixating 在环境中。</span><span class="sxs-lookup"><span data-stu-id="d7298-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="d7298-188">作出反应到每个看到您的品牌和可能意外地发出操作，因为您看到的内容太长时间会导致可怕的体验 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="d7298-189">这就是我们建议将关注与的视线移动原因*语音命令*，*传递手势*，*按钮单击*或扩展的停留来触发所选内容的目标。</span><span class="sxs-lookup"><span data-stu-id="d7298-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="d7298-190">此解决方案还可以在其中用户可以自由地一下而无需无意间触发一些让人不知所措的感觉的模式。</span><span class="sxs-lookup"><span data-stu-id="d7298-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="d7298-191">目标只查看时设计视觉和听觉反馈时，还应考虑执行此问题。</span><span class="sxs-lookup"><span data-stu-id="d7298-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="d7298-192">不要过度占用即时弹出影响的用户或将鼠标悬停在声音。</span><span class="sxs-lookup"><span data-stu-id="d7298-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="d7298-193">一个要点在于密钥 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-193">Subtlety is key!</span></span> <span data-ttu-id="d7298-194">当谈到的设计建议时，我们将此进一步下面讨论的一些最佳做法。</span><span class="sxs-lookup"><span data-stu-id="d7298-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="d7298-195">**与控件的观察**想象你想要精确对齐在贴在墙照片。</span><span class="sxs-lookup"><span data-stu-id="d7298-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="d7298-196">查看其边框和周围环境，了解是否它保持一致良好。</span><span class="sxs-lookup"><span data-stu-id="d7298-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="d7298-197">现在，假设您如何将建模时要使用作为输入你关注的视线移动移动图片在同一时间。</span><span class="sxs-lookup"><span data-stu-id="d7298-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="d7298-198">困难，不是吗？</span><span class="sxs-lookup"><span data-stu-id="d7298-198">Difficult, isn't it?</span></span> <span data-ttu-id="d7298-199">需要同时用于输入和控制时，它描述关注的视线移动的双精度角色。</span><span class="sxs-lookup"><span data-stu-id="d7298-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="d7298-200">**保留之前单击：** 研究显示结束手动单击前可能会移用户的关注的视线移动用于快速目标选项 (例如，airtap)。</span><span class="sxs-lookup"><span data-stu-id="d7298-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="d7298-201">因此，应特别注意必须支付给快速关注的视线移动信号同步慢控件输入 （例如，语音，手，控制器）。</span><span class="sxs-lookup"><span data-stu-id="d7298-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="d7298-202">**较小的目标：** 当您尝试读取只是有点太小，无法轻松读取的文本时，您是否知道这种感觉？</span><span class="sxs-lookup"><span data-stu-id="d7298-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="d7298-203">您会使您感到厌倦和磨损，因为尝试重新调整更好地专注于你自己的眼睛上此紧张感觉？</span><span class="sxs-lookup"><span data-stu-id="d7298-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="d7298-204">这是可以调用在你的用户时强制他们使用关注目标应用程序中选择目标太小，这种感觉。</span><span class="sxs-lookup"><span data-stu-id="d7298-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="d7298-205">对于您的设计、 创建愉快并能够熟练地体验为您的用户，我们建议目标应在至少 2 个 ° 中 visual 角度，最好是更大。</span><span class="sxs-lookup"><span data-stu-id="d7298-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="d7298-206">**右边未对齐的眼睛的视线移动移动**竞争对手的动态执行快速移动固定固定。</span><span class="sxs-lookup"><span data-stu-id="d7298-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="d7298-207">如果您查看扫描的录制的关注移动的路径，可以看到它们看起来右边未对齐。</span><span class="sxs-lookup"><span data-stu-id="d7298-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="d7298-208">您的眼睛移动快速和中与自发性跳转*头注视*或*分发动作*。</span><span class="sxs-lookup"><span data-stu-id="d7298-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="d7298-209">**跟踪可靠性：** 更改光，因为您的眼睛调整到新的条件的眼跟踪准确性可能会稍有降低。</span><span class="sxs-lookup"><span data-stu-id="d7298-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="d7298-210">虽然这应不一定会影响您的应用程序设计，因为准确性应该是上面提到的 2 个 ° 限制内。</span><span class="sxs-lookup"><span data-stu-id="d7298-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="d7298-211">这可能意味着，用户必须运行另一个校准。</span><span class="sxs-lookup"><span data-stu-id="d7298-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="d7298-212">设计建议</span><span class="sxs-lookup"><span data-stu-id="d7298-212">Design recommendations</span></span>
<span data-ttu-id="d7298-213">在下面的示例，我们列出特定的设计建议根据所述的优势和挑战关注注视输入：</span><span class="sxs-lookup"><span data-stu-id="d7298-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="d7298-214">**关注的视线移动 ！ = Head 的视线移动：**</span><span class="sxs-lookup"><span data-stu-id="d7298-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="d7298-215">**请考虑是否快速不规则的关注移动适合您输入的任务：** 虽然我们快速和不规则关注移动非常快速地在我们的视野之间选择目标，但并不太适用于需要平滑输入的轨迹 （例如，用于绘制或 encircling 批注） 的任务。</span><span class="sxs-lookup"><span data-stu-id="d7298-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="d7298-216">在这种情况下，手动或 head 指向应为首选。</span><span class="sxs-lookup"><span data-stu-id="d7298-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="d7298-217">**避免直接向用户的关注视线移动 （例如，滑块或光标） 附加内容。**</span><span class="sxs-lookup"><span data-stu-id="d7298-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="d7298-218">游标情况下这可能导致由于预计的关注的视线移动信号中的轻微偏移量"fleeing 游标"效果。</span><span class="sxs-lookup"><span data-stu-id="d7298-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="d7298-219">对于滑块，将它与冲突还想要检查的对象是否在正确位置时控制着滑块的双精度的角色。</span><span class="sxs-lookup"><span data-stu-id="d7298-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="d7298-220">简单地说，用户可能会快速轻松过载，很难理解，尤其是是否信号是为该用户不精确。</span><span class="sxs-lookup"><span data-stu-id="d7298-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="d7298-221">**将关注的视线移动与其他输入结合起来：** 与其他输入，如手势，语音命令或按钮按下的眼跟踪集成提供以下优点：</span><span class="sxs-lookup"><span data-stu-id="d7298-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="d7298-222">**允许免费观察：** 假定竞争对手的动态的主要角色是要观察我们的环境，务必要允许用户去了解一下未触发任何情况下 (视觉、 听觉，...) 的反馈或操作。</span><span class="sxs-lookup"><span data-stu-id="d7298-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="d7298-223">将与另一个输入控件结合使用 ET 允许 ET 观察和输入的控件模式之间平稳过渡。</span><span class="sxs-lookup"><span data-stu-id="d7298-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="d7298-224">**功能强大的上下文提供程序：** 有关使用信息，其中用户在查看时 uttering 语音命令或执行手动手势允许轻松地跨视图字段排列输入。</span><span class="sxs-lookup"><span data-stu-id="d7298-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="d7298-225">示例包括："，那里"快速和流畅选择放在场景之间的一张全息图定位通过只需查看目标和目标。</span><span class="sxs-lookup"><span data-stu-id="d7298-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="d7298-226">**同步多模输入 （"保留之前单击"问题） 的需要：** 将快速关注移动组合更复杂的其他输入 （例如，长语音命令或手势互补） 具有与你关注的视线移动完成其他输入的命令之前移动的风险。</span><span class="sxs-lookup"><span data-stu-id="d7298-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="d7298-227">因此，如果您创建自己的输入的控件 （例如，自定义手势），请确保记录此输入或近似的持续时间来关联与哪些用户有关注在过去的用于开始。</span><span class="sxs-lookup"><span data-stu-id="d7298-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="d7298-228">**眼睛追踪输入的细微反馈：** 它可用于提供反馈，如果目标介绍了 （以指示系统按预期方式工作），但应保留细微。</span><span class="sxs-lookup"><span data-stu-id="d7298-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="d7298-229">这可能包括缓慢值混合处理的输入/输出视觉突出显示或执行其他细微的目标的行为，例如慢速动作 （例如，略有增加的目标） 以指示系统正确检测用户正在查看目标，但是，如果没有不必要地中断用户的当前工作流。</span><span class="sxs-lookup"><span data-stu-id="d7298-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="d7298-230">**避免强制非自然关注移动作为输入：** 不强制用户在应用中触发操作执行特定的关注动作 （注视手势）。</span><span class="sxs-lookup"><span data-stu-id="d7298-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="d7298-231">**不精确性进行的帐户：** 我们来区分两种类型的不精确性是向用户明显：偏移量和抖动。</span><span class="sxs-lookup"><span data-stu-id="d7298-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="d7298-232">为地址偏移量的最简单方法是提供要与之交互的足够大，目标 (visual 角度 – 引用作为 2 个 ° >： 您的缩略图时，可以在视觉角度约 2 ° 延伸 arm (1))。</span><span class="sxs-lookup"><span data-stu-id="d7298-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="d7298-233">这会导致以下指南：</span><span class="sxs-lookup"><span data-stu-id="d7298-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="d7298-234">不强制用户选择目标较小：研究表明，是否目标是足够大 （和系统设计得当），用户描述为轻松而神奇的交互。</span><span class="sxs-lookup"><span data-stu-id="d7298-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="d7298-235">如果目标变得过小，用户将描述作为 fatiguing 和令人沮丧的体验。</span><span class="sxs-lookup"><span data-stu-id="d7298-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
    
# <a name="eye-gaze-design-guidelines-placeholder"></a><span data-ttu-id="d7298-236">关注的视线移动设计准则 （占位符）</span><span class="sxs-lookup"><span data-stu-id="d7298-236">Eye gaze design guidelines (Placeholder)</span></span>

<span data-ttu-id="d7298-237">HoloLens 2 中，我们有很好的机会，以便通过使用关注的视线移动而不头的视线移动的视线移动和更快、 更舒适的提交。</span><span class="sxs-lookup"><span data-stu-id="d7298-237">With HoloLens 2, we have the great opportunity to make gaze & commit faster and more comfortable by using eye gaze instead of head gaze.</span></span> <span data-ttu-id="d7298-238">但是，密切关注的视线移动的行为有很大不同于以某些方式的头视线移动，因此存在很多独特的挑战。</span><span class="sxs-lookup"><span data-stu-id="d7298-238">However, eye gaze behaves very differently to head gaze in certain ways and hence comes with a number of unique challenges.</span></span> <span data-ttu-id="d7298-239">在关注注视设计准则，我们汇总常规优点和使用眼跟踪作为全息版应用程序中的输入媒体时需要考虑的挑战。</span><span class="sxs-lookup"><span data-stu-id="d7298-239">In Eye Gaze Design Guidelines, we summarize general advantages and challenges to take into account when using eye tracking as an input medium in your holographic app.</span></span> <span data-ttu-id="d7298-240">在本部分中，我们重点关注的视线移动和提交的特定设计注意事项。</span><span class="sxs-lookup"><span data-stu-id="d7298-240">In this section, we focus on the specific design considerations for eye gaze & commit.</span></span> <span data-ttu-id="d7298-241">首先，竞争对手的动态非常迅速，因此很适合在快速目标选项将很有用。</span><span class="sxs-lookup"><span data-stu-id="d7298-241">First, our eyes move incredibly fast and thus are great at quickly targeting across the view.</span></span> <span data-ttu-id="d7298-242">这使得关注注视适用于快速的视线移动和提交操作，尤其是与快速提交，如按钮或以无线方式点击按结合使用时。</span><span class="sxs-lookup"><span data-stu-id="d7298-242">This makes eye gaze ideal for quick gaze & commit actions especially when combined with fast commits such as an air-tap or button press.</span></span>

<span data-ttu-id="d7298-243">不显示光标：虽然几乎不可能进行交互而无需使用 head 时游标注视，光标将变为快速明显，令人讨厌的使用关注的视线移动时。</span><span class="sxs-lookup"><span data-stu-id="d7298-243">Do not show a cursor: While it is nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="d7298-244">而不是依靠光标向用户通知的眼跟踪是否正常运行且已正确检测到当前查找目标，在使用细微的可视化突出显示 （详见下文）。</span><span class="sxs-lookup"><span data-stu-id="d7298-244">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights (more details below).</span></span>

<span data-ttu-id="d7298-245">讲求细微混合的悬停反馈：就像很好的可视反馈的头的视线移动可能会导致可怕，让人不知所措体验使用关注的视线移动。</span><span class="sxs-lookup"><span data-stu-id="d7298-245">Strive for subtle blended hover feedback: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="d7298-246">请记住，您的眼睛这个快速，快速 darting 跨在字段的视图中的点。</span><span class="sxs-lookup"><span data-stu-id="d7298-246">Remember that your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="d7298-247">（开/关） 快速突然突出显示更改可能会导致 flickery 反馈时仔细查看。</span><span class="sxs-lookup"><span data-stu-id="d7298-247">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="d7298-248">因此时提供悬停反馈，我们建议使用的顺利值混合处理中的突出显示框 （和混合扩展即可查看时）。</span><span class="sxs-lookup"><span data-stu-id="d7298-248">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="d7298-249">这意味着，在第一个，则会几乎不能看到反馈查看目标时。</span><span class="sxs-lookup"><span data-stu-id="d7298-249">This means that at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="d7298-250">在过去的 500-1000 ms 突出显示会增加在强度。</span><span class="sxs-lookup"><span data-stu-id="d7298-250">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="d7298-251">虽然可以保持初级用户查看要确保系统已正确确定已设定焦点的目标的目标，专家级用户无法快速注视和不必等待，直到反馈是达到其最大亮度，即可提交。</span><span class="sxs-lookup"><span data-stu-id="d7298-251">While novice users could keep looking at the target to ensure that the system has correctly determined the focused target, expert users could quickly gaze & commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="d7298-252">此外，我们还建议使用 blend 扩展时淡出悬停反馈。</span><span class="sxs-lookup"><span data-stu-id="d7298-252">In addition, we also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="d7298-253">研究表明，快速动作和对比度更改才会在你的外围视觉 （因此，其中不查看视觉对象字段的区域） 中非常明显。</span><span class="sxs-lookup"><span data-stu-id="d7298-253">Research has shown that quick motion and contrast changes are very noticeable in your peripheral vision (so, the area of your visual field where you are not looking).</span></span> <span data-ttu-id="d7298-254">淡出不一定要为慢如 blend 中。</span><span class="sxs-lookup"><span data-stu-id="d7298-254">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="d7298-255">当您突出显示为具有高对比度或颜色更改时，这是仅关键。</span><span class="sxs-lookup"><span data-stu-id="d7298-255">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="d7298-256">如果首先得到的悬停反馈是非常细微，您可能不会注意到差异。</span><span class="sxs-lookup"><span data-stu-id="d7298-256">If the hover feedback was pretty subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="d7298-257">同步的视线移动和提交信号查找：输入信号的同步可能小于所面临的难题简单的视线移动和提交，因此，请不要担心 ！</span><span class="sxs-lookup"><span data-stu-id="d7298-257">Look out for synchronizing gaze and commit signals: The synchronization of input signals may be less of a challenge for simple gaze & commit, so, don't worry!</span></span> <span data-ttu-id="d7298-258">这是一个需要密切注意如果你想要使用更复杂的提交操作，但这可能涉及长语音命令或复杂的手势。</span><span class="sxs-lookup"><span data-stu-id="d7298-258">It is something to look out for in case you want to use more complicated commit actions though that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="d7298-259">假设您看一看目标并说话长语音命令。</span><span class="sxs-lookup"><span data-stu-id="d7298-259">Imagine you look at target and utter a long voice command.</span></span> <span data-ttu-id="d7298-260">考虑在内，您说出所需的时间和系统检测到您所说内容所需的时间，你关注的视线移动通常长时间移动到场景中的一些新目标。</span><span class="sxs-lookup"><span data-stu-id="d7298-260">Taken into account the time that you needed to speak and the time that the system needed to detect what you said, your eye gaze has usually long moved on to some new target in the scene.</span></span> <span data-ttu-id="d7298-261">因此，可以让您知道它们可能会需要继续在之前识别此命令在目标查找或处理的方式确定的命令和用户必须已查找内容在那时开始输入的用户。</span><span class="sxs-lookup"><span data-stu-id="d7298-261">Hence, either make your users aware that they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="d7298-262">请参阅</span><span class="sxs-lookup"><span data-stu-id="d7298-262">See also</span></span>
* [<span data-ttu-id="d7298-263">视线移动和提交</span><span class="sxs-lookup"><span data-stu-id="d7298-263">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="d7298-264">Head 视线移动目标</span><span class="sxs-lookup"><span data-stu-id="d7298-264">Head gaze targeting</span></span>](gaze-targeting.md)
* [<span data-ttu-id="d7298-265">手势</span><span class="sxs-lookup"><span data-stu-id="d7298-265">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="d7298-266">语音设计</span><span class="sxs-lookup"><span data-stu-id="d7298-266">Voice design</span></span>](voice-design.md)
* [<span data-ttu-id="d7298-267">运动控制器</span><span class="sxs-lookup"><span data-stu-id="d7298-267">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="d7298-268">舒适</span><span class="sxs-lookup"><span data-stu-id="d7298-268">Comfort</span></span>](comfort.md)
