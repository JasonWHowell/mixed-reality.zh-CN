---
title: 眼睛-注视
description: HoloLens 2 为开发人员提供了使用用户所注视对象的相关信息的功能，将全息体验中的环境和人类理解能力提高到了一个新境界。
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 眼睛跟踪，混合现实，输入，眼睛
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122062"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="874f4-104">目视-注视 HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="874f4-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="874f4-105">HoloLens 2 为开发人员提供了使用用户所注视对象的相关信息的功能，将全息体验中的环境和人类理解能力提高到了一个新境界。</span><span class="sxs-lookup"><span data-stu-id="874f4-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="874f4-106">本页告诉开发人员如何从各种用例的目视跟踪中获益，以及在设计基于目视的用户界面时要查找的内容。</span><span class="sxs-lookup"><span data-stu-id="874f4-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="874f4-107">设备支持</span><span class="sxs-lookup"><span data-stu-id="874f4-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="874f4-108"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="874f4-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="874f4-109"><a href="hololens-hardware-details.md"><strong>HoloLens（第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="874f4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="874f4-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="874f4-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="874f4-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></span><span class="sxs-lookup"><span data-stu-id="874f4-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="874f4-112">眼睛-注视</span><span class="sxs-lookup"><span data-stu-id="874f4-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="874f4-113">❌</span><span class="sxs-lookup"><span data-stu-id="874f4-113">❌</span></span></td>
     <td><span data-ttu-id="874f4-114">✔️</span><span class="sxs-lookup"><span data-stu-id="874f4-114">✔️</span></span></td>
     <td><span data-ttu-id="874f4-115">❌</span><span class="sxs-lookup"><span data-stu-id="874f4-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="874f4-116">用例</span><span class="sxs-lookup"><span data-stu-id="874f4-116">Use cases</span></span>
<span data-ttu-id="874f4-117">眼动跟踪可让应用程序实时跟踪用户正在注视的位置。</span><span class="sxs-lookup"><span data-stu-id="874f4-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="874f4-118">以下用例介绍了混合现实中的目视跟踪可能会发生的一些交互。</span><span class="sxs-lookup"><span data-stu-id="874f4-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="874f4-119">请记住，[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)对于使用目视跟踪提供几个有趣和强大的示例非常有用，例如，快速和轻松地支持目视的目标选项，以及基于用户查看的内容。</span><span class="sxs-lookup"><span data-stu-id="874f4-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="874f4-120">用户意图</span><span class="sxs-lookup"><span data-stu-id="874f4-120">User intent</span></span>    
<span data-ttu-id="874f4-121">有关用户所在位置和内容的信息**为其他输入**提供了强大的上下文，例如语音、动手和控制器。</span><span class="sxs-lookup"><span data-stu-id="874f4-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="874f4-122">可在各种任务中使用此信息。</span><span class="sxs-lookup"><span data-stu-id="874f4-122">This can be used for various tasks.</span></span>
<span data-ttu-id="874f4-123">例如，这种方法的范围包括：只需查看一个全息影像并口述 "select" （也可以说 "选择["），](gaze-and-commit.md)或者说 *"put ..."* ，然后查看用户想要放置全息图，并说 *"。出现 "* 。</span><span class="sxs-lookup"><span data-stu-id="874f4-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="874f4-124">在[混合现实工具包 - 视线支持的目标选择](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合现实工具包 - 视线支持的目标定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中可以找到相关示例。</span><span class="sxs-lookup"><span data-stu-id="874f4-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="874f4-125">此外，用户意向的示例可能包括使用用户查看的信息来增强使用所介绍的虚拟代理和交互式全息影像。</span><span class="sxs-lookup"><span data-stu-id="874f4-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="874f4-126">例如，虚拟代理可能会根据当前查看的内容来调整可用选项及其行为。</span><span class="sxs-lookup"><span data-stu-id="874f4-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="874f4-127">隐式操作</span><span class="sxs-lookup"><span data-stu-id="874f4-127">Implicit actions</span></span>
<span data-ttu-id="874f4-128">隐式操作的类别与用户意图密切相关。</span><span class="sxs-lookup"><span data-stu-id="874f4-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="874f4-129">其思路是，全息影像或用户界面元素以某种 instinctual 的方式做出反应，甚至可能不会像用户同时与系统交互，而是让系统和用户保持同步。例如，**基于目视的自动滚动**，用户可以在其中读取长文本，该文本会在用户进入文本框底部时自动开始滚动，以使用户处于阅读流中而不抬起手指。</span><span class="sxs-lookup"><span data-stu-id="874f4-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="874f4-130">这种情况的一个关键方面是，滚动速度可适应用户的读取速度。</span><span class="sxs-lookup"><span data-stu-id="874f4-130">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="874f4-131">另一个例子就是**受支持的目视缩放和平移**，用户可以感觉到他或她所关注的内容完全接近。</span><span class="sxs-lookup"><span data-stu-id="874f4-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="874f4-132">触发缩放和控制缩放速度可以通过语音或手写输入来控制，这对于向用户提供控制感受，同时避免被淹没非常重要。</span><span class="sxs-lookup"><span data-stu-id="874f4-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="874f4-133">下面将更详细地讨论这些设计指南。</span><span class="sxs-lookup"><span data-stu-id="874f4-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="874f4-134">放大后，用户可以顺利地执行操作，例如，街道的学习过程只需使用其眼睛来浏览其邻居即可。</span><span class="sxs-lookup"><span data-stu-id="874f4-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="874f4-135">[混合现实工具包 - 视线支持的导航](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)示例中可以找到此类交互的演示。</span><span class="sxs-lookup"><span data-stu-id="874f4-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="874f4-136">_隐式操作_的其他用例包括：</span><span class="sxs-lookup"><span data-stu-id="874f4-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="874f4-137">**智能通知：** 当你专心浏览某段内容时，突然弹出的通知是否让你觉得很恼火？</span><span class="sxs-lookup"><span data-stu-id="874f4-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="874f4-138">考虑到用户正在关注的内容，你可以通过从当前 gazing 用户的位置偏移通知来更好地进行此体验。</span><span class="sxs-lookup"><span data-stu-id="874f4-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="874f4-139">这会限制干扰，并在用户完成读取后自动将其关闭。</span><span class="sxs-lookup"><span data-stu-id="874f4-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="874f4-140">**体贴入微的全息影像：** 在 gazed 时，会对影像进行细微反应。</span><span class="sxs-lookup"><span data-stu-id="874f4-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="874f4-141">这种情况的范围包括：从稍微光亮的 UI 元素到缓慢的百花齐放花给虚拟宠物，开始回顾用户，或尝试避免在长时间的琢磨后出现用户的眼睛。</span><span class="sxs-lookup"><span data-stu-id="874f4-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="874f4-142">这种交互可能会在应用程序中提供更有趣的连接和满意度。</span><span class="sxs-lookup"><span data-stu-id="874f4-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="874f4-143">注意力跟踪</span><span class="sxs-lookup"><span data-stu-id="874f4-143">Attention tracking</span></span>   
<span data-ttu-id="874f4-144">有关用户所在位置或内容的信息是一个非常强大的工具，可用于评估设计的可用性，并确定有效工作流中的问题。</span><span class="sxs-lookup"><span data-stu-id="874f4-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="874f4-145">目视跟踪可视化和分析是各种应用程序领域的常见做法。</span><span class="sxs-lookup"><span data-stu-id="874f4-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="874f4-146">在 HoloLens 2 中，我们提供了一种新的维度来理解，因为3D 全息图可以放置在真实的上下文中并进行相应的评估。</span><span class="sxs-lookup"><span data-stu-id="874f4-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="874f4-147">[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供了用于记录和加载目视跟踪数据的基本示例，以及如何对其进行可视化。</span><span class="sxs-lookup"><span data-stu-id="874f4-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="874f4-148">此区域中的其他应用程序可以包括：</span><span class="sxs-lookup"><span data-stu-id="874f4-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="874f4-149">**远程目视视觉视觉对象：** 可视化远程协作者正在寻找的内容，以确保正确理解并遵循说明。</span><span class="sxs-lookup"><span data-stu-id="874f4-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="874f4-150">**用户调研：** 注意跟踪可用于探索初级用户与专家用户直观地分析内容的方式，或者对复杂任务（例如分析医疗数据或操作机械）进行实时协调。</span><span class="sxs-lookup"><span data-stu-id="874f4-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="874f4-151">**训练模拟和性能监视：** 更有效地识别执行流中的瓶颈，实践并优化任务的执行。</span><span class="sxs-lookup"><span data-stu-id="874f4-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="874f4-152">**设计评估、广告和营销调查：** 在评估网站和产品设计时，目视跟踪是一种用于市场研究的常用工具。</span><span class="sxs-lookup"><span data-stu-id="874f4-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="874f4-153">其他用例</span><span class="sxs-lookup"><span data-stu-id="874f4-153">Additional use cases</span></span>
- <span data-ttu-id="874f4-154">**游戏：** 是否曾经想过拥有超能力？</span><span class="sxs-lookup"><span data-stu-id="874f4-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="874f4-155">机会来了！</span><span class="sxs-lookup"><span data-stu-id="874f4-155">Here's your chance!</span></span> <span data-ttu-id="874f4-156">可以通过起始在 levitate 全息影像。</span><span class="sxs-lookup"><span data-stu-id="874f4-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="874f4-157">从眼睛发射激光束。</span><span class="sxs-lookup"><span data-stu-id="874f4-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="874f4-158">将敌人变成石子，或将其冻结。</span><span class="sxs-lookup"><span data-stu-id="874f4-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="874f4-159">使用 X 光透视来扫描建筑物。</span><span class="sxs-lookup"><span data-stu-id="874f4-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="874f4-160">没有做不到，只有想不到！</span><span class="sxs-lookup"><span data-stu-id="874f4-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="874f4-161">**富有表现力的虚拟形象：** 目视跟踪通过使用实时眼睛跟踪数据来使真实的头像显示用户正在查看的内容，以更有意义的3D 头像为目标。</span><span class="sxs-lookup"><span data-stu-id="874f4-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="874f4-162">**文本输入：** 目视跟踪可用作低工作量文本输入的替代方案，特别是当语音或手不方便使用时。</span><span class="sxs-lookup"><span data-stu-id="874f4-162">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="available-eye-tracking-data"></a><span data-ttu-id="874f4-163">可用的目视跟踪数据</span><span class="sxs-lookup"><span data-stu-id="874f4-163">Available eye tracking data</span></span>
<span data-ttu-id="874f4-164">在深入了解有关目视目视交互的特定设计准则之前，我们想要简要指出 HoloLens 2[目视跟踪 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)提供的功能。</span><span class="sxs-lookup"><span data-stu-id="874f4-164">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="874f4-165">开发人员可在大约_30 FPS （60 Hz）_ 上访问一只眼睛为眼睛的光线（注视原点和方向）。</span><span class="sxs-lookup"><span data-stu-id="874f4-165">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (60 Hz)_.</span></span>
<span data-ttu-id="874f4-166">有关如何访问目视跟踪数据的更多详细信息，请参阅我们的开发人员指南了解如何使用[DirectX 中的眼睛](gaze-in-directx.md)，并看看[Unity](https://aka.ms/mrtk-eyes)。</span><span class="sxs-lookup"><span data-stu-id="874f4-166">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="874f4-167">围绕实际目标围绕视觉角度，眼睛的眼睛约在1.5 度内（请参阅下图）。</span><span class="sxs-lookup"><span data-stu-id="874f4-167">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="874f4-168">由于预期的轻微 imprecisions，开发人员应计划围绕此下限值（例如 2.0-3.0 度）的某些边距，这可能会导致更舒适的体验。</span><span class="sxs-lookup"><span data-stu-id="874f4-168">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="874f4-169">下面将详细介绍如何处理小目标的选择。</span><span class="sxs-lookup"><span data-stu-id="874f4-169">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="874f4-170">要准确运行眼动跟踪，每个用户需要完成眼动跟踪用户校准。</span><span class="sxs-lookup"><span data-stu-id="874f4-170">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="874f4-171">![2 米远处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="874f4-171">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="874f4-172">*以2米距离为目标的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="874f4-172">*Optimal target size at a 2-meter distance*</span></span>

## <a name="calibration"></a><span data-ttu-id="874f4-173">校准</span><span class="sxs-lookup"><span data-stu-id="874f4-173">Calibration</span></span> 
<span data-ttu-id="874f4-174">为了使目视跟踪能准确地工作，每个用户都需要经历[跟踪用户校准](calibration.md)，用户必须查看一组全息目标。</span><span class="sxs-lookup"><span data-stu-id="874f4-174">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="874f4-175">这允许设备调整系统，以便为用户提供更舒适和更高的质量查看体验，并确保同时进行准确的目视跟踪。</span><span class="sxs-lookup"><span data-stu-id="874f4-175">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="874f4-176">目视跟踪应该适用于大多数用户，但在某些情况下，用户可能无法成功校准。</span><span class="sxs-lookup"><span data-stu-id="874f4-176">Eye tracking should work for most users, but there are cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="874f4-177">若要了解有关校准的详细信息，请查看[校准](calibration.md)。</span><span class="sxs-lookup"><span data-stu-id="874f4-177">To learn more about the calibration, please check [Calibration](calibration.md).</span></span>

## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="874f4-178">目视输入设计准则</span><span class="sxs-lookup"><span data-stu-id="874f4-178">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="874f4-179">构建充分利用快速移动目视目标的交互可能会很困难。</span><span class="sxs-lookup"><span data-stu-id="874f4-179">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="874f4-180">在本部分中，我们总结了在设计应用程序时要考虑的主要优点和挑战。</span><span class="sxs-lookup"><span data-stu-id="874f4-180">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="874f4-181">目视输入的优点</span><span class="sxs-lookup"><span data-stu-id="874f4-181">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="874f4-182">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="874f4-182">**High speed pointing.**</span></span> <span data-ttu-id="874f4-183">眼睛判断力是人为身体最快的响应判断力。</span><span class="sxs-lookup"><span data-stu-id="874f4-183">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="874f4-184">**不费力。**</span><span class="sxs-lookup"><span data-stu-id="874f4-184">**Low effort.**</span></span> <span data-ttu-id="874f4-185">几乎没有任何身体动作。</span><span class="sxs-lookup"><span data-stu-id="874f4-185">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="874f4-186">**隐含性。**</span><span class="sxs-lookup"><span data-stu-id="874f4-186">**Implicitness.**</span></span> <span data-ttu-id="874f4-187">用户通常会将其描述为 "构思阅读"，有关用户的目视变动的信息使系统可以知道用户打算参与哪个目标。</span><span class="sxs-lookup"><span data-stu-id="874f4-187">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="874f4-188">**备选的输入通道。**</span><span class="sxs-lookup"><span data-stu-id="874f4-188">**Alternative input channel.**</span></span> <span data-ttu-id="874f4-189">眼睛可为用户提供强大的支持输入，并根据用户的手眼协调从用户的经验中生成。</span><span class="sxs-lookup"><span data-stu-id="874f4-189">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="874f4-190">**视觉注意力。**</span><span class="sxs-lookup"><span data-stu-id="874f4-190">**Visual attention.**</span></span> <span data-ttu-id="874f4-191">另一个重要的优点是可以推断出用户正在关注的内容。</span><span class="sxs-lookup"><span data-stu-id="874f4-191">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="874f4-192">这可以帮助不同的应用程序领域，从更有效地评估不同设计，到协助的用户界面，增加了社交提示以进行远程通信。</span><span class="sxs-lookup"><span data-stu-id="874f4-192">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="874f4-193">简而言之，使用眼睛眼睛作为输入可提供快速且简单的上下文信号。</span><span class="sxs-lookup"><span data-stu-id="874f4-193">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="874f4-194">与其他输入（如*语音*和*手动*输入）相结合时，此功能特别强大，可以确认用户的意图。</span><span class="sxs-lookup"><span data-stu-id="874f4-194">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="874f4-195">眼睛为输入的挑战</span><span class="sxs-lookup"><span data-stu-id="874f4-195">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="874f4-196">如果有大量的强大功能，就有了许多责任。</span><span class="sxs-lookup"><span data-stu-id="874f4-196">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="874f4-197">虽然眼睛可用于创建符合 superhero 的用户体验，但若要清楚地说明这一点，还必须了解这一点。</span><span class="sxs-lookup"><span data-stu-id="874f4-197">While eye-gaze can be used to create satisfying user experiences that makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="874f4-198">下面讨论了一些需要考虑的问题，以及如何解决这些*问题*：</span><span class="sxs-lookup"><span data-stu-id="874f4-198">The following discusses some *challenges* to consider as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="874f4-199">**眼睛为 "始终打开"** 打开眼睛护盖后，眼睛开始 fixating 环境中的东西。</span><span class="sxs-lookup"><span data-stu-id="874f4-199">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="874f4-200">对每个外观进行操作并意外发出操作，因为您查看的内容太长会导致 unsatisfying 体验。</span><span class="sxs-lookup"><span data-stu-id="874f4-200">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="874f4-201">因此，建议将眼睛与*声音命令*、*笔势*、*按钮单击*或扩展停留结合起来，以触发选择目标。</span><span class="sxs-lookup"><span data-stu-id="874f4-201">Therefore we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="874f4-202">此解决方案还允许使用一种模式，在该模式下，用户可以自由地查找，而不会因触发某些事情而 involuntarily。</span><span class="sxs-lookup"><span data-stu-id="874f4-202">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="874f4-203">如果仅查看目标，则在设计视觉对象和听觉反馈时，还应考虑此问题。</span><span class="sxs-lookup"><span data-stu-id="874f4-203">This issue should also be considered when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="874f4-204">不要使用即时弹出式效果或惊悚的声音来让用户感到不知所措。</span><span class="sxs-lookup"><span data-stu-id="874f4-204">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="874f4-205">个很微妙为 key。</span><span class="sxs-lookup"><span data-stu-id="874f4-205">Subtlety is key.</span></span> <span data-ttu-id="874f4-206">稍后在谈到设计建议时，我们会进一步讨论一些最佳做法。</span><span class="sxs-lookup"><span data-stu-id="874f4-206">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="874f4-207">**观察与控制**假设您想要在墙壁上精确地伸直照片。</span><span class="sxs-lookup"><span data-stu-id="874f4-207">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="874f4-208">你会参照它的边框和四周，检查它是否平齐。</span><span class="sxs-lookup"><span data-stu-id="874f4-208">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="874f4-209">现在，如果您想要使用眼睛作为输入来移动图片，则可以想象出如何实现此目的。</span><span class="sxs-lookup"><span data-stu-id="874f4-209">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="874f4-210">有点难度，对不对？</span><span class="sxs-lookup"><span data-stu-id="874f4-210">Difficult, isn't it?</span></span> <span data-ttu-id="874f4-211">这介绍了输入和控制需要时，眼睛的双重角色。</span><span class="sxs-lookup"><span data-stu-id="874f4-211">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="874f4-212">**点击之前离开目标：** 对于快速目标选择，研究表明，用户的眼睛可以在结束手动单击之前继续进行（例如，airtap）。</span><span class="sxs-lookup"><span data-stu-id="874f4-212">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="874f4-213">因此，必须特别注意的是，将快速目视眼睛的信号与慢速控制输入（例如语音、双手、控制器）进行同步。</span><span class="sxs-lookup"><span data-stu-id="874f4-213">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="874f4-214">**小目标：** 当您尝试读取只是太小而无法阅读的文本时，您是否知道这种感觉？</span><span class="sxs-lookup"><span data-stu-id="874f4-214">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="874f4-215">这会使您感到非常紧张，因为您尝试重新调整您的眼睛，使您能够更好地专注。</span><span class="sxs-lookup"><span data-stu-id="874f4-215">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="874f4-216">当你强制用户使用目视目标选择在你的应用程序中太小的目标时，你可以在用户中调用这种感觉。</span><span class="sxs-lookup"><span data-stu-id="874f4-216">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="874f4-217">在设计方面，为了给用户建立一种愉悦舒适的体验，我们建议目标至少在 2° 的视角范围内，最好是再大一些。</span><span class="sxs-lookup"><span data-stu-id="874f4-217">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="874f4-218">**眼睛不规则的运动**我们的眼睛执行从固定到固定的快速移动。</span><span class="sxs-lookup"><span data-stu-id="874f4-218">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="874f4-219">观察录制的眼部运动扫描路径时你会发现，这些路径看起来是不规则的。</span><span class="sxs-lookup"><span data-stu-id="874f4-219">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="874f4-220">您的眼睛会在与*打印头*或*手间运动*比较的情况中快速跳转。</span><span class="sxs-lookup"><span data-stu-id="874f4-220">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="874f4-221">**跟踪可靠性：** 当眼睛在光线变化的环境中适应新的条件时，眼动跟踪准确度可能会略有下降。</span><span class="sxs-lookup"><span data-stu-id="874f4-221">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="874f4-222">虽然这应该不会影响应用程序的设计，因为准确性应该在2°限制范围内，因此，用户可能需要重新校准。</span><span class="sxs-lookup"><span data-stu-id="874f4-222">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="874f4-223">设计建议</span><span class="sxs-lookup"><span data-stu-id="874f4-223">Design recommendations</span></span>
<span data-ttu-id="874f4-224">下面是基于目视输入的所述优点和挑战的特定设计建议列表：</span><span class="sxs-lookup"><span data-stu-id="874f4-224">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="874f4-225">**眼睛看不到打印头：**</span><span class="sxs-lookup"><span data-stu-id="874f4-225">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="874f4-226">**考虑快速且不规则的眼部运动是否适合你的输入任务：** 虽然我们的快速而引人注目的变动非常适合于在我们的视图中快速选择目标，但它不适用于需要平滑输入轨迹（如绘图或 encircling 批注）的任务。</span><span class="sxs-lookup"><span data-stu-id="874f4-226">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="874f4-227">在这种情况下，应该首选手部或头部指向。</span><span class="sxs-lookup"><span data-stu-id="874f4-227">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="874f4-228">**避免直接将某些内容附加到用户的眼睛，如滑块或光标。**</span><span class="sxs-lookup"><span data-stu-id="874f4-228">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="874f4-229">如果是游标，这可能会导致 "fleeing cursor" 效果，原因是预计的眼睛眼睛略有偏差。</span><span class="sxs-lookup"><span data-stu-id="874f4-229">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="874f4-230">如果是滑块，则它可能与用眼睛控制滑块的双角色冲突，同时也需要检查对象是否位于正确的位置。</span><span class="sxs-lookup"><span data-stu-id="874f4-230">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="874f4-231">简而言之，用户可能会被淹没和分散注意力，尤其是在信号对于该用户不精确的情况下。</span><span class="sxs-lookup"><span data-stu-id="874f4-231">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="874f4-232">**将眼睛与其他输入组合在一起：** 将眼睛跟踪与其他输入（如手势、语音命令或按钮按下）的集成具有以下优点：</span><span class="sxs-lookup"><span data-stu-id="874f4-232">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="874f4-233">**可以自由观察：** 考虑到我们的主要角色是观察我们的环境，这是一项重要的用户，而不触发任何（视觉、听觉等）反馈或操作。</span><span class="sxs-lookup"><span data-stu-id="874f4-233">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="874f4-234">将目视跟踪与其他输入控件结合起来允许在目视跟踪观察和输入控制模式之间平稳过渡。</span><span class="sxs-lookup"><span data-stu-id="874f4-234">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="874f4-235">**强大的上下文提供程序：** 使用有关用户在 uttering 语音命令或执行手手势时所处的位置和内容的信息，可以在视图字段间无缝排列输入。</span><span class="sxs-lookup"><span data-stu-id="874f4-235">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="874f4-236">例如：发出“放在这里”语音命令后，只需注视某个目标和目的地，就能快速顺畅地在场景中选择和放置全息影像。</span><span class="sxs-lookup"><span data-stu-id="874f4-236">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="874f4-237">**同步多模输入的需求（“点击之前离开”问题）：** 将快速目视运动与更复杂的附加输入（例如长的语音命令或手势）相结合，就能在完成附加输入命令之前继续眼睛的风险。</span><span class="sxs-lookup"><span data-stu-id="874f4-237">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="874f4-238">因此，如果您创建自己的输入控件（例如，自定义笔势），请确保记录此输入或大致持续时间的开始，以将其与用户过去查看的内容相关联。</span><span class="sxs-lookup"><span data-stu-id="874f4-238">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="874f4-239">**眼动追踪输入的微妙反馈：** 当查看目标以指示系统正在按预期工作但应保持微妙时，提供反馈很有用。</span><span class="sxs-lookup"><span data-stu-id="874f4-239">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="874f4-240">这可能包括缓慢混合、放大和缩小、视觉对象突出显示或执行其他微妙目标行为（如缓慢增加目标大小），以指示系统正确检测到用户正在查看目标而不不必要地中断用户的当前工作流。</span><span class="sxs-lookup"><span data-stu-id="874f4-240">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="874f4-241">**避免强制使用非自然的眼部运动作为输入：** 不要强制用户执行特定的目视运动（注视手势）来触发应用程序中的操作。</span><span class="sxs-lookup"><span data-stu-id="874f4-241">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="874f4-242">**考虑不精确性：** 我们区分对用户显而易见的两种类型的 imprecisions：偏移和抖动。</span><span class="sxs-lookup"><span data-stu-id="874f4-242">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="874f4-243">解决偏移量的最简单方法是提供足够大的目标来与进行交互。</span><span class="sxs-lookup"><span data-stu-id="874f4-243">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="874f4-244">建议使用大于2°的视觉角度作为参考。</span><span class="sxs-lookup"><span data-stu-id="874f4-244">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="874f4-245">例如，当您拉伸 arm 时，缩略图约为2°。</span><span class="sxs-lookup"><span data-stu-id="874f4-245">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="874f4-246">因此，我们的指导如下：</span><span class="sxs-lookup"><span data-stu-id="874f4-246">This leads to the following guidance:</span></span>
    - <span data-ttu-id="874f4-247">不要强制用户选择 "小目标"。</span><span class="sxs-lookup"><span data-stu-id="874f4-247">Do not force users to select tiny targets.</span></span> <span data-ttu-id="874f4-248">研究表明，如果目标足够大，并且系统设计良好，则用户会将其交互描述为轻松和神奇。</span><span class="sxs-lookup"><span data-stu-id="874f4-248">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="874f4-249">如果目标太小，则用户就会将体验描述为费力、令人沮丧。</span><span class="sxs-lookup"><span data-stu-id="874f4-249">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="874f4-250">开发指南：如果眼睛跟踪不可用，该怎么办？</span><span class="sxs-lookup"><span data-stu-id="874f4-250">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="874f4-251">在某些情况下，由于各种原因（包括但不限于），应用无法接收任何目视跟踪数据：</span><span class="sxs-lookup"><span data-stu-id="874f4-251">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="874f4-252">用户跳过了眼睛跟踪校准。</span><span class="sxs-lookup"><span data-stu-id="874f4-252">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="874f4-253">用户进行了校准，但决定不向应用程序授予使用其眼跟踪数据的权限。</span><span class="sxs-lookup"><span data-stu-id="874f4-253">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="874f4-254">用户具有唯一的眼镜，或系统尚不支持的某种眼睛状态。</span><span class="sxs-lookup"><span data-stu-id="874f4-254">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="874f4-255">外部因素抑制了一种可靠的眼睛跟踪，如在眼睛前面的头发上出现污迹面板或眼镜、强烈直接阳光和 occlusions。</span><span class="sxs-lookup"><span data-stu-id="874f4-255">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="874f4-256">作为应用开发人员，这意味着你需要考虑如何支持目视跟踪数据可能不可用的用户。</span><span class="sxs-lookup"><span data-stu-id="874f4-256">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="874f4-257">下面我们首先介绍如何检测目视跟踪是否可用，以及如何解决不能用于不同应用程序的情况。</span><span class="sxs-lookup"><span data-stu-id="874f4-257">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="874f4-258">1.如何检测目视跟踪可用</span><span class="sxs-lookup"><span data-stu-id="874f4-258">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="874f4-259">可以通过几个检查来确定是否有目视跟踪数据可用。</span><span class="sxs-lookup"><span data-stu-id="874f4-259">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="874f4-260">检查是否 。</span><span class="sxs-lookup"><span data-stu-id="874f4-260">Check whether...</span></span>
* <span data-ttu-id="874f4-261">...系统完全支持目视跟踪。</span><span class="sxs-lookup"><span data-stu-id="874f4-261">... the system supports eye tracking at all.</span></span> <span data-ttu-id="874f4-262">调用以下*方法*：[EyesPose. IsSupported （）](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="874f4-262">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="874f4-263">...校准了用户。</span><span class="sxs-lookup"><span data-stu-id="874f4-263">... the user is calibrated.</span></span> <span data-ttu-id="874f4-264">调用以下*属性*：[EyesPose. IsCalibrationValid。](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="874f4-264">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="874f4-265">...用户已将你的应用权限授予使用其目视跟踪数据：检索当前的 _"GazeInputAccessStatus"_ 。</span><span class="sxs-lookup"><span data-stu-id="874f4-265">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="874f4-266">有关如何执行此操作的示例，请参阅[请求访问注视输入](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input)。</span><span class="sxs-lookup"><span data-stu-id="874f4-266">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="874f4-267">此外，你可能需要通过在收到的目视跟踪数据更新之间添加超时，并以其他方式回退到下面所述的打印头来检查眼睛跟踪数据是否过时。</span><span class="sxs-lookup"><span data-stu-id="874f4-267">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="874f4-268">如上所述，眼睛跟踪数据可能不可用的原因有多种。</span><span class="sxs-lookup"><span data-stu-id="874f4-268">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="874f4-269">尽管某些用户可能已特意决定撤消对其眼睛跟踪数据的访问，但对于不提供对其眼睛跟踪数据的访问权限的隐私性的用户体验的不满，这一点很有可能是不可能的。</span><span class="sxs-lookup"><span data-stu-id="874f4-269">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="874f4-270">因此，如果你的应用程序使用目视跟踪，并且这是体验的重要部分，我们建议你清楚地将此信息传递给用户。</span><span class="sxs-lookup"><span data-stu-id="874f4-270">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="874f4-271">请通知用户，目视跟踪对于你的应用程序至关重要（甚至可能会列出一些增强的功能）以充分利用你的应用程序，从而帮助用户更好地了解他们所放弃的内容。</span><span class="sxs-lookup"><span data-stu-id="874f4-271">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="874f4-272">帮助用户确定目视跟踪可能不工作的原因（基于上述检查），并提供一些建议来快速解决潜在问题。</span><span class="sxs-lookup"><span data-stu-id="874f4-272">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="874f4-273">例如，如果您可以检测到系统支持目视跟踪，则用户会进行校准，甚至会获得其权限，但不会收到任何眼睛跟踪数据，这可能会导致某些其他问题，如污迹或眼睛封闭像素。</span><span class="sxs-lookup"><span data-stu-id="874f4-273">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="874f4-274">但请注意，在某些情况下，眼睛跟踪可能只是不能正常工作。</span><span class="sxs-lookup"><span data-stu-id="874f4-274">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="874f4-275">因此，在应用中启用眼睛跟踪时，可以通过允许消除甚至禁用提醒来过于这种情况。</span><span class="sxs-lookup"><span data-stu-id="874f4-275">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="874f4-276">2.使用红眼作为主要输入指针的应用回退</span><span class="sxs-lookup"><span data-stu-id="874f4-276">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="874f4-277">如果你的应用程序使用目视看眼作为指针输入来快速选择场景中的全息影像，但眼睛跟踪数据不可用，则建议回退到打印头并开始显示眼睛良好的光标。</span><span class="sxs-lookup"><span data-stu-id="874f4-277">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="874f4-278">建议使用超时值（例如500–1500毫秒）来确定是否要切换。</span><span class="sxs-lookup"><span data-stu-id="874f4-278">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="874f4-279">这是为了防止在系统每次由于快速目视动作或传情动漫或传情动漫而发生跟踪时弹出游标。</span><span class="sxs-lookup"><span data-stu-id="874f4-279">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="874f4-280">如果你是一名 Unity 开发人员，则已在混合现实工具包中处理自动回退到打印头。</span><span class="sxs-lookup"><span data-stu-id="874f4-280">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="874f4-281">如果你是 DirectX 开发人员，则需要自行处理此开关。</span><span class="sxs-lookup"><span data-stu-id="874f4-281">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="874f4-282">3.其他目视跟踪特定应用程序的回退</span><span class="sxs-lookup"><span data-stu-id="874f4-282">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="874f4-283">您的应用程序可以采用专门为眼睛定制的独特方式（例如，为头像形象提供动画或基于眼睛的关注热图，它依赖于有关视觉对象的精确信息）。</span><span class="sxs-lookup"><span data-stu-id="874f4-283">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="874f4-284">在这种情况下，不会有任何明确的回退。</span><span class="sxs-lookup"><span data-stu-id="874f4-284">In this case, there is no clear fallback.</span></span> <span data-ttu-id="874f4-285">如果目视跟踪不可用，则可能只需禁用这些功能。</span><span class="sxs-lookup"><span data-stu-id="874f4-285">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span> 

<br>

<span data-ttu-id="874f4-286">在此页面中，你可以获得一个良好的概述，使你开始了解 HoloLens 2 的眼睛跟踪和目视眼睛输入的角色。</span><span class="sxs-lookup"><span data-stu-id="874f4-286">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="874f4-287">若要开始开发，请查看我们关于[Unity 中眼睛](https://aka.ms/mrtk-eyes)的信息并观看[DirectX 中的眼睛](gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="874f4-287">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="874f4-288">请参阅</span><span class="sxs-lookup"><span data-stu-id="874f4-288">See also</span></span>
* [<span data-ttu-id="874f4-289">目视观察 DirectX</span><span class="sxs-lookup"><span data-stu-id="874f4-289">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="874f4-290">目视看 Unity （混合现实工具包）</span><span class="sxs-lookup"><span data-stu-id="874f4-290">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="874f4-291">校准</span><span class="sxs-lookup"><span data-stu-id="874f4-291">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="874f4-292">头部凝视并提交</span><span class="sxs-lookup"><span data-stu-id="874f4-292">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="874f4-293">手势</span><span class="sxs-lookup"><span data-stu-id="874f4-293">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="874f4-294">语音输入</span><span class="sxs-lookup"><span data-stu-id="874f4-294">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="874f4-295">运动控制器</span><span class="sxs-lookup"><span data-stu-id="874f4-295">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="874f4-296">舒适</span><span class="sxs-lookup"><span data-stu-id="874f4-296">Comfort</span></span>](comfort.md)
