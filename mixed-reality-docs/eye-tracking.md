---
title: 眼动跟踪
description: 眼动跟踪
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 眼动跟踪, 混合现实, 输入, 视线
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453701"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="6015e-104">HoloLens 2 中的眼动跟踪</span><span class="sxs-lookup"><span data-stu-id="6015e-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="6015e-105">HoloLens 2 提供令人难以置信的功能来让开发人员利用用户正在注视的对象的相关信息，它将全息体验中的上下文和人类理解能力提高了一个全新的境界。</span><span class="sxs-lookup"><span data-stu-id="6015e-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="6015e-106">本网页概述开发人员如何在不同的用例中利用眼动跟踪，以及在设计基于视线的用户界面时要注意哪些问题。</span><span class="sxs-lookup"><span data-stu-id="6015e-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="6015e-107">用例</span><span class="sxs-lookup"><span data-stu-id="6015e-107">Use cases</span></span>
<span data-ttu-id="6015e-108">眼动跟踪可让应用程序实时跟踪用户正在注视的位置。</span><span class="sxs-lookup"><span data-stu-id="6015e-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="6015e-109">本部分介绍混合现实中的眼动跟踪可以实现的一些潜在用例以及新颖的交互方式。</span><span class="sxs-lookup"><span data-stu-id="6015e-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="6015e-110">在开始之前，请注意本文稍后会多次提到[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)，其中提供了多个有趣且知识点非常丰富的示例，用于演示眼动跟踪的用法，例如，快速轻松地选择视线支持的目标，以及根据用户注视的位置自动滚动文本。</span><span class="sxs-lookup"><span data-stu-id="6015e-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="6015e-111">用户意图</span><span class="sxs-lookup"><span data-stu-id="6015e-111">User intent</span></span>    
<span data-ttu-id="6015e-112">有关用户注视位置的信息为语音、手和控制器等**其他输入**提供了丰富的上下文。</span><span class="sxs-lookup"><span data-stu-id="6015e-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="6015e-113">可在各种任务中使用此信息。</span><span class="sxs-lookup"><span data-stu-id="6015e-113">This can be used for various tasks.</span></span>
<span data-ttu-id="6015e-114">例如，这些任务可能包括，注视某个全息影像并讲出“选择”（另请参阅[头部跟踪视线和提交](gaze-and-commit.md)），或者讲出“将这个...”，然后注视要将该全息影像放到的某个位置并讲出“...放到这里”，即可快速轻松地在场景中切换**目标位置**。</span><span class="sxs-lookup"><span data-stu-id="6015e-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="6015e-115">在[混合现实工具包 - 视线支持的目标选择](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合现实工具包 - 视线支持的目标定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中可以找到相关示例。</span><span class="sxs-lookup"><span data-stu-id="6015e-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="6015e-116">用户意图的其他示例可能包括，使用用户注视的对象的相关信息的信息来增强具体化的虚拟代理和交互式全息影像的互动能力。</span><span class="sxs-lookup"><span data-stu-id="6015e-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="6015e-117">例如，虚拟代理能够根据当前查看的内容调整可用选项及其行为。</span><span class="sxs-lookup"><span data-stu-id="6015e-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="6015e-118">隐式操作</span><span class="sxs-lookup"><span data-stu-id="6015e-118">Implicit actions</span></span>
<span data-ttu-id="6015e-119">隐式操作的类别与用户意图密切相关。</span><span class="sxs-lookup"><span data-stu-id="6015e-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="6015e-120">其思路是，全息或用户界面元素凭借某种本能做出反应，就好像用户根本不是在与系统交互，而像是两者已同步。例如，一个非常成功的例子是**基于视线的自动滚屏**。</span><span class="sxs-lookup"><span data-stu-id="6015e-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="6015e-121">其思路非常简单：用户可以不中断地阅读文本。</span><span class="sxs-lookup"><span data-stu-id="6015e-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="6015e-122">文本会根据用户的阅读进度逐渐移动。</span><span class="sxs-lookup"><span data-stu-id="6015e-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="6015e-123">一个重要的特征是，滚屏速度与用户的阅读速度相适应。</span><span class="sxs-lookup"><span data-stu-id="6015e-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="6015e-124">另一个例子是**视线支持的缩放和平移**：用户可以感受到他们所要关注的内容立即涌现在眼前。</span><span class="sxs-lookup"><span data-stu-id="6015e-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="6015e-125">可以通过语音或手动输入来触发缩放和控制缩放速度，这对于提供控制感和避免出现眼花缭乱方面非常重要（下面会更详细地讨论这些设计准则）。</span><span class="sxs-lookup"><span data-stu-id="6015e-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="6015e-126">例如，在放大后，用户可以通过视线顺畅地观看其周边的街景。</span><span class="sxs-lookup"><span data-stu-id="6015e-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="6015e-127">[混合现实工具包 - 视线支持的导航](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)示例中可以找到此类交互的演示。</span><span class="sxs-lookup"><span data-stu-id="6015e-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="6015e-128">隐式操作的其他用例包括： </span><span class="sxs-lookup"><span data-stu-id="6015e-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="6015e-129">**智能通知：** 当你专心浏览某段内容时，突然弹出的通知是否让你觉得很恼火？</span><span class="sxs-lookup"><span data-stu-id="6015e-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="6015e-130">根据用户当前正在专心浏览的位置，你可以让事情变得更美好！</span><span class="sxs-lookup"><span data-stu-id="6015e-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="6015e-131">可以在偏离用户当前正在观看的位置显示通知，以避免分散其注意力，并在他们阅读完通知后自动隐藏通知。</span><span class="sxs-lookup"><span data-stu-id="6015e-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="6015e-132">**体贴入微的全息影像：** 注视时可做出微秒反应的全息影像。</span><span class="sxs-lookup"><span data-stu-id="6015e-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="6015e-133">这种反应包括柔和地让 UI 元素发光、当虚拟宠物开始回头看你时缓慢绽放花朵，或者在你长时间凝视后尝试避开你的视线。</span><span class="sxs-lookup"><span data-stu-id="6015e-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="6015e-134">这可以在应用中提供一种有趣的互动感和满足感。</span><span class="sxs-lookup"><span data-stu-id="6015e-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="6015e-135">注意力跟踪</span><span class="sxs-lookup"><span data-stu-id="6015e-135">Attention tracking</span></span>   
<span data-ttu-id="6015e-136">有关用户注视位置的信息是评估设计可用性以及在有效工作流中识别问题的强有力手段。</span><span class="sxs-lookup"><span data-stu-id="6015e-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="6015e-137">到目前为止，眼动追踪可视化和分析在各种应用领域中司空见惯。</span><span class="sxs-lookup"><span data-stu-id="6015e-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="6015e-138">HoloLens 2 为这种认知提供了一个新的维度，3D 全息影像可以放在真实的上下文中，并可以一起评估。</span><span class="sxs-lookup"><span data-stu-id="6015e-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="6015e-139">[混合现实工具包](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供了有关记录、加载和可视化眼动跟踪数据的基本示例。</span><span class="sxs-lookup"><span data-stu-id="6015e-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="6015e-140">此领域的其他应用场景包括：</span><span class="sxs-lookup"><span data-stu-id="6015e-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="6015e-141">**远程视线可视化：** 例如，可视化远程协作者正在注视的内容，以确保正确理解并遵循指示。</span><span class="sxs-lookup"><span data-stu-id="6015e-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="6015e-142">**用户调研：** 注意力跟踪可用于探索新手与专家用户对内容进行视觉分析的方式，或者在复杂任务中的手眼协调性（例如，分析医疗数据或操作机器时）。</span><span class="sxs-lookup"><span data-stu-id="6015e-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="6015e-143">**训练模拟和性能监视：** 更有效地识别执行流中的瓶颈，实践并优化任务的执行。</span><span class="sxs-lookup"><span data-stu-id="6015e-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="6015e-144">**设计评估、广告和营销调查：** 眼动跟踪是市场调查中评估网站和产品设计的一种常用工具。</span><span class="sxs-lookup"><span data-stu-id="6015e-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="6015e-145">其他用例</span><span class="sxs-lookup"><span data-stu-id="6015e-145">Additional use cases</span></span>
- <span data-ttu-id="6015e-146">**游戏：** 是否曾经想过拥有超能力？</span><span class="sxs-lookup"><span data-stu-id="6015e-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="6015e-147">机会来了！</span><span class="sxs-lookup"><span data-stu-id="6015e-147">Here's your chance!</span></span> <span data-ttu-id="6015e-148">注视全息影像，使之漂浮起来。</span><span class="sxs-lookup"><span data-stu-id="6015e-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="6015e-149">从眼睛发射激光束。</span><span class="sxs-lookup"><span data-stu-id="6015e-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="6015e-150">将敌人变成石头，或将其冻住！</span><span class="sxs-lookup"><span data-stu-id="6015e-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="6015e-151">使用 X 光透视来扫描建筑物。</span><span class="sxs-lookup"><span data-stu-id="6015e-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="6015e-152">没有做不到，只有想不到！</span><span class="sxs-lookup"><span data-stu-id="6015e-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="6015e-153">**富有表现力的虚拟形象：** 眼动跟踪有助于创建更富表现力的 3D 虚拟形象，因为它可以使用实时眼动跟踪数据来制作虚拟形象的眼睛动画，指示用户当前正在注视哪些内容。</span><span class="sxs-lookup"><span data-stu-id="6015e-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="6015e-154">它还能添加更多的眨单眼和眨眼表情。</span><span class="sxs-lookup"><span data-stu-id="6015e-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="6015e-155">**文本输入：** 可将眼动跟踪用作一种较为轻松的文本输入方式，而且输入过程比较有趣，尤其是不方便使用语音或双手时。</span><span class="sxs-lookup"><span data-stu-id="6015e-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="6015e-156">眼动跟踪 API</span><span class="sxs-lookup"><span data-stu-id="6015e-156">Eye tracking API</span></span>
<span data-ttu-id="6015e-157">在详细了解视线交互的具体设计准则之前，我们希望简要描述一下 HoloLens 2 眼动跟踪器所提供的功能。</span><span class="sxs-lookup"><span data-stu-id="6015e-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="6015e-158">可通过 `Windows.Perception.People.EyesPose` 访问[眼动跟踪 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)。</span><span class="sxs-lookup"><span data-stu-id="6015e-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="6015e-159">它向开发人员提供单一视线（视线原点和方向）。</span><span class="sxs-lookup"><span data-stu-id="6015e-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="6015e-160">眼动追踪器以大约 _30 FPS_ 的速率提供数据。</span><span class="sxs-lookup"><span data-stu-id="6015e-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="6015e-161">预测的视线位于</span><span class="sxs-lookup"><span data-stu-id="6015e-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="6015e-162">围绕实际注视目标的圆周 1.0 - 1.5 度视角范围内。</span><span class="sxs-lookup"><span data-stu-id="6015e-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="6015e-163">预期存在轻微的不精确性，因此，应该围绕此下限值规划好一定的余隙。</span><span class="sxs-lookup"><span data-stu-id="6015e-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="6015e-164">下面会更详细地讨论此问题。</span><span class="sxs-lookup"><span data-stu-id="6015e-164">We will discuss this more below.</span></span> <span data-ttu-id="6015e-165">要准确运行眼动跟踪，每个用户需要完成眼动跟踪用户校准。</span><span class="sxs-lookup"><span data-stu-id="6015e-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="6015e-166">![2 米远处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="6015e-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="6015e-167">*2 米远处的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="6015e-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="6015e-168">视线设计准则</span><span class="sxs-lookup"><span data-stu-id="6015e-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="6015e-169">构建利用快速移动的视线定位功能的交互式应用可能有难度。</span><span class="sxs-lookup"><span data-stu-id="6015e-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="6015e-170">本部分汇总了视线输入的主要优势，以及在设计应用时需要考虑到的一些难题。</span><span class="sxs-lookup"><span data-stu-id="6015e-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="6015e-171">视线输入的优势</span><span class="sxs-lookup"><span data-stu-id="6015e-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="6015e-172">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="6015e-172">**High speed pointing.**</span></span> <span data-ttu-id="6015e-173">眼部肌肉在人体中是反应速度最快的肌肉。</span><span class="sxs-lookup"><span data-stu-id="6015e-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="6015e-174">**不费力。**</span><span class="sxs-lookup"><span data-stu-id="6015e-174">**Low effort.**</span></span> <span data-ttu-id="6015e-175">几乎没有任何身体动作。</span><span class="sxs-lookup"><span data-stu-id="6015e-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="6015e-176">**隐含性。**</span><span class="sxs-lookup"><span data-stu-id="6015e-176">**Implicitness.**</span></span> <span data-ttu-id="6015e-177">此功能通常被用户描述为“读心术”。有关用户眼部动作的信息可让系统知道用户想要与哪个目标互动。</span><span class="sxs-lookup"><span data-stu-id="6015e-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="6015e-178">**备选的输入通道。**</span><span class="sxs-lookup"><span data-stu-id="6015e-178">**Alternative input channel.**</span></span> <span data-ttu-id="6015e-179">视线跟踪可为多年以来根据用户手眼协调性实现的手写和语音输入体验提供强有力的支持。</span><span class="sxs-lookup"><span data-stu-id="6015e-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="6015e-180">**视觉注意力。**</span><span class="sxs-lookup"><span data-stu-id="6015e-180">**Visual attention.**</span></span> <span data-ttu-id="6015e-181">另一个重要优势是能够推断出用户正在关注哪种内容。</span><span class="sxs-lookup"><span data-stu-id="6015e-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="6015e-182">这可以在各种应用领域中提供帮助，包括有效评估不同的设计，以帮助开发出更智能的用户界面，以及增强社交手段来实现远程通信。</span><span class="sxs-lookup"><span data-stu-id="6015e-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="6015e-183">简单地说，使用视线作为输入有可能会提供快速且毫不费力的上下文信号 - 与其他输入（例如，使用语音和人工输入来确认用户意图）结合使用时，此功能尤为强大。  </span><span class="sxs-lookup"><span data-stu-id="6015e-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="6015e-184">将视线用作输入所带来的难题</span><span class="sxs-lookup"><span data-stu-id="6015e-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="6015e-185">能力越大，责任也越大：尽管视线跟踪像超级英雄一样可以打造梦幻的用户体验，但相应地考虑到它的不足之处也很重要。</span><span class="sxs-lookup"><span data-stu-id="6015e-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="6015e-186">下面讨论在使用视线输入时要考虑到的一些难题，以及如何解决这些难题： </span><span class="sxs-lookup"><span data-stu-id="6015e-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="6015e-187">**视线始终是开启的。** 张开双眼的那一刻，眼睛就会开始注视环境中的事物。</span><span class="sxs-lookup"><span data-stu-id="6015e-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="6015e-188">对每种表情作出的反应，以及由于长时间注视某个事物而意外产生的动作都会导致出现可怕的体验！</span><span class="sxs-lookup"><span data-stu-id="6015e-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="6015e-189">正因如此，我们建议将视线跟踪与语音命令、手势、按钮点击或延长的停顿相结合来触发目标选择。   </span><span class="sxs-lookup"><span data-stu-id="6015e-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="6015e-190">这种解决方法还可以让用户进入一种可以自由环顾的模式，而不会迫使他们不情愿地触发某个操作。</span><span class="sxs-lookup"><span data-stu-id="6015e-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="6015e-191">设计视觉和听觉反馈（只需注视某个目标）时，也应考虑到此问题。</span><span class="sxs-lookup"><span data-stu-id="6015e-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="6015e-192">不要使用即时弹出式效果或惊悚的声音来让用户感到不知所措。</span><span class="sxs-lookup"><span data-stu-id="6015e-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="6015e-193">微妙才是关键所在！</span><span class="sxs-lookup"><span data-stu-id="6015e-193">Subtlety is key!</span></span> <span data-ttu-id="6015e-194">稍后在谈到设计建议时，我们会进一步讨论一些最佳做法。</span><span class="sxs-lookup"><span data-stu-id="6015e-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="6015e-195">**观测与控制。** 假设你要在墙上精确地将某幅照片摆放整齐。</span><span class="sxs-lookup"><span data-stu-id="6015e-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="6015e-196">你会参照它的边框和四周，检查它是否平齐。</span><span class="sxs-lookup"><span data-stu-id="6015e-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="6015e-197">现在想一想，如果你同时要使用视线作为输入来移动图片，如何做到平齐地移动呢？</span><span class="sxs-lookup"><span data-stu-id="6015e-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="6015e-198">有点难度，对不对？</span><span class="sxs-lookup"><span data-stu-id="6015e-198">Difficult, isn't it?</span></span> <span data-ttu-id="6015e-199">这就是视线在同时用于输入和控制时发挥的双重作用。</span><span class="sxs-lookup"><span data-stu-id="6015e-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="6015e-200">**点击之前离开目标：** 在快速目标选择方面，有研究表明，在确定手动点击（例如隔空敲击）之前，用户的视线可能会移动。</span><span class="sxs-lookup"><span data-stu-id="6015e-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="6015e-201">因此，将快速视线信号与慢速控制输入（例如语音、手、控制器）同步时，必须特别小心。</span><span class="sxs-lookup"><span data-stu-id="6015e-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="6015e-202">**小目标：** 你是否体会过阅读的文字太小，以致不能舒适阅读时的那种感受？</span><span class="sxs-lookup"><span data-stu-id="6015e-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="6015e-203">眼睛的紧张感会让你感到疲倦，因为你要尝试重新调整双眼，以便更好地聚焦。</span><span class="sxs-lookup"><span data-stu-id="6015e-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="6015e-204">如果在应用中使用视线定位来强迫用户选择太小的目标，则用户可能就会产生这种感觉。</span><span class="sxs-lookup"><span data-stu-id="6015e-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="6015e-205">在设计方面，为了给用户建立一种愉悦舒适的体验，我们建议目标至少在 2° 的视角范围内，最好是再大一些。</span><span class="sxs-lookup"><span data-stu-id="6015e-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="6015e-206">**不规则的视线移动。** 我们的眼睛会从一个位置快速移动到另一个位置。</span><span class="sxs-lookup"><span data-stu-id="6015e-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="6015e-207">观察录制的眼部运动扫描路径时你会发现，这些路径看起来是不规则的。</span><span class="sxs-lookup"><span data-stu-id="6015e-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="6015e-208">与头部跟踪视线和手部运动相比，眼睛的移动速度飞快，是本能跳动的。  </span><span class="sxs-lookup"><span data-stu-id="6015e-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="6015e-209">**跟踪可靠性：** 当眼睛在光线变化的环境中适应新的条件时，眼动跟踪准确度可能会略有下降。</span><span class="sxs-lookup"><span data-stu-id="6015e-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="6015e-210">这不一定会影响应用的设计，因为准确度应该处于上述 2° 限制范围内。</span><span class="sxs-lookup"><span data-stu-id="6015e-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="6015e-211">但这可能意味着，用户需要再次运行校准。</span><span class="sxs-lookup"><span data-stu-id="6015e-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="6015e-212">设计建议</span><span class="sxs-lookup"><span data-stu-id="6015e-212">Design recommendations</span></span>
<span data-ttu-id="6015e-213">下面我们根据所述的视线输入优势和难题列出了具体的设计建议：</span><span class="sxs-lookup"><span data-stu-id="6015e-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="6015e-214">**视线 != 头部跟踪视线：**</span><span class="sxs-lookup"><span data-stu-id="6015e-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="6015e-215">**考虑快速且不规则的眼部运动是否适合你的输入任务：** 尽管快速且不规则的眼部运动非常适合用于快速选择视场中的目标，但它不是很适合用于需要平滑输入轨迹的任务（例如，绘图或圈住批注）。</span><span class="sxs-lookup"><span data-stu-id="6015e-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="6015e-216">在这种情况下，应该首选手部或头部指向。</span><span class="sxs-lookup"><span data-stu-id="6015e-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="6015e-217">**避免将物件直接对准用户的视线（例如滑块或光标）。**</span><span class="sxs-lookup"><span data-stu-id="6015e-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="6015e-218">以光标为例，这可能会导致“光标逃逸”效应，因为投影的视线信号中存在微小的偏移。</span><span class="sxs-lookup"><span data-stu-id="6015e-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="6015e-219">以滑块为例，它会与视线既要通过眼睛控制滑块，又要检查对象是否位于正确的位置这种双重角色相冲突。</span><span class="sxs-lookup"><span data-stu-id="6015e-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="6015e-220">简单而言，用户可能很快就会感到眼花缭乱，注意力分散，尤其是信号对于该用户不精确时。</span><span class="sxs-lookup"><span data-stu-id="6015e-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="6015e-221">**将视线与其他输入相结合：** 将眼动跟踪与其他输入（例如手势、语音命令或按钮）相集成可带来以下优势：</span><span class="sxs-lookup"><span data-stu-id="6015e-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="6015e-222">**可以自由观察：** 假设我们的眼睛主要用于观察环境，则必须允许用户在不触发任何（视觉、听觉...）反馈或操作的情况下环顾四周。</span><span class="sxs-lookup"><span data-stu-id="6015e-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="6015e-223">将 ET 与其他输入控制相结合，可在 ET 观察与输入控制模式之间平稳过渡。</span><span class="sxs-lookup"><span data-stu-id="6015e-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="6015e-224">**强大的上下文提供程序：** 在发出语音命令或执行手势的同时使用有关用户正在注视哪个位置的信息，可以毫不费力地在整个视场中传送输入。</span><span class="sxs-lookup"><span data-stu-id="6015e-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="6015e-225">示例包括：发出“放在这里”语音命令后，只需注视某个目标和目的地，就能快速顺畅地在场景中选择和放置全息影像。</span><span class="sxs-lookup"><span data-stu-id="6015e-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="6015e-226">**同步多模输入的需求（“点击之前离开”问题）：** 将快速眼部运动与更复杂的附加输入（例如，较长的语音命令或手势）相结合会带来在完成附加输入命令之前移动视线的风险。</span><span class="sxs-lookup"><span data-stu-id="6015e-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="6015e-227">因此，如果你要创建自己的输入控件（例如自定义手势），请务必记录此输入的发生时间或近似持续时间，使之与用户过去注视的物件相关联。</span><span class="sxs-lookup"><span data-stu-id="6015e-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="6015e-228">**眼动追踪输入的微妙反馈：** 如果某个目标已被注视（表示系统正在按预期方式工作）但应保持微妙的状态，则最好是提供反馈。</span><span class="sxs-lookup"><span data-stu-id="6015e-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="6015e-229">这可能包括，慢慢融入/排除视觉关注点，或执行其他微妙的目标行为，例如慢动作（例如略微增大目标），以指示系统已正确检测到用户正在注视目标，但是，不要无谓地中断用户的当前工作流。</span><span class="sxs-lookup"><span data-stu-id="6015e-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="6015e-230">**避免强制使用非自然的眼部运动作为输入：** 不要强迫用户执行特定的眼部运动（注视手势）来触发应用中的操作。</span><span class="sxs-lookup"><span data-stu-id="6015e-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="6015e-231">**考虑不精确性：** 我们区分两种对用户而言非常重要的不精确性：偏移和抖动。</span><span class="sxs-lookup"><span data-stu-id="6015e-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="6015e-232">解决偏移的最简单方法是提供足够大的交互目标（视角 2° – 供参考：张开双臂 (1) 时，你的缩略图的视角大约为 2°）。</span><span class="sxs-lookup"><span data-stu-id="6015e-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="6015e-233">因此，我们的指导如下：</span><span class="sxs-lookup"><span data-stu-id="6015e-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="6015e-234">不要强迫用户选择微小的目标：研究表明，如果目标足够大（并且系统设计得当），则用户就会将交互效果描述为轻松且神奇。</span><span class="sxs-lookup"><span data-stu-id="6015e-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="6015e-235">如果目标太小，则用户就会将体验描述为费力、令人沮丧。</span><span class="sxs-lookup"><span data-stu-id="6015e-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="6015e-236">另请参阅</span><span class="sxs-lookup"><span data-stu-id="6015e-236">See also</span></span>
* [<span data-ttu-id="6015e-237">头部凝视并提交</span><span class="sxs-lookup"><span data-stu-id="6015e-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="6015e-238">DirectX 中的头部和眼部凝视</span><span class="sxs-lookup"><span data-stu-id="6015e-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="6015e-239">Unity（混合现实工具包）中的视线跟踪</span><span class="sxs-lookup"><span data-stu-id="6015e-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="6015e-240">手势</span><span class="sxs-lookup"><span data-stu-id="6015e-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="6015e-241">语音输入</span><span class="sxs-lookup"><span data-stu-id="6015e-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="6015e-242">运动控制器</span><span class="sxs-lookup"><span data-stu-id="6015e-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="6015e-243">舒适</span><span class="sxs-lookup"><span data-stu-id="6015e-243">Comfort</span></span>](comfort.md)
